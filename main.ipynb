{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from datasets import load_dataset\n",
    "import transformer_lens\n",
    "import sae_lens\n",
    "\n",
    "import einops\n",
    "import circuitsvis as cv\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "from openai import OpenAI\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Hugging face: 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\n",
    "# Wandb: 6b549d940e7a29c79c184f27f25606e94a48a966"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "t.set_grad_enabled(False)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "gpt2: sae_lens.HookedSAETransformer = sae_lens.HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c376168d144dd2a66ce89f52b0ebcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d68d40f9af4b46a318cd5c3d8076b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e97449dd52141f6be96b905c15252a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v5_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cf1b87c313484e97c086386fd63a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v5.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702494c611814cdc92a1bfeccfdbb503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v4_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808ede7b9d6e4fdd9f015ba113ae8ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v4.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bf62c642c5436d9afca4507a47f15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10d047494b44a4789f5383f8460f645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6821808b8ca4b5ba49de4e9e2f1f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v7_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0061cbdb14435496e9b8c9e4fb3bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v7.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f366e1c4c44c13b52cf0249699be19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fe80cd4cdd4c80acae239d5dfca16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f614d87176e4d6da817699e5726bfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0256fa7f236340a08177b2493b549abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef7abf2015249d8bf1e0241e65d4ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5639bc3e8641e9a746ca6fa09b349e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bf1f088e384feaa0c5078e1399a76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-05_rsanthropic_rie25000_nr4_v6_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8bc030aede474e945372ba03890c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-05_rsanthropic_rie25000_nr4_v6.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0917c45b0f8a4acb8c0674116c633006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357a64ee28ed45d4ac2934efb947429b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5655517736e54bbaa4aef090695e8474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-05_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf699835bc94188be87abd319ab5597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-05_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb58f319904a4482ad2e1e2d283ffae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ac1abd619b44979a4c87935778cd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c3.16e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_saes = {\n",
    "    layer: sae_lens.SAE.from_pretrained(\n",
    "        \"gpt2-small-hook-z-kk\",\n",
    "        f\"blocks.{layer}.hook_z\",\n",
    "        device=device,\n",
    "    )[0]\n",
    "    for layer in range(gpt2.cfg.n_layers)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://neuronpedia.org/gpt2-small/9-att-kk/2?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/9-att-kk/2?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ef9b05566e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_dashboard(\n",
    "    sae_release=\"gpt2-small-res-jb\",\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",\n",
    "    latent_idx=0,\n",
    "    width=800,\n",
    "    height=600,\n",
    "):\n",
    "    release = sae_lens.toolkit.pretrained_saes_directory.get_pretrained_saes_directory()[sae_release]\n",
    "    neuronpedia_id = release.neuronpedia_id[sae_id]\n",
    "\n",
    "    url = f\"https://neuronpedia.org/{neuronpedia_id}/{latent_idx}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "    print(url)\n",
    "    display(IFrame(url, width=width, height=height))\n",
    "\n",
    "\n",
    "layer = 9\n",
    "\n",
    "display_dashboard(\n",
    "    sae_release=\"gpt2-small-hook-z-kk\",\n",
    "    sae_id=f\"blocks.{layer}.hook_z\",\n",
    "    latent_idx=2,  # or you can try `random.randint(0, attn_saes[layer].cfg.d_sae)`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  0.,  0., -0.],\n",
       "        [ 3., -2., -0., -3.],\n",
       "        [-3.,  0.,  0.,  2.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wanda pruning\n",
    "def wanda_prune(W, X, s):\n",
    "    # Compute the L2 norm of input features\n",
    "    X_norm = t.norm(X, dim=0)\n",
    "    \n",
    "    # Compute the pruning scores\n",
    "    scores = t.abs(W) * X_norm\n",
    "    \n",
    "    # Determine the pruning threshold\n",
    "    n_prune = int(W.numel() * s)\n",
    "    threshold = t.topk(scores.flatten(), n_prune, largest=False)[0][-1]\n",
    "    \n",
    "    # Create the mask\n",
    "    mask = scores > threshold\n",
    "    \n",
    "    # Apply the mask to the weights\n",
    "    W_pruned = W * mask\n",
    "    \n",
    "    return W_pruned\n",
    "\n",
    "\n",
    "W = t.tensor([\n",
    "    [4, 0, 1, -1], \n",
    "    [3, -2, -1, -3], \n",
    "    [-3, 1, 0, 2]\n",
    "    ], dtype=t.float32)\n",
    "X = t.tensor([1, 2, 8, 3], dtype=t.float32)\n",
    "\n",
    "true = t.tensor([\n",
    "    [4, 0, 1, 0], \n",
    "    [0, 0, -1, -3], \n",
    "    [-3, 0, 0, 2]\n",
    "    ], dtype=t.float32)\n",
    "\n",
    "computed = wanda_prune(W.clone(), X, 0.5)\n",
    "computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma2\n",
    "\n",
    "Issue: Pretrained SAE is not available for the model - for attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43d88923b19449098cb3f88e93afc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "gemma2b: sae_lens.HookedSAETransformer = sae_lens.HookedSAETransformer.from_pretrained(\"gemma-2-2b\", device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
