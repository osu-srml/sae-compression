{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from datasets import load_dataset\n",
    "\n",
    "import sae_lens\n",
    "import transformer_lens\n",
    "from sae_lens import (\n",
    "    SAE,\n",
    "    ActivationsStore,\n",
    "    HookedSAETransformer,\n",
    "    LanguageModelSAERunnerConfig,\n",
    "    SAEConfig,\n",
    "    SAETrainingRunner,\n",
    "    upload_saes_to_huggingface,\n",
    ")\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from sae_vis import SaeVisConfig, SaeVisData, SaeVisLayoutConfig\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.utils import get_act_name, test_prompt, to_numpy\n",
    "\n",
    "import einops\n",
    "import circuitsvis as cv\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "from openai import OpenAI\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "from transformer_lens import utils\n",
    "from functools import partial\n",
    "from sae_lens.evals import *\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# device1 = t.device(\"cuda:1\" if t.cuda.is_available() else \"cpu\")\n",
    "# device2 = t.device(\"cuda:2\" if t.cuda.is_available() else \"cpu\")\n",
    "# print(device1, device2)\n",
    "# gpt2 = sae_lens.HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device1)\n",
    "# Hugging face: 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\n",
    "# Wandb: 6b549d940e7a29c79c184f27f25606e94a48a966"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q. How different is an SAE trained on wanda-pruned gpt2-small from a wanda-pruned SAE trained on gpt2-small?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_grad_enabled(False)\n",
    "\n",
    "# next we want to do a reconstruction test.\n",
    "def reconstr_hook(activation, hook, sae_out):\n",
    "    return sae_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = sae_lens.HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device1)\n",
    "\n",
    "# # MATS\n",
    "# hf_repo_id = \"gpt2-small-hook-z-kk\"\n",
    "# sae_id = \"blocks.9.hook_z\"\n",
    "# pruned_sae_trained_on_gpt2 = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device1))[0]\n",
    "# pruned_sae_trained_on_gpt2.load_state_dict(t.load('pruned/pruned_gpt2_attn_sae_wanda.pth'))\n",
    "\n",
    "# Trained by me\n",
    "hf_repo_id = \"suchitg/sae_wanda\"\n",
    "sae_id = 'blocks.9.attn.hook_z-v1'\n",
    "pruned_sae_trained_on_gpt2 = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device1))[0]\n",
    "pruned_sae_trained_on_gpt2.load_state_dict(t.load('pruned/pruned_gpt2_sae_wanda.pth'))\n",
    "\n",
    "\n",
    "dataset = load_dataset(\n",
    "    path=\"NeelNanda/pile-10k\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "token_dataset = tokenize_and_concatenate(\n",
    "    dataset=dataset,  # type: ignore\n",
    "    tokenizer=gpt2.tokenizer,  # type: ignore\n",
    "    streaming=True,\n",
    "    max_length=pruned_sae_trained_on_gpt2.cfg.context_size,\n",
    "    add_bos_token=pruned_sae_trained_on_gpt2.cfg.prepend_bos,\n",
    ")\n",
    "\n",
    "pruned_sae_trained_on_gpt2.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n",
    "\n",
    "with t.no_grad():\n",
    "\n",
    "    # activation store can give us tokens.\n",
    "    batch_tokens = token_dataset[:16][\"tokens\"]\n",
    "    _, cache = gpt2.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "    # Use the SAE\n",
    "    feature_acts = pruned_sae_trained_on_gpt2.encode(cache[pruned_sae_trained_on_gpt2.cfg.hook_name])\n",
    "    sae_out = pruned_sae_trained_on_gpt2.decode(feature_acts)\n",
    "\n",
    "    # save some room\n",
    "    del cache\n",
    "\n",
    "    print(\n",
    "    \"Reconstuction loss:\",\n",
    "    gpt2.run_with_hooks(\n",
    "        batch_tokens,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                pruned_sae_trained_on_gpt2.cfg.hook_name,\n",
    "                partial(reconstr_hook, sae_out=sae_out),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAE trained on wanda-pruned gpt2-small\n",
    "\n",
    "gpt2_pruned = sae_lens.HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device2)\n",
    "gpt2_pruned.load_state_dict(t.load('pruned/pruned_gpt2_wanda.pth'))\n",
    "\n",
    "# # MATS trained config\n",
    "# hf_repo_id = \"suchitg/sae_test\"\n",
    "# sae_id = 'blocks.9.attn.hook_z-attn-sae-v1'\n",
    "# sae_trained_on_gpt2_pruned = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device2))[0]\n",
    "\n",
    "# Trained by me\n",
    "hf_repo_id = \"suchitg/sae_wanda\"\n",
    "sae_id = 'blocks.9.attn.hook_z-v1'\n",
    "sae_trained_on_gpt2_pruned = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device2))[0]\n",
    "\n",
    "sae_trained_on_gpt2_pruned.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n",
    "\n",
    "with t.no_grad():\n",
    "\n",
    "    # activation store can give us tokens.\n",
    "    batch_tokens = token_dataset[:16][\"tokens\"]\n",
    "    _, cache = gpt2_pruned.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "    # Use the SAE\n",
    "    feature_acts = sae_trained_on_gpt2_pruned.encode(cache[sae_trained_on_gpt2_pruned.cfg.hook_name])\n",
    "    sae_out = sae_trained_on_gpt2_pruned.decode(feature_acts)\n",
    "\n",
    "    # save some room\n",
    "    del cache\n",
    "\n",
    "\n",
    "    print(\n",
    "    \"Reconstuction loss:\",\n",
    "    gpt2_pruned.run_with_hooks(\n",
    "        batch_tokens,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                sae_trained_on_gpt2_pruned.cfg.hook_name,\n",
    "                partial(reconstr_hook, sae_out=sae_out),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other method to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanda-pruned SAE trained on gpt2-small\n",
    "from evals import multiple_evals as ME\n",
    "\n",
    "hf_repo_id = \"gpt2-small-hook-z-kk\"\n",
    "sae_id = \"blocks.9.hook_z\"\n",
    "pruned_sae_trained_on_gpt2 = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device1))[0]\n",
    "pruned_sae_trained_on_gpt2.load_state_dict(t.load('pruned/pruned_gpt2_attn_sae_wanda.pth'))\n",
    "eval_results = ME(pruned_sae_trained_on_gpt2, 20, 200, 16, datasets=['Skylion007/openwebtext'], output_dir=\"out/pruned_sae_trained_on_gpt2\",verbose=True, load=False, path_to_load_from=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals import process_results as PR\n",
    "\n",
    "output_files = PR(eval_results, 'out/pruned_sae_trained_on_gpt2')\n",
    "print(\"Evaluation complete. Output files:\")\n",
    "print(f\"Individual JSONs: {len(output_files['individual_jsons'])}\")  # type: ignore\n",
    "print(f\"Combined JSON: {output_files['combined_json']}\")\n",
    "print(f\"CSV: {output_files['csv']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('out/pruned_sae_trained_on_gpt2/all_eval_results.csv')\n",
    "res['metrics.reconstruction_quality.mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_repo_id = \"suchitg/sae_test\"\n",
    "sae_id = 'blocks.9.attn.hook_z-attn-sae-v1'\n",
    "sae_trained_on_gpt2_pruned = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device2))[0]\n",
    "eval_results = ME(sae_trained_on_gpt2_pruned, 20, 200, 16, datasets=['Skylion007/openwebtext'], output_dir=\"out/sae_trained_on_gpt2_pruned\",verbose=True, load=False, path_to_load_from=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals import process_results as PR\n",
    "\n",
    "output_files = PR(eval_results, 'out/sae_trained_on_gpt2_pruned')\n",
    "print(\"Evaluation complete. Output files:\")\n",
    "print(f\"Individual JSONs: {len(output_files['individual_jsons'])}\")  # type: ignore\n",
    "print(f\"Combined JSON: {output_files['combined_json']}\")\n",
    "print(f\"CSV: {output_files['csv']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('out/sae_trained_on_gpt2_pruned/all_eval_results.csv')\n",
    "res['metrics.reconstruction_quality.mse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try reconstruction loss from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_reconstruction_loss(sae, model, dataset, batch_size=8):\n",
    "    sae.eval()\n",
    "    hook_name = sae.cfg.hook_name\n",
    "    # print(hook_name, head_index)\n",
    "    def reconstr_hook(activation, hook, sae_out):\n",
    "        return sae_out\n",
    "    \n",
    "    n_batches = dataset.num_rows // batch_size\n",
    "    loss = 0\n",
    "\n",
    "    for batch in tqdm(range(n_batches)):\n",
    "        with t.no_grad():\n",
    "            batch_tokens = token_dataset[batch * batch_size : (batch + 1) * batch_size][\"tokens\"]\n",
    "            _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "            feature_acts = sae.encode(cache[hook_name])\n",
    "            sae_out = sae.decode(feature_acts)\n",
    "            del cache\n",
    "\n",
    "            loss += model.run_with_hooks(batch_tokens, fwd_hooks=[(hook_name, partial(reconstr_hook, sae_out=sae_out))], return_type=\"loss\").item()\n",
    "    \n",
    "    return loss/n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    path=\"NeelNanda/pile-10k\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "token_dataset = tokenize_and_concatenate(\n",
    "    dataset=dataset,  # type: ignore\n",
    "    tokenizer=gpt2.tokenizer,  # type: ignore\n",
    "    streaming=True,\n",
    "    max_length=128,\n",
    "    add_bos_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MATS\n",
    "# hf_repo_id = \"gpt2-small-hook-z-kk\"\n",
    "# sae_id = \"blocks.9.hook_z\"\n",
    "# pruned_sae_trained_on_gpt2 = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device1))[0]\n",
    "# pruned_sae_trained_on_gpt2.load_state_dict(t.load('pruned/pruned_gpt2_attn_sae_wanda.pth'))\n",
    "\n",
    "# Trained by me\n",
    "hf_repo_id = \"suchitg/sae_wanda\"\n",
    "sae_id = 'blocks.9.attn.hook_z-v1'\n",
    "pruned_sae_trained_on_gpt2 = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device1))[0]\n",
    "pruned_sae_trained_on_gpt2.load_state_dict(t.load('pruned/pruned_gpt2_sae_wanda.pth'))\n",
    "\n",
    "get_reconstruction_loss(pruned_sae_trained_on_gpt2, gpt2, token_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATS\n",
    "hf_repo_id = \"gpt2-small-hook-z-kk\"\n",
    "sae_id = \"blocks.9.hook_z\"\n",
    "pruned_sae_trained_on_gpt2 = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device1))[0]\n",
    "pruned_sae_trained_on_gpt2.load_state_dict(t.load('pruned/pruned_gpt2_attn_sae_wanda.pth'))\n",
    "\n",
    "get_reconstruction_loss(pruned_sae_trained_on_gpt2, gpt2, token_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_pruned = sae_lens.HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device2)\n",
    "gpt2_pruned.load_state_dict(t.load('pruned/pruned_gpt2_wanda.pth'))\n",
    "\n",
    "# Trained by me\n",
    "hf_repo_id = \"suchitg/sae_wanda\"\n",
    "sae_id = 'blocks.9.attn.hook_z-v1'\n",
    "sae_trained_on_gpt2_pruned = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device2))[0]\n",
    "\n",
    "get_reconstruction_loss(sae_trained_on_gpt2_pruned, gpt2_pruned, token_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATS trained config\n",
    "hf_repo_id = \"suchitg/sae_test\"\n",
    "sae_id = 'blocks.9.attn.hook_z-attn-sae-v1'\n",
    "sae_trained_on_gpt2_pruned = sae_lens.SAE.from_pretrained(release=hf_repo_id, sae_id=sae_id, device=str(device2))[0]\n",
    "\n",
    "get_reconstruction_loss(sae_trained_on_gpt2_pruned, gpt2_pruned, token_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the reconstruction loss of the original pre-trained SAE on the compressed model's activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = sae_lens.SAE.from_pretrained(\"gpt2-small-hook-z-kk\",\"blocks.9.hook_z\",device=device1,)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sae_lens.HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device1)\n",
    "get_reconstruction_loss(sae, model, token_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = sae_lens.HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device1)\n",
    "pruned_model.load_state_dict(t.load('pruned/pruned_gpt2_wanda.pth'))\n",
    "get_reconstruction_loss(sae, pruned_model, token_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sense of the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = pd.read_csv('logs/results_c4.csv')\n",
    "c4_losses = pd.read_csv('logs/losses_c4.csv')\n",
    "\n",
    "openwebtext = pd.read_csv('logs/results_openwebtext.csv')\n",
    "openwebtext_losses = pd.read_csv('logs/losses_openwebtext.csv')\n",
    "\n",
    "pile = pd.read_csv('logs/results_pile.csv')\n",
    "pile_losses = pd.read_csv('logs/losses_pile.csv')\n",
    "\n",
    "wiki = pd.read_csv('logs/results_wiki.csv')\n",
    "wiki_losses = pd.read_csv('logs/losses_wiki.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unused functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c4[(c4['Model'] == 'Pruned SAE') & (c4['Layer'] == 10) & (c4['Sparse Ratio'] >= 0.9)].sort_values(by='Validation Loss').head(20)\n",
    "# openwebtext[(openwebtext['Model'] == 'Pruned SAE') & (openwebtext['Layer'] == 11) & (openwebtext['Sparse Ratio'] >= 0.9)].sort_values(by='Validation Loss').head(20)\n",
    "# pile[(pile['Model'] == 'Pruned SAE') & (pile['Layer'] == 9) & (pile['Sparse Ratio'] >= 0.24)].sort_values(by='Validation Loss').head(20)\n",
    "# wiki[(wiki['Model'] == 'Pruned SAE') & (wiki['Layer'] == 10) & (wiki['Sparse Ratio'] >= 0.9)].sort_values(by='Validation Loss').head(20)\n",
    "\n",
    "# c4[c4['Model'] == 'SAE trained on pruned gpt2-small ']['Validation Loss']\n",
    "# openwebtext[openwebtext['Model'] == 'SAE trained on pruned gpt2-small ']['Validation Loss']\n",
    "# pile[pile['Model'] == 'SAE trained on pruned gpt2-small ']['Validation Loss']\n",
    "# wiki[wiki['Model'] == 'SAE trained on pruned gpt2-small ']['Validation Loss']\n",
    "\n",
    "# c4[c4['Model'] == 'Best sparse ratio pruned SAE']['Validation Loss']\n",
    "# openwebtext[openwebtext['Model'] == 'Best sparse ratio pruned SAE']['Validation Loss']\n",
    "# pile[pile['Model'] == 'Best sparse ratio pruned SAE']['Validation Loss']\n",
    "# wiki[wiki['Model'] == 'Best sparse ratio pruned SAE']['Validation Loss']\n",
    "\n",
    "# c4[c4['Model'] == 'Best sparse ratio pruned SAE']['Sparse Ratio']\n",
    "# openwebtext[openwebtext['Model'] == 'Best sparse ratio pruned SAE']['Sparse Ratio']\n",
    "# pile[pile['Model'] == 'Best sparse ratio pruned SAE']['Sparse Ratio']\n",
    "# wiki[wiki['Model'] == 'Best sparse ratio pruned SAE']['Sparse Ratio']\n",
    "\n",
    "# c4[c4['Model'] == 'Pretrained SAE']['Validation Loss']\n",
    "# openwebtext[openwebtext['Model'] == 'Pretrained SAE']['Validation Loss']\n",
    "# pile[pile['Model'] == 'Pretrained SAE']['Validation Loss']\n",
    "# wiki[wiki['Model'] == 'Pretrained SAE']['Validation Loss']\n",
    "\n",
    "# def plot(dataset):\n",
    "#     # Create subplots for each layer\n",
    "#     fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 12), sharex=True, sharey=True)\n",
    "#     axes = axes.flatten()\n",
    "#     df = dataset[(dataset['Model'] == 'Pruned SAE')]\n",
    "\n",
    "#     for i in range(12):\n",
    "#         val1 = dataset[(dataset['Model'] == 'SAE trained on pruned gpt2-small ') & (dataset['Layer'] == i)]['Validation Loss'].values[0]\n",
    "#         val2 = dataset[(dataset['Model'] == 'Pretrained SAE') & (dataset['Layer'] == i)]['Validation Loss'].values[0]\n",
    "        \n",
    "#         layer_df = df[df[\"Layer\"] == i]\n",
    "#         ax = axes[i]\n",
    "#         ax.plot(layer_df[\"Sparse Ratio\"], layer_df[\"Validation Loss\"], label=\"Validation Loss\")\n",
    "#         ax.axhline(y=val1, color='r', linestyle='--', label=\"SAE trained on pruned gpt2-small \")\n",
    "#         ax.axhline(y=val2, color='b', linestyle='--', label=\"Pretrained SAE\")\n",
    "\n",
    "\n",
    "#         ax.set_title(f\"Layer {i}\")\n",
    "#         ax.legend()\n",
    "#         ax.set_xlabel(\"Sparse Ratio\")\n",
    "#         ax.set_ylabel(\"Loss\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "\n",
    "def plot(dataset, losses):\n",
    "    # Create a 4x3 subplot grid\n",
    "    fig = sp.make_subplots(rows=4, cols=3, subplot_titles=[f\"Layer {i}\" for i in range(12)],\n",
    "                           shared_xaxes=True, shared_yaxes=True)\n",
    "\n",
    "    df = dataset[dataset['Model'] == 'Pruned SAE']\n",
    "\n",
    "    for i in range(12):\n",
    "        val1 = dataset[(dataset['Model'] == 'SAE trained on pruned gpt2-small ') & (dataset['Layer'] == i)]['Validation Loss'].values[0]\n",
    "        val2 = dataset[(dataset['Model'] == 'Pretrained SAE') & (dataset['Layer'] == i)]['Validation Loss'].values[0]\n",
    "\n",
    "        val3 = losses[(losses['Model'] == 'SAE trained on pruned gpt2-small') & \n",
    "                      (losses['Layer'] == i) & \n",
    "                      (losses['Config'] == 'MATS') & \n",
    "                      (losses['Architecture'] == 'standard') & \n",
    "                      (losses['Epochs'] == '30K')]['Validation Loss'].values[0]\n",
    "        \n",
    "        val4 = losses[(losses['Model'] == 'SAE trained on pruned gpt2-small') & \n",
    "                      (losses['Layer'] == i) & \n",
    "                      (losses['Config'] == 'Custom') & \n",
    "                      (losses['Architecture'] == 'standard') & \n",
    "                      (losses['Epochs'] == '30K')]['Validation Loss'].values[0]\n",
    "        \n",
    "        # val5 = losses[(losses['Model'] == 'SAE trained on pruned gpt2-small') & \n",
    "        #               (losses['Layer'] == i) & \n",
    "        #               (losses['Config'] == 'Custom') & \n",
    "        #               (losses['Architecture'] == 'standard') & \n",
    "        #               (losses['Epochs'] == '50K')]['Validation Loss'].values[0]\n",
    "        \n",
    "        # assert val1 == val3\n",
    "        # print(val1, val3)\n",
    "\n",
    "\n",
    "        \n",
    "        layer_df = df[df[\"Layer\"] == i]\n",
    "        row, col = (i // 3) + 1, (i % 3) + 1  # Determine subplot position\n",
    "        \n",
    "        # Add main line plot\n",
    "        fig.add_trace(go.Scatter(x=layer_df[\"Sparse Ratio\"], y=layer_df[\"Validation Loss\"],\n",
    "                                 mode='lines+markers', name=\"Pruned SAE\",\n",
    "                                 marker=dict(size=2, color=\"black\"), line=dict(width=1, color=\"green\"),\n",
    "                                 showlegend=True if i == 0 else False), row=row, col=col)\n",
    "\n",
    "        # Add horizontal reference lines\n",
    "        fig.add_trace(go.Scatter(x=[layer_df[\"Sparse Ratio\"].min(), layer_df[\"Sparse Ratio\"].max()],\n",
    "                                 y=[val1, val1], mode=\"lines\", name=\"SAE trained on pruned (MATS)\",\n",
    "                                 line=dict(dash=\"dash\", color=\"red\"), showlegend=True if i == 0 else False),\n",
    "                      row=row, col=col)\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=[layer_df[\"Sparse Ratio\"].min(), layer_df[\"Sparse Ratio\"].max()],\n",
    "                                 y=[val4, val4], mode=\"lines\", name=\"SAE trained on pruned (Custom)\",\n",
    "                                 line=dict(dash=\"dot\", color=\"blue\"), showlegend=True if i == 0 else False),\n",
    "                      row=row, col=col)\n",
    "        \n",
    "        # fig.add_trace(go.Scatter(x=[layer_df[\"Sparse Ratio\"].min(), layer_df[\"Sparse Ratio\"].max()],\n",
    "        #                          y=[val5, val5], mode=\"lines\", name=\"SAE trained on pruned (Custom-50K)\",\n",
    "        #                          line=dict(dash=\"dashdot\", color=\"purple\"), showlegend=True if i == 0 else False),\n",
    "        #               row=row, col=col)\n",
    "        \n",
    "\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=[layer_df[\"Sparse Ratio\"].min(), layer_df[\"Sparse Ratio\"].max()],\n",
    "                                 y=[val2, val2], mode=\"lines\", name=\"Pretrained SAE\",\n",
    "                                 line=dict(dash=\"longdash\", color=\"orange\"), showlegend=True if i == 0 else False),\n",
    "                      row=row, col=col)\n",
    "\n",
    "    # Layout improvements\n",
    "    fig.update_layout(height=800, width=1200,\n",
    "                      title_text=\"Validation Loss vs Sparse Ratio across Layers\",\n",
    "                      title_x=0.5, showlegend=True, template=\"plotly_white\")\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Sparse Ratio\")\n",
    "    fig.update_yaxes(title_text=\"Validation Loss\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(c4, c4_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(openwebtext, openwebtext_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pile, pile_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(wiki, wiki_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
