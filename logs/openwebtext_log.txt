2025-03-08 18:53:20,942 - INFO - Using device: cuda:0
2025-03-08 18:53:24,129 - INFO - Loaded wanda pruned gpt-2 small
2025-03-08 18:53:25,027 - INFO - Loaded calibration dataset: openwebtext
2025-03-08 18:55:29,609 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 10.3479, and Test loss: 10.3022
2025-03-08 18:57:07,622 - INFO - Before pruning pretrained SAE, Validation loss: 7.5272, and Test loss: 7.5207
2025-03-08 18:57:07,623 - INFO - Pruning for layer: 0
2025-03-08 18:57:07,623 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.0.hook_z
2025-03-08 18:57:07,623 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.0.attn.hook_z-attn-sae-v1
2025-03-08 18:58:41,073 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 4.1083
2025-03-08 18:58:42,049 - INFO - Resetting pretrained SAE
2025-03-08 19:00:15,460 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 5.2209
2025-03-08 19:00:15,679 - INFO - Resetting pretrained SAE
2025-03-08 19:01:50,247 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 6.4787
2025-03-08 19:01:50,470 - INFO - Resetting pretrained SAE
2025-03-08 19:03:24,856 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 7.3085
2025-03-08 19:03:25,075 - INFO - Resetting pretrained SAE
2025-03-08 19:04:59,156 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 7.6803
2025-03-08 19:04:59,452 - INFO - Resetting pretrained SAE
2025-03-08 19:06:33,548 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 7.8197
2025-03-08 19:06:33,769 - INFO - Resetting pretrained SAE
2025-03-08 19:08:07,711 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 7.942
2025-03-08 19:08:07,939 - INFO - Resetting pretrained SAE
2025-03-08 19:09:42,404 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 7.9039
2025-03-08 19:09:42,641 - INFO - Resetting pretrained SAE
2025-03-08 19:11:16,573 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 7.9273
2025-03-08 19:11:23,405 - INFO - Resetting pretrained SAE
2025-03-08 19:12:57,209 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 7.8956
2025-03-08 19:12:57,453 - INFO - Resetting pretrained SAE
2025-03-08 19:14:31,864 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 7.8257
2025-03-08 19:14:32,088 - INFO - Resetting pretrained SAE
2025-03-08 19:16:05,946 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 7.7498
2025-03-08 19:16:06,168 - INFO - Resetting pretrained SAE
2025-03-08 19:17:40,273 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 7.6943
2025-03-08 19:17:40,494 - INFO - Resetting pretrained SAE
2025-03-08 19:19:14,290 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 7.691
2025-03-08 19:19:14,559 - INFO - Resetting pretrained SAE
2025-03-08 19:20:49,371 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 7.6807
2025-03-08 19:20:49,589 - INFO - Resetting pretrained SAE
2025-03-08 19:22:24,267 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 7.6646
2025-03-08 19:22:24,552 - INFO - Resetting pretrained SAE
2025-03-08 19:23:58,981 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 7.6557
2025-03-08 19:23:59,218 - INFO - Resetting pretrained SAE
2025-03-08 19:25:33,392 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 7.6714
2025-03-08 19:25:33,698 - INFO - Resetting pretrained SAE
2025-03-08 19:27:08,692 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 7.677
2025-03-08 19:27:08,913 - INFO - Resetting pretrained SAE
2025-03-08 19:28:43,133 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 7.6622
2025-03-08 19:28:43,350 - INFO - Resetting pretrained SAE
2025-03-08 19:30:17,296 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 7.6517
2025-03-08 19:30:17,533 - INFO - Resetting pretrained SAE
2025-03-08 19:31:52,005 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 7.6458
2025-03-08 19:31:52,233 - INFO - Resetting pretrained SAE
2025-03-08 19:33:26,622 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 7.63
2025-03-08 19:33:26,837 - INFO - Resetting pretrained SAE
2025-03-08 19:35:02,131 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 7.6178
2025-03-08 19:35:02,343 - INFO - Resetting pretrained SAE
2025-03-08 19:36:36,699 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 7.623
2025-03-08 19:36:36,957 - INFO - Resetting pretrained SAE
2025-03-08 19:38:11,022 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 7.632
2025-03-08 19:38:11,256 - INFO - Resetting pretrained SAE
2025-03-08 19:39:45,853 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 7.6125
2025-03-08 19:39:46,066 - INFO - Resetting pretrained SAE
2025-03-08 19:41:19,905 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 7.599
2025-03-08 19:41:20,125 - INFO - Resetting pretrained SAE
2025-03-08 19:42:54,443 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 7.6029
2025-03-08 19:42:54,666 - INFO - Resetting pretrained SAE
2025-03-08 19:44:29,195 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 7.592
2025-03-08 19:44:29,447 - INFO - Resetting pretrained SAE
2025-03-08 19:46:03,305 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 7.5816
2025-03-08 19:46:03,518 - INFO - Resetting pretrained SAE
2025-03-08 19:47:37,675 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 7.5842
2025-03-08 19:47:38,154 - INFO - Resetting pretrained SAE
2025-03-08 19:49:12,418 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 7.5568
2025-03-08 19:49:12,662 - INFO - Resetting pretrained SAE
2025-03-08 19:50:47,227 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 7.5649
2025-03-08 19:50:47,484 - INFO - Resetting pretrained SAE
2025-03-08 19:52:22,370 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 7.5519
2025-03-08 19:52:22,590 - INFO - Resetting pretrained SAE
2025-03-08 19:53:57,279 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 7.5446
2025-03-08 19:53:57,570 - INFO - Resetting pretrained SAE
2025-03-08 19:55:31,682 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 7.5389
2025-03-08 19:55:31,942 - INFO - Resetting pretrained SAE
2025-03-08 19:57:06,407 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 7.5364
2025-03-08 19:57:06,639 - INFO - Resetting pretrained SAE
2025-03-08 19:57:06,642 - INFO - For layer 0, the best Sparse Ratio: 0.99 with validation loss: 4.1083
2025-03-08 19:57:24,433 - INFO - After pruning pretrained SAE, Validation loss: 4.1083, and Test loss: 4.1497
2025-03-08 19:59:03,057 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 7.8594, and Test loss: 7.8735
2025-03-08 20:00:42,482 - INFO - Before pruning pretrained SAE, Validation loss: 5.3171, and Test loss: 5.3619
2025-03-08 20:00:42,482 - INFO - Pruning for layer: 1
2025-03-08 20:00:42,482 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.1.hook_z
2025-03-08 20:00:42,482 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.1.attn.hook_z-attn-sae-v1
2025-03-08 20:02:16,534 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 3.191
2025-03-08 20:02:16,765 - INFO - Resetting pretrained SAE
2025-03-08 20:03:51,336 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 3.9963
2025-03-08 20:03:51,555 - INFO - Resetting pretrained SAE
2025-03-08 20:05:26,015 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 4.2163
2025-03-08 20:05:26,279 - INFO - Resetting pretrained SAE
2025-03-08 20:07:00,371 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 4.3853
2025-03-08 20:07:00,588 - INFO - Resetting pretrained SAE
2025-03-08 20:08:34,694 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 4.3052
2025-03-08 20:08:34,922 - INFO - Resetting pretrained SAE
2025-03-08 20:10:08,693 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 4.3975
2025-03-08 20:10:08,922 - INFO - Resetting pretrained SAE
2025-03-08 20:11:43,496 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 4.6543
2025-03-08 20:11:43,782 - INFO - Resetting pretrained SAE
2025-03-08 20:13:18,038 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 4.8193
2025-03-08 20:13:18,292 - INFO - Resetting pretrained SAE
2025-03-08 20:14:52,726 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 4.8763
2025-03-08 20:14:53,079 - INFO - Resetting pretrained SAE
2025-03-08 20:16:27,411 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 4.9025
2025-03-08 20:16:27,642 - INFO - Resetting pretrained SAE
2025-03-08 20:18:02,404 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 5.0337
2025-03-08 20:18:02,642 - INFO - Resetting pretrained SAE
2025-03-08 20:19:37,516 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 5.0568
2025-03-08 20:19:37,734 - INFO - Resetting pretrained SAE
2025-03-08 20:21:11,985 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 5.1095
2025-03-08 20:21:12,208 - INFO - Resetting pretrained SAE
2025-03-08 20:22:46,937 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 5.0979
2025-03-08 20:22:47,157 - INFO - Resetting pretrained SAE
2025-03-08 20:24:21,189 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 5.1767
2025-03-08 20:24:21,392 - INFO - Resetting pretrained SAE
2025-03-08 20:25:55,441 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 5.2222
2025-03-08 20:25:55,660 - INFO - Resetting pretrained SAE
2025-03-08 20:27:30,041 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 5.2474
2025-03-08 20:27:30,269 - INFO - Resetting pretrained SAE
2025-03-08 20:29:04,432 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 5.2659
2025-03-08 20:29:04,648 - INFO - Resetting pretrained SAE
2025-03-08 20:30:39,028 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 5.2671
2025-03-08 20:30:39,461 - INFO - Resetting pretrained SAE
2025-03-08 20:32:13,065 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 5.2255
2025-03-08 20:32:13,293 - INFO - Resetting pretrained SAE
2025-03-08 20:33:47,609 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 5.259
2025-03-08 20:33:47,823 - INFO - Resetting pretrained SAE
2025-03-08 20:35:22,300 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 5.2356
2025-03-08 20:35:22,518 - INFO - Resetting pretrained SAE
2025-03-08 20:36:57,191 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 5.325
2025-03-08 20:36:57,413 - INFO - Resetting pretrained SAE
2025-03-08 20:38:32,192 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 5.4362
2025-03-08 20:38:32,404 - INFO - Resetting pretrained SAE
2025-03-08 20:40:06,756 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 5.509
2025-03-08 20:40:07,134 - INFO - Resetting pretrained SAE
2025-03-08 20:41:41,208 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 5.4338
2025-03-08 20:41:41,425 - INFO - Resetting pretrained SAE
2025-03-08 20:43:15,671 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 5.4651
2025-03-08 20:43:15,895 - INFO - Resetting pretrained SAE
2025-03-08 20:44:50,436 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 5.415
2025-03-08 20:44:50,677 - INFO - Resetting pretrained SAE
2025-03-08 20:46:24,992 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 5.4738
2025-03-08 20:46:25,305 - INFO - Resetting pretrained SAE
2025-03-08 20:48:00,177 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 5.5464
2025-03-08 20:48:00,617 - INFO - Resetting pretrained SAE
2025-03-08 20:49:35,810 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 5.4958
2025-03-08 20:49:36,049 - INFO - Resetting pretrained SAE
2025-03-08 20:51:10,266 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 5.5117
2025-03-08 20:51:10,491 - INFO - Resetting pretrained SAE
2025-03-08 20:52:44,908 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 5.4945
2025-03-08 20:52:45,152 - INFO - Resetting pretrained SAE
2025-03-08 20:54:19,946 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 5.4324
2025-03-08 20:54:20,183 - INFO - Resetting pretrained SAE
2025-03-08 20:55:54,431 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 5.3859
2025-03-08 20:55:54,661 - INFO - Resetting pretrained SAE
2025-03-08 20:57:28,916 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 5.3257
2025-03-08 20:57:29,283 - INFO - Resetting pretrained SAE
2025-03-08 20:59:03,451 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 5.3125
2025-03-08 20:59:03,678 - INFO - Resetting pretrained SAE
2025-03-08 21:00:37,970 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 5.2984
2025-03-08 21:00:38,310 - INFO - Resetting pretrained SAE
2025-03-08 21:00:38,314 - INFO - For layer 1, the best Sparse Ratio: 0.99 with validation loss: 3.191
2025-03-08 21:00:55,998 - INFO - After pruning pretrained SAE, Validation loss: 3.191, and Test loss: 3.1764
2025-03-08 21:02:35,363 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 4.1071, and Test loss: 4.1652
2025-03-08 21:04:13,821 - INFO - Before pruning pretrained SAE, Validation loss: 4.7232, and Test loss: 4.7297
2025-03-08 21:04:13,822 - INFO - Pruning for layer: 2
2025-03-08 21:04:13,822 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.2.hook_z
2025-03-08 21:04:13,822 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.2.attn.hook_z-attn-sae-v1
2025-03-08 21:05:48,559 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.6078
2025-03-08 21:05:48,780 - INFO - Resetting pretrained SAE
2025-03-08 21:07:22,957 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.6468
2025-03-08 21:07:23,174 - INFO - Resetting pretrained SAE
2025-03-08 21:08:57,349 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.7865
2025-03-08 21:08:57,566 - INFO - Resetting pretrained SAE
2025-03-08 21:10:32,461 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9283
2025-03-08 21:10:32,693 - INFO - Resetting pretrained SAE
2025-03-08 21:12:07,200 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 3.1106
2025-03-08 21:12:07,434 - INFO - Resetting pretrained SAE
2025-03-08 21:13:41,786 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 3.3579
2025-03-08 21:13:42,005 - INFO - Resetting pretrained SAE
2025-03-08 21:15:16,193 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 3.5038
2025-03-08 21:15:16,414 - INFO - Resetting pretrained SAE
2025-03-08 21:16:51,070 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 3.6248
2025-03-08 21:16:51,303 - INFO - Resetting pretrained SAE
2025-03-08 21:18:25,239 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 3.6548
2025-03-08 21:18:25,491 - INFO - Resetting pretrained SAE
2025-03-08 21:20:00,132 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 3.6875
2025-03-08 21:20:00,401 - INFO - Resetting pretrained SAE
2025-03-08 21:21:35,722 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 3.7391
2025-03-08 21:21:36,166 - INFO - Resetting pretrained SAE
2025-03-08 21:23:11,075 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 3.8618
2025-03-08 21:23:11,324 - INFO - Resetting pretrained SAE
2025-03-08 21:24:45,211 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 3.8926
2025-03-08 21:24:45,429 - INFO - Resetting pretrained SAE
2025-03-08 21:26:19,284 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 4.0125
2025-03-08 21:26:19,585 - INFO - Resetting pretrained SAE
2025-03-08 21:27:54,204 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 4.0469
2025-03-08 21:27:54,431 - INFO - Resetting pretrained SAE
2025-03-08 21:29:28,770 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 4.1046
2025-03-08 21:29:28,980 - INFO - Resetting pretrained SAE
2025-03-08 21:31:03,385 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 4.1603
2025-03-08 21:31:03,610 - INFO - Resetting pretrained SAE
2025-03-08 21:32:37,692 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 4.2205
2025-03-08 21:32:37,922 - INFO - Resetting pretrained SAE
2025-03-08 21:34:11,964 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 4.3242
2025-03-08 21:34:12,224 - INFO - Resetting pretrained SAE
2025-03-08 21:35:47,187 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 4.3938
2025-03-08 21:35:47,409 - INFO - Resetting pretrained SAE
2025-03-08 21:37:21,706 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 4.3659
2025-03-08 21:37:21,923 - INFO - Resetting pretrained SAE
2025-03-08 21:38:56,389 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 4.4309
2025-03-08 21:38:56,624 - INFO - Resetting pretrained SAE
2025-03-08 21:40:30,955 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 4.4394
2025-03-08 21:40:31,173 - INFO - Resetting pretrained SAE
2025-03-08 21:42:05,328 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 4.467
2025-03-08 21:42:05,543 - INFO - Resetting pretrained SAE
2025-03-08 21:43:40,171 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 4.5122
2025-03-08 21:43:40,412 - INFO - Resetting pretrained SAE
2025-03-08 21:45:14,750 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 4.5221
2025-03-08 21:45:14,973 - INFO - Resetting pretrained SAE
2025-03-08 21:46:49,278 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 4.4914
2025-03-08 21:46:49,726 - INFO - Resetting pretrained SAE
2025-03-08 21:48:24,198 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 4.4912
2025-03-08 21:48:24,468 - INFO - Resetting pretrained SAE
2025-03-08 21:49:58,950 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 4.4007
2025-03-08 21:49:59,167 - INFO - Resetting pretrained SAE
2025-03-08 21:51:33,730 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 4.3743
2025-03-08 21:51:33,960 - INFO - Resetting pretrained SAE
2025-03-08 21:53:08,207 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 4.318
2025-03-08 21:53:08,427 - INFO - Resetting pretrained SAE
2025-03-08 21:54:43,567 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 4.3351
2025-03-08 21:54:43,841 - INFO - Resetting pretrained SAE
2025-03-08 21:56:18,396 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 4.3527
2025-03-08 21:56:18,629 - INFO - Resetting pretrained SAE
2025-03-08 21:57:52,924 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 4.3762
2025-03-08 21:57:53,174 - INFO - Resetting pretrained SAE
2025-03-08 21:59:27,414 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 4.4064
2025-03-08 21:59:27,647 - INFO - Resetting pretrained SAE
2025-03-08 22:01:01,722 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 4.4382
2025-03-08 22:01:01,959 - INFO - Resetting pretrained SAE
2025-03-08 22:02:36,688 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 4.4613
2025-03-08 22:02:36,922 - INFO - Resetting pretrained SAE
2025-03-08 22:04:11,297 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 4.4876
2025-03-08 22:04:11,526 - INFO - Resetting pretrained SAE
2025-03-08 22:04:11,529 - INFO - For layer 2, the best Sparse Ratio: 0.99 with validation loss: 2.6078
2025-03-08 22:04:29,319 - INFO - After pruning pretrained SAE, Validation loss: 2.6078, and Test loss: 2.6549
2025-03-08 22:06:08,701 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.5374, and Test loss: 2.5824
2025-03-08 22:07:47,432 - INFO - Before pruning pretrained SAE, Validation loss: 2.6188, and Test loss: 2.6558
2025-03-08 22:07:47,432 - INFO - Pruning for layer: 3
2025-03-08 22:07:47,432 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.3.hook_z
2025-03-08 22:07:47,432 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.3.attn.hook_z-attn-sae-v1
2025-03-08 22:09:21,733 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.5407
2025-03-08 22:09:21,950 - INFO - Resetting pretrained SAE
2025-03-08 22:10:56,217 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.5427
2025-03-08 22:10:56,520 - INFO - Resetting pretrained SAE
2025-03-08 22:12:30,082 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.5419
2025-03-08 22:12:30,315 - INFO - Resetting pretrained SAE
2025-03-08 22:14:04,316 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.5422
2025-03-08 22:14:04,552 - INFO - Resetting pretrained SAE
2025-03-08 22:15:38,555 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.5408
2025-03-08 22:15:38,783 - INFO - Resetting pretrained SAE
2025-03-08 22:17:12,716 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.5397
2025-03-08 22:17:12,936 - INFO - Resetting pretrained SAE
2025-03-08 22:18:46,969 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.5347
2025-03-08 22:18:47,192 - INFO - Resetting pretrained SAE
2025-03-08 22:20:21,326 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.5347
2025-03-08 22:20:21,578 - INFO - Resetting pretrained SAE
2025-03-08 22:21:56,256 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.5356
2025-03-08 22:21:56,485 - INFO - Resetting pretrained SAE
2025-03-08 22:23:30,688 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.5359
2025-03-08 22:23:30,909 - INFO - Resetting pretrained SAE
2025-03-08 22:25:05,033 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.5376
2025-03-08 22:25:05,270 - INFO - Resetting pretrained SAE
2025-03-08 22:26:39,328 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.5388
2025-03-08 22:26:39,580 - INFO - Resetting pretrained SAE
2025-03-08 22:28:13,806 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.5328
2025-03-08 22:28:14,033 - INFO - Resetting pretrained SAE
2025-03-08 22:29:48,543 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.5295
2025-03-08 22:29:48,767 - INFO - Resetting pretrained SAE
2025-03-08 22:31:22,993 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.5301
2025-03-08 22:31:23,222 - INFO - Resetting pretrained SAE
2025-03-08 22:32:58,076 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.5343
2025-03-08 22:32:58,317 - INFO - Resetting pretrained SAE
2025-03-08 22:34:32,229 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.5297
2025-03-08 22:34:32,541 - INFO - Resetting pretrained SAE
2025-03-08 22:36:06,733 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.5258
2025-03-08 22:36:06,954 - INFO - Resetting pretrained SAE
2025-03-08 22:37:41,225 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.5322
2025-03-08 22:37:41,460 - INFO - Resetting pretrained SAE
2025-03-08 22:39:15,959 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.5384
2025-03-08 22:39:16,167 - INFO - Resetting pretrained SAE
2025-03-08 22:40:50,328 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.5262
2025-03-08 22:40:50,540 - INFO - Resetting pretrained SAE
2025-03-08 22:42:24,811 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.5422
2025-03-08 22:42:25,103 - INFO - Resetting pretrained SAE
2025-03-08 22:43:59,338 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.5322
2025-03-08 22:43:59,552 - INFO - Resetting pretrained SAE
2025-03-08 22:45:33,404 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.5464
2025-03-08 22:45:33,703 - INFO - Resetting pretrained SAE
2025-03-08 22:47:07,986 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.5543
2025-03-08 22:47:08,244 - INFO - Resetting pretrained SAE
2025-03-08 22:48:42,877 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.5491
2025-03-08 22:48:43,153 - INFO - Resetting pretrained SAE
2025-03-08 22:50:17,579 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.5363
2025-03-08 22:50:17,868 - INFO - Resetting pretrained SAE
2025-03-08 22:51:52,075 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.559
2025-03-08 22:51:52,749 - INFO - Resetting pretrained SAE
2025-03-08 22:53:26,777 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.5707
2025-03-08 22:53:27,021 - INFO - Resetting pretrained SAE
2025-03-08 22:55:01,068 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.5721
2025-03-08 22:55:01,320 - INFO - Resetting pretrained SAE
2025-03-08 22:56:35,600 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.5957
2025-03-08 22:56:35,858 - INFO - Resetting pretrained SAE
2025-03-08 22:58:10,387 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.6167
2025-03-08 22:58:10,602 - INFO - Resetting pretrained SAE
2025-03-08 22:59:44,570 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.5768
2025-03-08 22:59:44,809 - INFO - Resetting pretrained SAE
2025-03-08 23:01:19,021 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.5865
2025-03-08 23:01:19,468 - INFO - Resetting pretrained SAE
2025-03-08 23:02:54,069 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.5928
2025-03-08 23:02:54,321 - INFO - Resetting pretrained SAE
2025-03-08 23:04:28,331 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.6093
2025-03-08 23:04:28,556 - INFO - Resetting pretrained SAE
2025-03-08 23:06:02,605 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.6127
2025-03-08 23:06:02,834 - INFO - Resetting pretrained SAE
2025-03-08 23:07:36,656 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.6155
2025-03-08 23:07:36,887 - INFO - Resetting pretrained SAE
2025-03-08 23:07:36,890 - INFO - For layer 3, the best Sparse Ratio: 0.65 with validation loss: 2.5258
2025-03-08 23:07:54,878 - INFO - After pruning pretrained SAE, Validation loss: 2.5258, and Test loss: 2.5803
2025-03-08 23:09:34,157 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.9354, and Test loss: 3.9157
2025-03-08 23:11:13,297 - INFO - Before pruning pretrained SAE, Validation loss: 2.4924, and Test loss: 2.5374
2025-03-08 23:11:13,298 - INFO - Pruning for layer: 4
2025-03-08 23:11:13,298 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.4.hook_z
2025-03-08 23:11:13,298 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.4.attn.hook_z-attn-sae-v1
2025-03-08 23:12:47,850 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.5797
2025-03-08 23:12:48,074 - INFO - Resetting pretrained SAE
2025-03-08 23:14:22,012 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.5787
2025-03-08 23:14:22,237 - INFO - Resetting pretrained SAE
2025-03-08 23:15:56,290 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.5776
2025-03-08 23:15:56,546 - INFO - Resetting pretrained SAE
2025-03-08 23:17:30,702 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.5759
2025-03-08 23:17:30,924 - INFO - Resetting pretrained SAE
2025-03-08 23:19:04,969 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.5737
2025-03-08 23:19:05,209 - INFO - Resetting pretrained SAE
2025-03-08 23:20:39,341 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.5712
2025-03-08 23:20:39,564 - INFO - Resetting pretrained SAE
2025-03-08 23:22:13,808 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.5682
2025-03-08 23:22:14,028 - INFO - Resetting pretrained SAE
2025-03-08 23:23:48,174 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.5652
2025-03-08 23:23:48,397 - INFO - Resetting pretrained SAE
2025-03-08 23:25:22,871 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.5622
2025-03-08 23:25:23,087 - INFO - Resetting pretrained SAE
2025-03-08 23:26:57,307 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.5593
2025-03-08 23:26:57,520 - INFO - Resetting pretrained SAE
2025-03-08 23:28:31,800 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.556
2025-03-08 23:28:32,073 - INFO - Resetting pretrained SAE
2025-03-08 23:30:06,121 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.5534
2025-03-08 23:30:06,360 - INFO - Resetting pretrained SAE
2025-03-08 23:31:40,232 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.5508
2025-03-08 23:31:40,498 - INFO - Resetting pretrained SAE
2025-03-08 23:33:14,507 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.5484
2025-03-08 23:33:14,762 - INFO - Resetting pretrained SAE
2025-03-08 23:34:48,614 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.5462
2025-03-08 23:34:48,850 - INFO - Resetting pretrained SAE
2025-03-08 23:36:22,889 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.543
2025-03-08 23:36:23,117 - INFO - Resetting pretrained SAE
2025-03-08 23:37:57,243 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.5414
2025-03-08 23:37:57,462 - INFO - Resetting pretrained SAE
2025-03-08 23:39:31,903 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.5392
2025-03-08 23:39:32,181 - INFO - Resetting pretrained SAE
2025-03-08 23:41:06,337 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.5359
2025-03-08 23:41:06,564 - INFO - Resetting pretrained SAE
2025-03-08 23:42:40,602 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.5339
2025-03-08 23:42:40,811 - INFO - Resetting pretrained SAE
2025-03-08 23:44:15,190 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.5318
2025-03-08 23:44:15,414 - INFO - Resetting pretrained SAE
2025-03-08 23:45:49,465 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.53
2025-03-08 23:45:49,702 - INFO - Resetting pretrained SAE
2025-03-08 23:47:24,150 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.5279
2025-03-08 23:47:24,368 - INFO - Resetting pretrained SAE
2025-03-08 23:48:58,274 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.5264
2025-03-08 23:48:58,621 - INFO - Resetting pretrained SAE
2025-03-08 23:50:32,931 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.5247
2025-03-08 23:50:33,175 - INFO - Resetting pretrained SAE
2025-03-08 23:52:07,374 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.5228
2025-03-08 23:52:07,663 - INFO - Resetting pretrained SAE
2025-03-08 23:53:42,214 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.5208
2025-03-08 23:53:42,509 - INFO - Resetting pretrained SAE
2025-03-08 23:55:17,186 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.5191
2025-03-08 23:55:17,401 - INFO - Resetting pretrained SAE
2025-03-08 23:56:51,685 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.5169
2025-03-08 23:56:51,908 - INFO - Resetting pretrained SAE
2025-03-08 23:58:26,006 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.5145
2025-03-08 23:58:26,448 - INFO - Resetting pretrained SAE
2025-03-09 00:00:00,342 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.5126
2025-03-09 00:00:00,637 - INFO - Resetting pretrained SAE
2025-03-09 00:01:34,847 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.5103
2025-03-09 00:01:35,120 - INFO - Resetting pretrained SAE
2025-03-09 00:03:09,487 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.5083
2025-03-09 00:03:09,709 - INFO - Resetting pretrained SAE
2025-03-09 00:04:43,894 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.5065
2025-03-09 00:04:44,112 - INFO - Resetting pretrained SAE
2025-03-09 00:06:18,277 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.5053
2025-03-09 00:06:20,089 - INFO - Resetting pretrained SAE
2025-03-09 00:07:54,142 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.504
2025-03-09 00:07:54,354 - INFO - Resetting pretrained SAE
2025-03-09 00:09:28,521 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.5023
2025-03-09 00:09:28,740 - INFO - Resetting pretrained SAE
2025-03-09 00:11:03,087 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.5012
2025-03-09 00:11:03,304 - INFO - Resetting pretrained SAE
2025-03-09 00:11:03,307 - INFO - For layer 4, the best Sparse Ratio: 0.25 with validation loss: 2.5012
2025-03-09 00:11:21,374 - INFO - After pruning pretrained SAE, Validation loss: 2.5012, and Test loss: 2.546
2025-03-09 00:12:59,831 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.4718, and Test loss: 2.5178
2025-03-09 00:14:42,387 - INFO - Before pruning pretrained SAE, Validation loss: 2.7078, and Test loss: 2.756
2025-03-09 00:14:42,388 - INFO - Pruning for layer: 5
2025-03-09 00:14:42,388 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.5.hook_z
2025-03-09 00:14:42,388 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.5.attn.hook_z-attn-sae-v1
2025-03-09 00:16:20,560 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.631
2025-03-09 00:16:20,920 - INFO - Resetting pretrained SAE
2025-03-09 00:17:59,033 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 3.082
2025-03-09 00:17:59,379 - INFO - Resetting pretrained SAE
2025-03-09 00:19:37,624 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 3.4841
2025-03-09 00:19:38,075 - INFO - Resetting pretrained SAE
2025-03-09 00:21:16,360 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 3.303
2025-03-09 00:21:16,703 - INFO - Resetting pretrained SAE
2025-03-09 00:22:54,434 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 3.9069
2025-03-09 00:22:54,776 - INFO - Resetting pretrained SAE
2025-03-09 00:24:32,849 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 4.1947
2025-03-09 00:24:33,212 - INFO - Resetting pretrained SAE
2025-03-09 00:26:11,705 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 3.7548
2025-03-09 00:26:12,045 - INFO - Resetting pretrained SAE
2025-03-09 00:27:50,317 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 3.7474
2025-03-09 00:27:50,769 - INFO - Resetting pretrained SAE
2025-03-09 00:29:28,996 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 3.8346
2025-03-09 00:29:29,346 - INFO - Resetting pretrained SAE
2025-03-09 00:31:07,648 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 3.9862
2025-03-09 00:31:08,101 - INFO - Resetting pretrained SAE
2025-03-09 00:32:46,274 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 3.8151
2025-03-09 00:32:46,620 - INFO - Resetting pretrained SAE
2025-03-09 00:34:24,687 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 4.0047
2025-03-09 00:34:25,077 - INFO - Resetting pretrained SAE
2025-03-09 00:36:03,173 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 3.9164
2025-03-09 00:36:03,518 - INFO - Resetting pretrained SAE
2025-03-09 00:37:41,356 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 3.94
2025-03-09 00:37:41,707 - INFO - Resetting pretrained SAE
2025-03-09 00:39:20,046 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 4.0048
2025-03-09 00:39:20,358 - INFO - Resetting pretrained SAE
2025-03-09 00:40:58,588 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 4.0416
2025-03-09 00:40:59,039 - INFO - Resetting pretrained SAE
2025-03-09 00:42:37,217 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 3.8981
2025-03-09 00:42:37,574 - INFO - Resetting pretrained SAE
2025-03-09 00:44:16,138 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 4.0733
2025-03-09 00:44:16,547 - INFO - Resetting pretrained SAE
2025-03-09 00:45:55,067 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 4.1501
2025-03-09 00:45:55,432 - INFO - Resetting pretrained SAE
2025-03-09 00:47:33,467 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 4.05
2025-03-09 00:47:33,885 - INFO - Resetting pretrained SAE
2025-03-09 00:49:11,561 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 3.9979
2025-03-09 00:49:11,959 - INFO - Resetting pretrained SAE
2025-03-09 00:50:50,055 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 3.9937
2025-03-09 00:50:50,390 - INFO - Resetting pretrained SAE
2025-03-09 00:52:28,817 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 4.0171
2025-03-09 00:52:29,202 - INFO - Resetting pretrained SAE
2025-03-09 00:54:07,772 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 3.8976
2025-03-09 00:54:08,132 - INFO - Resetting pretrained SAE
2025-03-09 00:55:46,061 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 3.9692
2025-03-09 00:55:46,438 - INFO - Resetting pretrained SAE
2025-03-09 00:57:24,852 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 3.8877
2025-03-09 00:57:25,215 - INFO - Resetting pretrained SAE
2025-03-09 00:59:03,548 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 3.9483
2025-03-09 00:59:03,887 - INFO - Resetting pretrained SAE
2025-03-09 01:00:42,192 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 3.9093
2025-03-09 01:00:42,683 - INFO - Resetting pretrained SAE
2025-03-09 01:02:20,589 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 3.8755
2025-03-09 01:02:20,923 - INFO - Resetting pretrained SAE
2025-03-09 01:03:58,644 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 4.0794
2025-03-09 01:03:58,977 - INFO - Resetting pretrained SAE
2025-03-09 01:05:37,384 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 3.8334
2025-03-09 01:05:37,718 - INFO - Resetting pretrained SAE
2025-03-09 01:07:15,622 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 3.637
2025-03-09 01:07:16,025 - INFO - Resetting pretrained SAE
2025-03-09 01:08:54,445 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 3.7655
2025-03-09 01:08:54,897 - INFO - Resetting pretrained SAE
2025-03-09 01:10:32,716 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 3.5978
2025-03-09 01:10:33,050 - INFO - Resetting pretrained SAE
2025-03-09 01:12:11,577 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 3.1632
2025-03-09 01:12:11,928 - INFO - Resetting pretrained SAE
2025-03-09 01:13:49,884 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 3.0706
2025-03-09 01:13:50,312 - INFO - Resetting pretrained SAE
2025-03-09 01:15:28,745 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.9655
2025-03-09 01:15:29,090 - INFO - Resetting pretrained SAE
2025-03-09 01:17:07,622 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 3.0062
2025-03-09 01:17:07,988 - INFO - Resetting pretrained SAE
2025-03-09 01:17:07,992 - INFO - For layer 5, the best Sparse Ratio: 0.99 with validation loss: 2.631
2025-03-09 01:17:26,110 - INFO - After pruning pretrained SAE, Validation loss: 2.631, and Test loss: 2.7818
2025-03-09 01:19:04,598 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.9069, and Test loss: 2.9467
2025-03-09 01:20:43,722 - INFO - Before pruning pretrained SAE, Validation loss: 2.4586, and Test loss: 2.5048
2025-03-09 01:20:43,723 - INFO - Pruning for layer: 6
2025-03-09 01:20:43,723 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.6.hook_z
2025-03-09 01:20:43,723 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.6.attn.hook_z-attn-sae-v1
2025-03-09 01:22:18,530 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.5602
2025-03-09 01:22:18,826 - INFO - Resetting pretrained SAE
2025-03-09 01:23:53,226 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.5601
2025-03-09 01:23:53,443 - INFO - Resetting pretrained SAE
2025-03-09 01:25:27,839 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.5574
2025-03-09 01:25:28,099 - INFO - Resetting pretrained SAE
2025-03-09 01:27:01,808 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.5498
2025-03-09 01:27:02,038 - INFO - Resetting pretrained SAE
2025-03-09 01:28:36,240 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.5501
2025-03-09 01:28:36,470 - INFO - Resetting pretrained SAE
2025-03-09 01:30:10,403 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.5499
2025-03-09 01:30:10,631 - INFO - Resetting pretrained SAE
2025-03-09 01:31:45,145 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.54
2025-03-09 01:31:45,369 - INFO - Resetting pretrained SAE
2025-03-09 01:33:18,986 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.5364
2025-03-09 01:33:19,211 - INFO - Resetting pretrained SAE
2025-03-09 01:34:53,780 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.5357
2025-03-09 01:34:54,029 - INFO - Resetting pretrained SAE
2025-03-09 01:36:28,524 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.5315
2025-03-09 01:36:28,748 - INFO - Resetting pretrained SAE
2025-03-09 01:38:02,688 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.5327
2025-03-09 01:38:02,937 - INFO - Resetting pretrained SAE
2025-03-09 01:39:36,914 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.532
2025-03-09 01:39:37,133 - INFO - Resetting pretrained SAE
2025-03-09 01:41:11,012 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.5324
2025-03-09 01:41:11,224 - INFO - Resetting pretrained SAE
2025-03-09 01:42:45,804 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.5302
2025-03-09 01:42:46,039 - INFO - Resetting pretrained SAE
2025-03-09 01:44:19,610 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.5271
2025-03-09 01:44:19,831 - INFO - Resetting pretrained SAE
2025-03-09 01:45:54,009 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.5272
2025-03-09 01:45:54,316 - INFO - Resetting pretrained SAE
2025-03-09 01:47:27,956 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.5259
2025-03-09 01:47:28,161 - INFO - Resetting pretrained SAE
2025-03-09 01:49:02,293 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.525
2025-03-09 01:49:02,510 - INFO - Resetting pretrained SAE
2025-03-09 01:50:36,719 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.5233
2025-03-09 01:50:36,942 - INFO - Resetting pretrained SAE
2025-03-09 01:52:10,744 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.5196
2025-03-09 01:52:10,963 - INFO - Resetting pretrained SAE
2025-03-09 01:53:45,074 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.5139
2025-03-09 01:53:45,327 - INFO - Resetting pretrained SAE
2025-03-09 01:55:19,796 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.5152
2025-03-09 01:55:20,019 - INFO - Resetting pretrained SAE
2025-03-09 01:56:54,211 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.5118
2025-03-09 01:56:54,428 - INFO - Resetting pretrained SAE
2025-03-09 01:58:28,737 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.506
2025-03-09 01:58:28,953 - INFO - Resetting pretrained SAE
2025-03-09 03:00:03,812 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.5059
2025-03-09 03:00:04,022 - INFO - Resetting pretrained SAE
2025-03-09 03:01:38,544 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.5026
2025-03-09 03:01:38,740 - INFO - Resetting pretrained SAE
2025-03-09 03:03:12,881 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.5013
2025-03-09 03:03:13,459 - INFO - Resetting pretrained SAE
2025-03-09 03:04:47,887 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.4971
2025-03-09 03:04:48,140 - INFO - Resetting pretrained SAE
2025-03-09 03:06:22,439 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.4928
2025-03-09 03:06:22,653 - INFO - Resetting pretrained SAE
2025-03-09 03:07:57,452 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.4919
2025-03-09 03:07:57,782 - INFO - Resetting pretrained SAE
2025-03-09 03:09:32,641 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.4868
2025-03-09 03:09:32,850 - INFO - Resetting pretrained SAE
2025-03-09 03:11:06,849 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.4832
2025-03-09 03:11:07,073 - INFO - Resetting pretrained SAE
2025-03-09 03:12:41,519 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.4791
2025-03-09 03:12:41,999 - INFO - Resetting pretrained SAE
2025-03-09 03:14:16,097 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.4765
2025-03-09 03:14:16,347 - INFO - Resetting pretrained SAE
2025-03-09 03:15:50,664 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.4748
2025-03-09 03:15:50,883 - INFO - Resetting pretrained SAE
2025-03-09 03:17:25,064 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.4709
2025-03-09 03:17:25,266 - INFO - Resetting pretrained SAE
2025-03-09 03:18:59,316 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.4689
2025-03-09 03:18:59,747 - INFO - Resetting pretrained SAE
2025-03-09 03:20:34,215 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.4673
2025-03-09 03:20:34,441 - INFO - Resetting pretrained SAE
2025-03-09 03:20:34,444 - INFO - For layer 6, the best Sparse Ratio: 0.25 with validation loss: 2.4673
2025-03-09 03:20:52,245 - INFO - After pruning pretrained SAE, Validation loss: 2.4673, and Test loss: 2.5133
2025-03-09 03:22:31,214 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.8322, and Test loss: 3.8981
2025-03-09 03:24:14,545 - INFO - Before pruning pretrained SAE, Validation loss: 2.4442, and Test loss: 2.49
2025-03-09 03:24:14,546 - INFO - Pruning for layer: 7
2025-03-09 03:24:14,546 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.7.hook_z
2025-03-09 03:24:14,546 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.7.attn.hook_z-attn-sae-v1
2025-03-09 03:25:52,495 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.6316
2025-03-09 03:25:52,837 - INFO - Resetting pretrained SAE
2025-03-09 03:27:31,291 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.6564
2025-03-09 03:27:31,693 - INFO - Resetting pretrained SAE
2025-03-09 03:29:10,191 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.7011
2025-03-09 03:29:10,539 - INFO - Resetting pretrained SAE
2025-03-09 03:30:48,978 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.6614
2025-03-09 03:30:49,329 - INFO - Resetting pretrained SAE
2025-03-09 03:32:27,409 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.6953
2025-03-09 03:32:27,744 - INFO - Resetting pretrained SAE
2025-03-09 03:34:05,836 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.7225
2025-03-09 03:34:06,140 - INFO - Resetting pretrained SAE
2025-03-09 03:35:43,967 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.7014
2025-03-09 03:35:44,305 - INFO - Resetting pretrained SAE
2025-03-09 03:37:22,290 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.7212
2025-03-09 03:37:22,703 - INFO - Resetting pretrained SAE
2025-03-09 03:39:00,513 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.6857
2025-03-09 03:39:00,845 - INFO - Resetting pretrained SAE
2025-03-09 03:40:38,963 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.8413
2025-03-09 03:40:39,301 - INFO - Resetting pretrained SAE
2025-03-09 03:42:17,398 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.6946
2025-03-09 03:42:17,735 - INFO - Resetting pretrained SAE
2025-03-09 03:43:55,631 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.6625
2025-03-09 03:43:55,975 - INFO - Resetting pretrained SAE
2025-03-09 03:45:34,179 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.7427
2025-03-09 03:45:34,518 - INFO - Resetting pretrained SAE
2025-03-09 03:47:12,566 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.7036
2025-03-09 03:47:12,980 - INFO - Resetting pretrained SAE
2025-03-09 03:48:51,249 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.8383
2025-03-09 03:48:51,591 - INFO - Resetting pretrained SAE
2025-03-09 03:50:29,593 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.6864
2025-03-09 03:50:30,025 - INFO - Resetting pretrained SAE
2025-03-09 03:52:08,181 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.8044
2025-03-09 03:52:08,520 - INFO - Resetting pretrained SAE
2025-03-09 03:53:46,480 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.8599
2025-03-09 03:53:46,797 - INFO - Resetting pretrained SAE
2025-03-09 03:55:24,653 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9166
2025-03-09 03:55:25,000 - INFO - Resetting pretrained SAE
2025-03-09 03:57:03,088 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9194
2025-03-09 03:57:03,422 - INFO - Resetting pretrained SAE
2025-03-09 03:58:41,405 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.9207
2025-03-09 03:58:41,750 - INFO - Resetting pretrained SAE
2025-03-09 04:00:20,520 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 3.0088
2025-03-09 04:00:20,862 - INFO - Resetting pretrained SAE
2025-03-09 04:01:59,181 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.7565
2025-03-09 04:01:59,528 - INFO - Resetting pretrained SAE
2025-03-09 04:03:37,863 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.7369
2025-03-09 04:03:38,260 - INFO - Resetting pretrained SAE
2025-03-09 04:05:16,646 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.7578
2025-03-09 04:05:17,017 - INFO - Resetting pretrained SAE
2025-03-09 04:06:55,300 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.7608
2025-03-09 04:06:55,642 - INFO - Resetting pretrained SAE
2025-03-09 04:08:33,573 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.8239
2025-03-09 04:08:33,917 - INFO - Resetting pretrained SAE
2025-03-09 04:10:11,791 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.5528
2025-03-09 04:10:12,105 - INFO - Resetting pretrained SAE
2025-03-09 04:11:50,473 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.6434
2025-03-09 04:11:50,816 - INFO - Resetting pretrained SAE
2025-03-09 04:13:29,102 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.7004
2025-03-09 04:13:29,445 - INFO - Resetting pretrained SAE
2025-03-09 04:15:07,238 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.5196
2025-03-09 04:15:07,571 - INFO - Resetting pretrained SAE
2025-03-09 04:16:45,371 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.5206
2025-03-09 04:16:45,709 - INFO - Resetting pretrained SAE
2025-03-09 04:18:24,063 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.5143
2025-03-09 04:18:24,397 - INFO - Resetting pretrained SAE
2025-03-09 04:20:02,899 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.5263
2025-03-09 04:20:03,272 - INFO - Resetting pretrained SAE
2025-03-09 04:21:41,476 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.5163
2025-03-09 04:21:41,788 - INFO - Resetting pretrained SAE
2025-03-09 04:23:19,604 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.5103
2025-03-09 04:23:19,948 - INFO - Resetting pretrained SAE
2025-03-09 04:24:58,076 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.4925
2025-03-09 04:24:58,415 - INFO - Resetting pretrained SAE
2025-03-09 04:26:36,469 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.484
2025-03-09 04:26:36,799 - INFO - Resetting pretrained SAE
2025-03-09 04:26:36,805 - INFO - For layer 7, the best Sparse Ratio: 0.25 with validation loss: 2.484
2025-03-09 04:26:55,173 - INFO - After pruning pretrained SAE, Validation loss: 2.484, and Test loss: 2.5261
2025-03-09 04:28:34,011 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.017, and Test loss: 3.0618
2025-03-09 04:30:12,592 - INFO - Before pruning pretrained SAE, Validation loss: 2.4159, and Test loss: 2.4623
2025-03-09 04:30:12,592 - INFO - Pruning for layer: 8
2025-03-09 04:30:12,592 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.8.hook_z
2025-03-09 04:30:12,592 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.8.attn.hook_z-attn-sae-v1
2025-03-09 04:31:47,024 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.4513
2025-03-09 04:31:47,248 - INFO - Resetting pretrained SAE
2025-03-09 04:33:21,124 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.4512
2025-03-09 04:33:21,359 - INFO - Resetting pretrained SAE
2025-03-09 04:34:55,041 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.4503
2025-03-09 04:34:55,273 - INFO - Resetting pretrained SAE
2025-03-09 04:36:29,113 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.4499
2025-03-09 04:36:29,363 - INFO - Resetting pretrained SAE
2025-03-09 04:38:03,644 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.4505
2025-03-09 04:38:03,879 - INFO - Resetting pretrained SAE
2025-03-09 04:39:38,470 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.4492
2025-03-09 04:39:38,687 - INFO - Resetting pretrained SAE
2025-03-09 04:41:12,999 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.4491
2025-03-09 04:41:13,460 - INFO - Resetting pretrained SAE
2025-03-09 04:42:47,408 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.448
2025-03-09 04:42:47,609 - INFO - Resetting pretrained SAE
2025-03-09 04:44:21,813 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.4465
2025-03-09 04:44:22,054 - INFO - Resetting pretrained SAE
2025-03-09 04:45:56,192 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.4458
2025-03-09 04:45:56,386 - INFO - Resetting pretrained SAE
2025-03-09 04:47:30,220 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.4439
2025-03-09 04:47:30,431 - INFO - Resetting pretrained SAE
2025-03-09 04:49:04,298 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.4434
2025-03-09 04:49:04,514 - INFO - Resetting pretrained SAE
2025-03-09 04:50:39,120 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.442
2025-03-09 04:50:39,329 - INFO - Resetting pretrained SAE
2025-03-09 04:52:12,986 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.4408
2025-03-09 04:52:13,200 - INFO - Resetting pretrained SAE
2025-03-09 04:53:47,117 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.4408
2025-03-09 04:53:47,371 - INFO - Resetting pretrained SAE
2025-03-09 04:55:21,483 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.4407
2025-03-09 04:55:21,701 - INFO - Resetting pretrained SAE
2025-03-09 04:56:56,046 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.4405
2025-03-09 04:56:56,298 - INFO - Resetting pretrained SAE
2025-03-09 04:58:30,425 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.4389
2025-03-09 04:58:30,637 - INFO - Resetting pretrained SAE
2025-03-09 05:00:04,384 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.4387
2025-03-09 05:00:04,603 - INFO - Resetting pretrained SAE
2025-03-09 05:01:39,326 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.4379
2025-03-09 05:01:39,531 - INFO - Resetting pretrained SAE
2025-03-09 05:03:13,451 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.4378
2025-03-09 05:03:13,687 - INFO - Resetting pretrained SAE
2025-03-09 05:04:48,802 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.4374
2025-03-09 05:04:49,038 - INFO - Resetting pretrained SAE
2025-03-09 05:06:22,869 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.4354
2025-03-09 05:06:23,103 - INFO - Resetting pretrained SAE
2025-03-09 05:07:57,645 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.4351
2025-03-09 05:07:57,857 - INFO - Resetting pretrained SAE
2025-03-09 05:09:32,511 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.4351
2025-03-09 05:09:32,831 - INFO - Resetting pretrained SAE
2025-03-09 05:11:07,219 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.4334
2025-03-09 05:11:07,439 - INFO - Resetting pretrained SAE
2025-03-09 05:12:41,879 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.4328
2025-03-09 05:12:42,849 - INFO - Resetting pretrained SAE
2025-03-09 05:14:16,967 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.4318
2025-03-09 05:14:17,182 - INFO - Resetting pretrained SAE
2025-03-09 05:15:51,929 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.4303
2025-03-09 05:15:52,128 - INFO - Resetting pretrained SAE
2025-03-09 05:17:26,676 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.4296
2025-03-09 05:17:26,892 - INFO - Resetting pretrained SAE
2025-03-09 05:19:01,432 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.4281
2025-03-09 05:19:01,749 - INFO - Resetting pretrained SAE
2025-03-09 05:20:36,187 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.4269
2025-03-09 05:20:36,556 - INFO - Resetting pretrained SAE
2025-03-09 05:22:10,687 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.4262
2025-03-09 05:22:10,882 - INFO - Resetting pretrained SAE
2025-03-09 05:23:45,053 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.4243
2025-03-09 05:23:45,337 - INFO - Resetting pretrained SAE
2025-03-09 05:25:19,418 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.4237
2025-03-09 05:25:19,632 - INFO - Resetting pretrained SAE
2025-03-09 05:26:53,801 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.4223
2025-03-09 05:26:54,019 - INFO - Resetting pretrained SAE
2025-03-09 05:28:28,679 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.4215
2025-03-09 05:28:28,902 - INFO - Resetting pretrained SAE
2025-03-09 05:30:03,125 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.4201
2025-03-09 05:30:03,362 - INFO - Resetting pretrained SAE
2025-03-09 05:30:03,365 - INFO - For layer 8, the best Sparse Ratio: 0.25 with validation loss: 2.4201
2025-03-09 05:30:21,246 - INFO - After pruning pretrained SAE, Validation loss: 2.4201, and Test loss: 2.4668
2025-03-09 05:31:59,671 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.7542, and Test loss: 3.8359
2025-03-09 05:33:38,709 - INFO - Before pruning pretrained SAE, Validation loss: 2.4179, and Test loss: 2.4643
2025-03-09 05:33:38,709 - INFO - Pruning for layer: 9
2025-03-09 05:33:38,710 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.9.hook_z
2025-03-09 05:33:38,710 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.9.attn.hook_z-attn-sae-v1
2025-03-09 05:35:13,048 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.5331
2025-03-09 05:35:13,265 - INFO - Resetting pretrained SAE
2025-03-09 05:36:46,743 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.5332
2025-03-09 05:36:46,966 - INFO - Resetting pretrained SAE
2025-03-09 05:38:21,029 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.5318
2025-03-09 05:38:21,232 - INFO - Resetting pretrained SAE
2025-03-09 05:39:55,342 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.5343
2025-03-09 05:39:55,565 - INFO - Resetting pretrained SAE
2025-03-09 05:41:29,275 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.5319
2025-03-09 05:41:29,494 - INFO - Resetting pretrained SAE
2025-03-09 05:43:03,280 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.5341
2025-03-09 05:43:03,529 - INFO - Resetting pretrained SAE
2025-03-09 05:44:38,066 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.5335
2025-03-09 05:44:38,300 - INFO - Resetting pretrained SAE
2025-03-09 05:46:12,239 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.536
2025-03-09 05:46:12,591 - INFO - Resetting pretrained SAE
2025-03-09 05:47:47,110 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.5387
2025-03-09 05:47:47,325 - INFO - Resetting pretrained SAE
2025-03-09 05:49:21,586 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.5439
2025-03-09 05:49:21,811 - INFO - Resetting pretrained SAE
2025-03-09 05:50:55,549 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.5344
2025-03-09 05:50:55,782 - INFO - Resetting pretrained SAE
2025-03-09 05:52:29,355 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.5332
2025-03-09 05:52:30,396 - INFO - Resetting pretrained SAE
2025-03-09 05:54:04,567 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.5342
2025-03-09 05:54:04,790 - INFO - Resetting pretrained SAE
2025-03-09 05:55:38,678 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.5342
2025-03-09 05:55:39,045 - INFO - Resetting pretrained SAE
2025-03-09 05:57:13,266 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.537
2025-03-09 05:57:13,492 - INFO - Resetting pretrained SAE
2025-03-09 05:58:47,632 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.5346
2025-03-09 05:58:47,823 - INFO - Resetting pretrained SAE
2025-03-09 06:00:22,385 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.5358
2025-03-09 06:00:22,608 - INFO - Resetting pretrained SAE
2025-03-09 06:01:56,879 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.5315
2025-03-09 06:01:57,173 - INFO - Resetting pretrained SAE
2025-03-09 06:03:31,560 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.5323
2025-03-09 06:03:31,761 - INFO - Resetting pretrained SAE
2025-03-09 06:05:05,976 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.5319
2025-03-09 06:05:06,186 - INFO - Resetting pretrained SAE
2025-03-09 06:06:40,357 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.5317
2025-03-09 06:06:40,589 - INFO - Resetting pretrained SAE
2025-03-09 06:08:14,969 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.5364
2025-03-09 06:08:15,204 - INFO - Resetting pretrained SAE
2025-03-09 06:09:49,874 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.5299
2025-03-09 06:09:50,111 - INFO - Resetting pretrained SAE
2025-03-09 06:11:24,380 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.5384
2025-03-09 06:11:24,717 - INFO - Resetting pretrained SAE
2025-03-09 06:12:59,369 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.5107
2025-03-09 06:12:59,622 - INFO - Resetting pretrained SAE
2025-03-09 06:14:34,576 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.4895
2025-03-09 06:14:34,807 - INFO - Resetting pretrained SAE
2025-03-09 06:16:09,276 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.4697
2025-03-09 06:16:09,530 - INFO - Resetting pretrained SAE
2025-03-09 06:17:43,974 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.4669
2025-03-09 06:17:44,201 - INFO - Resetting pretrained SAE
2025-03-09 06:19:18,213 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.4634
2025-03-09 06:19:18,422 - INFO - Resetting pretrained SAE
2025-03-09 06:20:53,395 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.4522
2025-03-09 06:20:53,618 - INFO - Resetting pretrained SAE
2025-03-09 06:22:28,347 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.4494
2025-03-09 06:22:28,621 - INFO - Resetting pretrained SAE
2025-03-09 06:24:03,171 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.4469
2025-03-09 06:24:03,386 - INFO - Resetting pretrained SAE
2025-03-09 06:25:37,920 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.4473
2025-03-09 06:25:38,153 - INFO - Resetting pretrained SAE
2025-03-09 06:27:12,362 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.4419
2025-03-09 06:27:12,580 - INFO - Resetting pretrained SAE
2025-03-09 06:28:47,033 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.4376
2025-03-09 06:28:47,282 - INFO - Resetting pretrained SAE
2025-03-09 06:30:21,833 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.4341
2025-03-09 06:30:22,195 - INFO - Resetting pretrained SAE
2025-03-09 06:31:56,304 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.4313
2025-03-09 06:31:56,557 - INFO - Resetting pretrained SAE
2025-03-09 06:33:30,540 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.4285
2025-03-09 06:33:30,753 - INFO - Resetting pretrained SAE
2025-03-09 06:33:30,756 - INFO - For layer 9, the best Sparse Ratio: 0.25 with validation loss: 2.4285
2025-03-09 06:33:48,577 - INFO - After pruning pretrained SAE, Validation loss: 2.4285, and Test loss: 2.4739
2025-03-09 06:35:26,740 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.4083, and Test loss: 2.4557
2025-03-09 06:37:04,614 - INFO - Before pruning pretrained SAE, Validation loss: 2.4151, and Test loss: 2.4615
2025-03-09 06:37:04,615 - INFO - Pruning for layer: 10
2025-03-09 06:37:04,615 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.10.hook_z
2025-03-09 06:37:04,615 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.10.attn.hook_z-attn-sae-v1
2025-03-09 06:38:38,011 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.4646
2025-03-09 06:38:38,242 - INFO - Resetting pretrained SAE
2025-03-09 06:40:11,592 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.4646
2025-03-09 06:40:11,824 - INFO - Resetting pretrained SAE
2025-03-09 06:41:45,564 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.4644
2025-03-09 06:41:45,766 - INFO - Resetting pretrained SAE
2025-03-09 06:43:19,173 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.4644
2025-03-09 06:43:19,548 - INFO - Resetting pretrained SAE
2025-03-09 06:44:53,233 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.4643
2025-03-09 06:44:53,444 - INFO - Resetting pretrained SAE
2025-03-09 06:46:27,223 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.4644
2025-03-09 06:46:27,451 - INFO - Resetting pretrained SAE
2025-03-09 06:48:00,695 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.4644
2025-03-09 06:48:00,943 - INFO - Resetting pretrained SAE
2025-03-09 06:49:34,298 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.4643
2025-03-09 06:49:34,558 - INFO - Resetting pretrained SAE
2025-03-09 06:51:08,352 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.4662
2025-03-09 06:51:08,587 - INFO - Resetting pretrained SAE
2025-03-09 06:52:42,759 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.467
2025-03-09 06:52:42,977 - INFO - Resetting pretrained SAE
2025-03-09 06:54:16,352 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.4656
2025-03-09 06:54:16,561 - INFO - Resetting pretrained SAE
2025-03-09 06:55:50,170 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.4665
2025-03-09 06:55:50,369 - INFO - Resetting pretrained SAE
2025-03-09 06:57:23,990 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.4674
2025-03-09 06:57:24,204 - INFO - Resetting pretrained SAE
2025-03-09 06:58:57,681 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.4702
2025-03-09 06:58:57,885 - INFO - Resetting pretrained SAE
2025-03-09 07:00:31,996 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.4674
2025-03-09 07:00:32,273 - INFO - Resetting pretrained SAE
2025-03-09 07:02:05,818 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.4689
2025-03-09 07:02:06,219 - INFO - Resetting pretrained SAE
2025-03-09 07:03:39,619 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.4696
2025-03-09 07:03:39,898 - INFO - Resetting pretrained SAE
2025-03-09 07:05:13,361 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.4688
2025-03-09 07:05:13,598 - INFO - Resetting pretrained SAE
2025-03-09 07:06:47,168 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.4671
2025-03-09 07:06:47,481 - INFO - Resetting pretrained SAE
2025-03-09 07:08:21,308 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.4713
2025-03-09 07:08:21,528 - INFO - Resetting pretrained SAE
2025-03-09 07:09:55,222 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.4684
2025-03-09 07:09:55,435 - INFO - Resetting pretrained SAE
2025-03-09 07:11:29,130 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.4662
2025-03-09 07:11:29,346 - INFO - Resetting pretrained SAE
2025-03-09 07:13:03,021 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.4638
2025-03-09 07:13:03,231 - INFO - Resetting pretrained SAE
2025-03-09 07:14:36,606 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.4639
2025-03-09 07:14:36,804 - INFO - Resetting pretrained SAE
2025-03-09 07:16:10,676 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.4618
2025-03-09 07:16:10,911 - INFO - Resetting pretrained SAE
2025-03-09 07:17:44,378 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.461
2025-03-09 07:17:44,596 - INFO - Resetting pretrained SAE
2025-03-09 07:19:18,021 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.4603
2025-03-09 07:19:18,905 - INFO - Resetting pretrained SAE
2025-03-09 07:20:52,597 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.4605
2025-03-09 07:20:52,828 - INFO - Resetting pretrained SAE
2025-03-09 07:22:26,477 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.4599
2025-03-09 07:22:26,673 - INFO - Resetting pretrained SAE
2025-03-09 07:24:00,379 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.4546
2025-03-09 07:24:00,598 - INFO - Resetting pretrained SAE
2025-03-09 07:25:33,783 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.4509
2025-03-09 07:25:33,992 - INFO - Resetting pretrained SAE
2025-03-09 07:27:07,744 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.4493
2025-03-09 07:27:08,025 - INFO - Resetting pretrained SAE
2025-03-09 07:28:41,895 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.4485
2025-03-09 07:28:42,105 - INFO - Resetting pretrained SAE
2025-03-09 07:30:15,889 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.4436
2025-03-09 07:30:16,102 - INFO - Resetting pretrained SAE
2025-03-09 07:31:49,769 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.4413
2025-03-09 07:31:50,265 - INFO - Resetting pretrained SAE
2025-03-09 07:33:23,905 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.4384
2025-03-09 07:33:24,132 - INFO - Resetting pretrained SAE
2025-03-09 07:34:57,850 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.4348
2025-03-09 07:34:58,068 - INFO - Resetting pretrained SAE
2025-03-09 07:36:31,793 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.4318
2025-03-09 07:36:32,011 - INFO - Resetting pretrained SAE
2025-03-09 07:36:32,014 - INFO - For layer 10, the best Sparse Ratio: 0.25 with validation loss: 2.4318
2025-03-09 07:36:49,910 - INFO - After pruning pretrained SAE, Validation loss: 2.4318, and Test loss: 2.4775
2025-03-09 07:38:28,410 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.3948, and Test loss: 2.4414
2025-03-09 07:40:06,305 - INFO - Before pruning pretrained SAE, Validation loss: 2.428, and Test loss: 2.474
2025-03-09 07:40:06,306 - INFO - Pruning for layer: 11
2025-03-09 07:40:06,306 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.11.hook_z
2025-03-09 07:40:06,306 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.11.attn.hook_z-attn-sae-v1
2025-03-09 07:41:40,006 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.4582
2025-03-09 07:41:40,234 - INFO - Resetting pretrained SAE
2025-03-09 07:43:13,816 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.4578
2025-03-09 07:43:14,066 - INFO - Resetting pretrained SAE
2025-03-09 07:44:47,543 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.4629
2025-03-09 07:44:47,836 - INFO - Resetting pretrained SAE
2025-03-09 07:46:21,252 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.4658
2025-03-09 07:46:21,779 - INFO - Resetting pretrained SAE
2025-03-09 07:47:55,969 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.464
2025-03-09 07:47:56,201 - INFO - Resetting pretrained SAE
2025-03-09 07:49:30,074 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.4658
2025-03-09 07:49:30,366 - INFO - Resetting pretrained SAE
2025-03-09 07:51:04,223 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.4653
2025-03-09 07:51:04,443 - INFO - Resetting pretrained SAE
2025-03-09 07:52:38,194 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.4584
2025-03-09 07:52:38,409 - INFO - Resetting pretrained SAE
2025-03-09 07:54:12,054 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.4602
2025-03-09 07:54:12,267 - INFO - Resetting pretrained SAE
2025-03-09 07:55:46,705 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.4582
2025-03-09 07:55:46,906 - INFO - Resetting pretrained SAE
2025-03-09 07:57:20,987 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.4575
2025-03-09 07:57:21,232 - INFO - Resetting pretrained SAE
2025-03-09 07:58:55,165 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.4581
2025-03-09 07:58:55,387 - INFO - Resetting pretrained SAE
2025-03-09 08:00:29,279 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.4616
2025-03-09 08:00:29,554 - INFO - Resetting pretrained SAE
2025-03-09 08:02:03,403 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.4609
2025-03-09 08:02:03,623 - INFO - Resetting pretrained SAE
2025-03-09 08:03:37,211 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.4617
2025-03-09 08:03:37,468 - INFO - Resetting pretrained SAE
2025-03-09 08:05:11,050 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.4597
2025-03-09 08:05:11,269 - INFO - Resetting pretrained SAE
2025-03-09 08:06:44,998 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.4599
2025-03-09 08:06:45,386 - INFO - Resetting pretrained SAE
2025-03-09 08:08:18,989 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.4588
2025-03-09 08:08:19,227 - INFO - Resetting pretrained SAE
2025-03-09 08:09:53,209 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.46
2025-03-09 08:09:53,471 - INFO - Resetting pretrained SAE
2025-03-09 08:11:27,246 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.4586
2025-03-09 08:11:27,476 - INFO - Resetting pretrained SAE
2025-03-09 08:13:01,262 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.4579
2025-03-09 08:13:01,493 - INFO - Resetting pretrained SAE
2025-03-09 08:14:35,149 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.4589
2025-03-09 08:14:35,364 - INFO - Resetting pretrained SAE
2025-03-09 08:16:09,056 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.4603
2025-03-09 08:16:09,330 - INFO - Resetting pretrained SAE
2025-03-09 08:17:43,082 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.4594
2025-03-09 08:17:43,281 - INFO - Resetting pretrained SAE
2025-03-09 08:19:17,045 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.4611
2025-03-09 08:19:17,279 - INFO - Resetting pretrained SAE
2025-03-09 08:20:50,757 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.4603
2025-03-09 08:20:50,996 - INFO - Resetting pretrained SAE
2025-03-09 08:22:24,909 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.4605
2025-03-09 08:22:25,130 - INFO - Resetting pretrained SAE
2025-03-09 08:23:59,070 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.4609
2025-03-09 08:23:59,279 - INFO - Resetting pretrained SAE
2025-03-09 08:25:33,419 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.4587
2025-03-09 08:25:33,655 - INFO - Resetting pretrained SAE
2025-03-09 08:27:07,708 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.4573
2025-03-09 08:27:07,934 - INFO - Resetting pretrained SAE
2025-03-09 08:28:41,597 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.4628
2025-03-09 08:28:41,819 - INFO - Resetting pretrained SAE
2025-03-09 08:30:15,349 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.4594
2025-03-09 08:30:15,604 - INFO - Resetting pretrained SAE
2025-03-09 08:31:49,432 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.4553
2025-03-09 08:31:49,703 - INFO - Resetting pretrained SAE
2025-03-09 08:33:23,192 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.4516
2025-03-09 08:33:23,408 - INFO - Resetting pretrained SAE
2025-03-09 08:34:56,924 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.4533
2025-03-09 08:34:57,224 - INFO - Resetting pretrained SAE
2025-03-09 08:36:30,728 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.4534
2025-03-09 08:36:30,973 - INFO - Resetting pretrained SAE
2025-03-09 08:38:04,980 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.452
2025-03-09 08:38:05,191 - INFO - Resetting pretrained SAE
2025-03-09 08:39:38,905 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.4532
2025-03-09 08:39:39,125 - INFO - Resetting pretrained SAE
2025-03-09 08:39:39,130 - INFO - For layer 11, the best Sparse Ratio: 0.33 with validation loss: 2.4516
2025-03-09 08:39:57,111 - INFO - After pruning pretrained SAE, Validation loss: 2.4516, and Test loss: 2.4971
