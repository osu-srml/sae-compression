\begin{table}
\caption{mlp output - core}
\label{tab:mlp_core}
\begin{tabular}{llllll}
\toprule
metric & prunedBest & pruned25 & pretrained & trained & pruned50 \\
\midrule
metric & core & core & core & core & core \\
kl_div_score & -1.000 & -1.000 & -1.000 & -1.000 & -1.000 \\
kl_div_with_ablation & -1.000 & -1.000 & -1.000 & -1.000 & -1.000 \\
kl_div_with_sae & -1.000 & -1.000 & -1.000 & -1.000 & -1.000 \\
ce_loss_score & 0.746 & 0.769 & 0.776 & 0.776 & 0.667 \\
ce_loss_with_ablation & 3.975 & 3.645 & 3.975 & 3.967 & 3.645 \\
ce_loss_with_sae & 3.877 & 3.586 & 3.873 & 3.865 & 3.594 \\
ce_loss_without_sae & 3.844 & 3.568 & 3.844 & 3.836 & 3.568 \\
explained_variance & 0.734 & 0.741 & 0.767 & 0.662 & 0.636 \\
explained_variance_legacy & 0.640 & 0.679 & 0.668 & 0.611 & 0.586 \\
mse & 0.044 & 0.051 & 0.039 & 0.045 & 0.071 \\
cossim & 0.816 & 0.831 & 0.831 & 0.813 & 0.775 \\
l2_norm_in & 16.719 & 18.344 & 16.719 & 16.203 & 18.344 \\
l2_norm_out & 14.367 & 16.031 & 13.992 & 10.977 & 15.055 \\
l2_ratio & 0.848 & 0.866 & 0.828 & 0.667 & 0.809 \\
relative_reconstruction_bias & 1.059 & 1.058 & 0.999 & 0.849 & 1.114 \\
l0 & 32.000 & 32.000 & 32.000 & 46.810 & 32.000 \\
l1 & 84.812 & 86.500 & 81.062 & 23.562 & 82.625 \\
total_tokens_eval_reconstruction & 409600 & 409600 & 409600 & 409600 & 409600 \\
total_tokens_eval_sparsity_variance & 4096000 & 4096000 & 4096000 & 4096000 & 4096000 \\
freq_over_1_percent & 0.008 & 0.005 & 0.010 & 0.042 & 0.003 \\
freq_over_10_percent & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
normalized_freq_over_1_percent & 0.143 & 0.104 & 0.180 & 0.445 & 0.077 \\
normalized_freq_over_10_percent & 0.033 & 0.032 & 0.036 & 0.043 & 0.029 \\
average_max_encoder_cosine_sim & 0.457 & 0.457 & 0.473 & 0.748 & 0.402 \\
average_max_decoder_cosine_sim & 0.315 & 0.315 & 0.317 & 0.479 & 0.299 \\
frac_alive & 1.000 & 1.000 & 1.000 & 0.998 & 0.993 \\
\bottomrule
\end{tabular}
\end{table}
