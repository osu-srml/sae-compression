{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 32,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": false,
    "model_name": "gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "5118afb7-2cbe-481c-a3a3-0f4f5dba848a",
  "datetime_epoch_millis": 1742883820928,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.1596603806932007,
      "scr_metric_threshold_2": 0.0225174004925707,
      "scr_dir2_threshold_2": 0.035430552814456104,
      "scr_dir1_threshold_5": 0.15952432366303998,
      "scr_metric_threshold_5": 0.046545273867983454,
      "scr_dir2_threshold_5": 0.045398133561286816,
      "scr_dir1_threshold_10": 0.1459653684811526,
      "scr_metric_threshold_10": 0.05823896608018084,
      "scr_dir2_threshold_10": 0.06963932846407132,
      "scr_dir1_threshold_20": 0.17411729011219274,
      "scr_metric_threshold_20": 0.07249252478200952,
      "scr_dir2_threshold_20": 0.08181651393603943,
      "scr_dir1_threshold_50": 0.2164097464526976,
      "scr_metric_threshold_50": 0.10397408083710455,
      "scr_dir2_threshold_50": 0.14694046358545287,
      "scr_dir1_threshold_100": 0.22771962190170314,
      "scr_metric_threshold_100": 0.1328273448849031,
      "scr_dir2_threshold_100": 0.20604755510202968,
      "scr_dir1_threshold_500": 0.18410989369641076,
      "scr_metric_threshold_500": 0.18492177018774783,
      "scr_dir2_threshold_500": 0.2027932721720495
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.24999937911799985,
      "scr_metric_threshold_2": 0.01913879282354446,
      "scr_dir2_threshold_2": 0.01913879282354446,
      "scr_dir1_threshold_5": 0.1250009313230002,
      "scr_metric_threshold_5": 0.03588512959802375,
      "scr_dir2_threshold_5": 0.03588512959802375,
      "scr_dir1_threshold_10": 0.1250009313230002,
      "scr_metric_threshold_10": 0.040669899101324604,
      "scr_dir2_threshold_10": 0.040669899101324604,
      "scr_dir1_threshold_20": 0.08333229852999978,
      "scr_metric_threshold_20": 0.040669899101324604,
      "scr_dir2_threshold_20": 0.040669899101324604,
      "scr_dir1_threshold_50": 0.24999937911799985,
      "scr_metric_threshold_50": 0.05263160896733252,
      "scr_dir2_threshold_50": 0.05263160896733252,
      "scr_dir1_threshold_100": 0.3333341611760002,
      "scr_metric_threshold_100": 0.06220100537910475,
      "scr_dir2_threshold_100": 0.06220100537910475,
      "scr_dir1_threshold_500": 0.0,
      "scr_metric_threshold_500": 0.06698563228757613,
      "scr_dir2_threshold_500": 0.06698563228757613
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.3469389989344155,
      "scr_metric_threshold_2": 0.010695208472019047,
      "scr_dir2_threshold_2": 0.010695208472019047,
      "scr_dir1_threshold_5": 0.38775477931695546,
      "scr_metric_threshold_5": 0.010695208472019047,
      "scr_dir2_threshold_5": 0.010695208472019047,
      "scr_dir1_threshold_10": 0.3061220021311691,
      "scr_metric_threshold_10": 0.016042733022677336,
      "scr_dir2_threshold_10": 0.016042733022677336,
      "scr_dir1_threshold_20": 0.4285717761202018,
      "scr_metric_threshold_20": 0.029411863140727995,
      "scr_dir2_threshold_20": 0.029411863140727995,
      "scr_dir1_threshold_50": 0.4285717761202018,
      "scr_metric_threshold_50": 0.04010691224204457,
      "scr_dir2_threshold_50": 0.04010691224204457,
      "scr_dir1_threshold_100": 0.5510203336885282,
      "scr_metric_threshold_100": 0.03743314996671543,
      "scr_dir2_threshold_100": 0.03743314996671543,
      "scr_dir1_threshold_500": 0.32653110874314545,
      "scr_metric_threshold_500": 0.0,
      "scr_dir2_threshold_500": 0.0
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.3333326710601867,
      "scr_metric_threshold_2": 0.007537591361340128,
      "scr_dir2_threshold_2": 0.007537591361340128,
      "scr_dir1_threshold_5": 0.36666554080231745,
      "scr_metric_threshold_5": 0.012562802029313504,
      "scr_dir2_threshold_5": 0.012562802029313504,
      "scr_dir1_threshold_10": 0.3333326710601867,
      "scr_metric_threshold_10": 0.012562802029313504,
      "scr_dir2_threshold_10": 0.012562802029313504,
      "scr_dir1_threshold_20": 0.400000397363888,
      "scr_metric_threshold_20": 0.030150664966187093,
      "scr_dir2_threshold_20": 0.030150664966187093,
      "scr_dir1_threshold_50": 0.3333326710601867,
      "scr_metric_threshold_50": 0.027638134512407053,
      "scr_dir2_threshold_50": 0.027638134512407053,
      "scr_dir1_threshold_100": 0.400000397363888,
      "scr_metric_threshold_100": 0.05025120811725402,
      "scr_dir2_threshold_100": 0.05025120811725402,
      "scr_dir1_threshold_500": 0.10000059604583195,
      "scr_metric_threshold_500": 0.04773867766347398,
      "scr_dir2_threshold_500": 0.04773867766347398
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.2068968706549006,
      "scr_metric_threshold_2": 0.0026524855055588045,
      "scr_dir2_threshold_2": 0.0026524855055588045,
      "scr_dir1_threshold_5": 0.08620677252309422,
      "scr_metric_threshold_5": 0.0026524855055588045,
      "scr_dir2_threshold_5": 0.0026524855055588045,
      "scr_dir1_threshold_10": 0.017241148971460694,
      "scr_metric_threshold_10": 0.010610100124727056,
      "scr_dir2_threshold_10": 0.010610100124727056,
      "scr_dir1_threshold_20": 0.017241148971460694,
      "scr_metric_threshold_20": 0.015915071135844665,
      "scr_dir2_threshold_20": 0.015915071135844665,
      "scr_dir1_threshold_50": 0.03448332560871214,
      "scr_metric_threshold_50": 0.02652517126057172,
      "scr_dir2_threshold_50": 0.02652517126057172,
      "scr_dir1_threshold_100": -0.32758594112091616,
      "scr_metric_threshold_100": 0.047745371510025836,
      "scr_dir2_threshold_100": 0.047745371510025836,
      "scr_dir1_threshold_500": -0.3103447921494555,
      "scr_metric_threshold_500": 0.007957614619168251,
      "scr_dir2_threshold_500": 0.007957614619168251
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.06557388902829207,
      "scr_metric_threshold_2": 0.06557388902829207,
      "scr_dir2_threshold_2": 0.09774443503318589,
      "scr_dir1_threshold_5": 0.10491802702024525,
      "scr_metric_threshold_5": 0.10491802702024525,
      "scr_dir2_threshold_5": 0.13533837956053904,
      "scr_dir1_threshold_10": 0.12131145042106276,
      "scr_metric_threshold_10": 0.12131145042106276,
      "scr_dir2_threshold_10": 0.24060151386816173,
      "scr_dir1_threshold_20": 0.1409837148420614,
      "scr_metric_threshold_20": 0.1409837148420614,
      "scr_dir2_threshold_20": 0.315789402922868,
      "scr_dir1_threshold_50": 0.1770492072388555,
      "scr_metric_threshold_50": 0.1770492072388555,
      "scr_dir2_threshold_50": 0.4436090832089703,
      "scr_dir1_threshold_100": 0.21967218625098983,
      "scr_metric_threshold_100": 0.21967218625098983,
      "scr_dir2_threshold_100": 0.5263156715381133,
      "scr_dir1_threshold_500": 0.31147543546557666,
      "scr_metric_threshold_500": 0.31147543546557666,
      "scr_dir2_threshold_500": 0.5639096160654665
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.02076138840444366,
      "scr_metric_threshold_2": 0.02076138840444366,
      "scr_dir2_threshold_2": 0.0,
      "scr_dir1_threshold_5": 0.06574412162151014,
      "scr_metric_threshold_5": 0.06574412162151014,
      "scr_dir2_threshold_5": -0.03125005820765137,
      "scr_dir1_threshold_10": 0.10726648594155529,
      "scr_metric_threshold_10": 0.10726648594155529,
      "scr_dir2_threshold_10": 0.03125005820765137,
      "scr_dir1_threshold_20": 0.14532889385342126,
      "scr_metric_threshold_20": 0.14532889385342126,
      "scr_dir2_threshold_20": 0.007812863797821078,
      "scr_dir1_threshold_50": 0.17993093286826592,
      "scr_metric_threshold_50": 0.17993093286826592,
      "scr_dir2_threshold_50": 0.14062502910382568,
      "scr_dir1_threshold_100": 0.20761244033348897,
      "scr_metric_threshold_100": 0.20761244033348897,
      "scr_dir2_threshold_100": 0.21874994179234863,
      "scr_dir1_threshold_500": 0.3010380694202222,
      "scr_metric_threshold_500": 0.3010380694202222,
      "scr_dir2_threshold_500": 0.19531274738251833
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.021052567736489773,
      "scr_metric_threshold_2": 0.021052567736489773,
      "scr_dir2_threshold_2": 0.12328769360278982,
      "scr_dir1_threshold_5": 0.052631523910767045,
      "scr_metric_threshold_5": 0.052631523910767045,
      "scr_dir2_threshold_5": 0.13013691919163053,
      "scr_dir1_threshold_10": 0.07017536521435606,
      "scr_metric_threshold_10": 0.07017536521435606,
      "scr_dir2_threshold_10": 0.12328769360278982,
      "scr_dir1_threshold_20": 0.11929816269222235,
      "scr_metric_threshold_20": 0.11929816269222235,
      "scr_dir2_threshold_20": 0.18493154040418475,
      "scr_dir1_threshold_50": 0.1824560750407769,
      "scr_metric_threshold_50": 0.1824560750407769,
      "scr_dir2_threshold_50": 0.28767114898953816,
      "scr_dir1_threshold_100": 0.2631578286929205,
      "scr_metric_threshold_100": 0.2631578286929205,
      "scr_dir2_threshold_100": 0.3698630808083695,
      "scr_dir1_threshold_500": 0.43508772443499505,
      "scr_metric_threshold_500": 0.43508772443499505,
      "scr_dir2_threshold_500": 0.31506845959581525
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.032727280608877626,
      "scr_metric_threshold_2": 0.032727280608877626,
      "scr_dir2_threshold_2": 0.022388215717210662,
      "scr_dir1_threshold_5": 0.08727289278643008,
      "scr_metric_threshold_5": 0.08727289278643008,
      "scr_dir2_threshold_5": 0.06716420234086116,
      "scr_dir1_threshold_10": 0.08727289278643008,
      "scr_metric_threshold_10": 0.08727289278643008,
      "scr_dir2_threshold_10": 0.08208982775592522,
      "scr_dir1_threshold_20": 0.05818192852428672,
      "scr_metric_threshold_20": 0.05818192852428672,
      "scr_dir2_threshold_20": 0.029850806019357277,
      "scr_dir1_threshold_50": 0.14545460456658219,
      "scr_metric_threshold_50": 0.14545460456658219,
      "scr_dir2_threshold_50": 0.156716620398933,
      "scr_dir1_threshold_100": 0.17454556882872554,
      "scr_metric_threshold_100": 0.17454556882872554,
      "scr_dir2_threshold_100": 0.33582101170430584,
      "scr_dir1_threshold_500": 0.3090910076109703,
      "scr_metric_threshold_500": 0.3090910076109703,
      "scr_dir2_threshold_500": 0.42537342976237763
    }
  ],
  "sae_bench_commit_hash": "c5c90a136c8db8e704e401328a49b19932ad56c9",
  "sae_lens_id": "layer_12/width_16k/canonical",
  "sae_lens_release_id": "gemma-scope-2b-pt-mlp-canonical",
  "sae_lens_version": "5.6.1",
  "sae_cfg_dict": {
    "architecture": "jumprelu",
    "d_in": 2304,
    "d_sae": 16384,
    "activation_fn_str": "relu",
    "apply_b_dec_to_input": false,
    "finetuning_scaling_factor": false,
    "context_size": 1024,
    "model_name": "gemma-2-2b",
    "hook_name": "blocks.12.hook_mlp_out",
    "hook_layer": 12,
    "hook_head_index": null,
    "prepend_bos": true,
    "dataset_path": "monology/pile-uncopyrighted",
    "dataset_trust_remote_code": true,
    "normalize_activations": null,
    "dtype": "torch.bfloat16",
    "device": "cuda",
    "sae_lens_training_version": null,
    "activation_fn_kwargs": {},
    "neuronpedia_id": "gemma-2-2b/12-gemmascope-mlp-16k",
    "model_from_pretrained_kwargs": {},
    "seqpos_slice": [
      null
    ]
  },
  "eval_result_unstructured": null
}