{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 32,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": false,
    "model_name": "gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "0d1ff002-0ee1-40c0-82a5-d1b9daa7a268",
  "datetime_epoch_millis": 1742893419466,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.09654530303916414,
      "scr_metric_threshold_2": 0.019181702051588603,
      "scr_dir2_threshold_2": 0.014690110404719198,
      "scr_dir1_threshold_5": 0.09434546417642078,
      "scr_metric_threshold_5": 0.027886018951076362,
      "scr_dir2_threshold_5": 0.03283320833810837,
      "scr_dir1_threshold_10": 0.09253478282445739,
      "scr_metric_threshold_10": 0.029969233091352014,
      "scr_dir2_threshold_10": 0.03597969254417636,
      "scr_dir1_threshold_20": 0.11170140723141292,
      "scr_metric_threshold_20": 0.03528929338289344,
      "scr_dir2_threshold_20": 0.055217709820989405,
      "scr_dir1_threshold_50": 0.07222689856370051,
      "scr_metric_threshold_50": 0.050280790964988074,
      "scr_dir2_threshold_50": 0.07674511164104204,
      "scr_dir1_threshold_100": 0.07811256280599178,
      "scr_metric_threshold_100": 0.0482507054814066,
      "scr_dir2_threshold_100": 0.09760172943110147,
      "scr_dir1_threshold_500": 0.006618506758357097,
      "scr_metric_threshold_500": 0.07746448229219033,
      "scr_dir2_threshold_500": 0.10884976595787463
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.04166614926499989,
      "scr_metric_threshold_2": 0.011961709866007917,
      "scr_dir2_threshold_2": 0.011961709866007917,
      "scr_dir1_threshold_5": 0.08333229852999978,
      "scr_metric_threshold_5": 0.021531106277780147,
      "scr_dir2_threshold_5": 0.021531106277780147,
      "scr_dir1_threshold_10": 0.08333229852999978,
      "scr_metric_threshold_10": 0.02870818923531669,
      "scr_dir2_threshold_10": 0.02870818923531669,
      "scr_dir1_threshold_20": 0.04166614926499989,
      "scr_metric_threshold_20": 0.02631573318625152,
      "scr_dir2_threshold_20": 0.02631573318625152,
      "scr_dir1_threshold_50": 0.08333229852999978,
      "scr_metric_threshold_50": 0.04545452600979598,
      "scr_dir2_threshold_50": 0.04545452600979598,
      "scr_dir1_threshold_100": 0.08333229852999978,
      "scr_metric_threshold_100": 0.04784683946403167,
      "scr_dir2_threshold_100": 0.04784683946403167,
      "scr_dir1_threshold_500": -0.04166614926499989,
      "scr_metric_threshold_500": 0.06459331883334044,
      "scr_dir2_threshold_500": 0.06459331883334044
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.22449044136608912,
      "scr_metric_threshold_2": 0.002673762275329144,
      "scr_dir2_threshold_2": 0.002673762275329144,
      "scr_dir1_threshold_5": 0.2857141119398991,
      "scr_metric_threshold_5": 0.008021446196689902,
      "scr_dir2_threshold_5": 0.008021446196689902,
      "scr_dir1_threshold_10": 0.22449044136608912,
      "scr_metric_threshold_10": 0.016042733022677336,
      "scr_dir2_threshold_10": 0.016042733022677336,
      "scr_dir1_threshold_20": 0.20408133475411272,
      "scr_metric_threshold_20": 0.021390416944038093,
      "scr_dir2_threshold_20": 0.021390416944038093,
      "scr_dir1_threshold_50": 0.18367344456284274,
      "scr_metric_threshold_50": 0.008021446196689902,
      "scr_dir2_threshold_50": 0.008021446196689902,
      "scr_dir1_threshold_100": 0.2448983315573591,
      "scr_metric_threshold_100": 0.005347683921360758,
      "scr_dir2_threshold_100": 0.005347683921360758,
      "scr_dir1_threshold_500": 0.2653062217486291,
      "scr_metric_threshold_500": -0.008021286825987434,
      "scr_dir2_threshold_500": -0.008021286825987434
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.19999920527222406,
      "scr_metric_threshold_2": 0.005025060907560086,
      "scr_dir2_threshold_2": 0.005025060907560086,
      "scr_dir1_threshold_5": 0.19999920527222406,
      "scr_metric_threshold_5": 0.002512530453780043,
      "scr_dir2_threshold_5": 0.002512530453780043,
      "scr_dir1_threshold_10": 0.2333340618337946,
      "scr_metric_threshold_10": 0.002512530453780043,
      "scr_dir2_threshold_10": 0.002512530453780043,
      "scr_dir1_threshold_20": 0.2666669315759253,
      "scr_metric_threshold_20": 0.012562802029313504,
      "scr_dir2_threshold_20": 0.012562802029313504,
      "scr_dir1_threshold_50": 0.13333346578796265,
      "scr_metric_threshold_50": 0.020100543151066925,
      "scr_dir2_threshold_50": 0.020100543151066925,
      "scr_dir1_threshold_100": 0.19999920527222406,
      "scr_metric_threshold_100": 0.022613073604846965,
      "scr_dir2_threshold_100": 0.022613073604846965,
      "scr_dir1_threshold_500": -0.5666667328939813,
      "scr_metric_threshold_500": 0.07035175126832094,
      "scr_dir2_threshold_500": 0.07035175126832094
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.17241354504618844,
      "scr_metric_threshold_2": 0.0,
      "scr_dir2_threshold_2": 0.0,
      "scr_dir1_threshold_5": 0.0,
      "scr_metric_threshold_5": 0.005304971011117609,
      "scr_dir2_threshold_5": 0.005304971011117609,
      "scr_dir1_threshold_10": 0.017241148971460694,
      "scr_metric_threshold_10": 0.010610100124727056,
      "scr_dir2_threshold_10": 0.010610100124727056,
      "scr_dir1_threshold_20": 0.13793124710326704,
      "scr_metric_threshold_20": -0.02122020024945411,
      "scr_dir2_threshold_20": -0.02122020024945411,
      "scr_dir1_threshold_50": -0.13793124710326704,
      "scr_metric_threshold_50": 0.01326258563028586,
      "scr_dir2_threshold_50": 0.01326258563028586,
      "scr_dir1_threshold_100": -0.18965469401764914,
      "scr_metric_threshold_100": 0.023872685755012918,
      "scr_dir2_threshold_100": 0.023872685755012918,
      "scr_dir1_threshold_500": -0.05172447458017283,
      "scr_metric_threshold_500": 0.04509288600446703,
      "scr_dir2_threshold_500": 0.04509288600446703
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.05245911122263366,
      "scr_metric_threshold_2": 0.05245911122263366,
      "scr_dir2_threshold_2": 0.0751878890547063,
      "scr_dir1_threshold_5": 0.06885253462345116,
      "scr_metric_threshold_5": 0.06885253462345116,
      "scr_dir2_threshold_5": 0.10526313430762267,
      "scr_dir1_threshold_10": 0.06557388902829207,
      "scr_metric_threshold_10": 0.06557388902829207,
      "scr_dir2_threshold_10": 0.187970170791935,
      "scr_dir1_threshold_20": 0.059016402412951835,
      "scr_metric_threshold_20": 0.059016402412951835,
      "scr_dir2_threshold_20": 0.24060151386816173,
      "scr_dir1_threshold_50": 0.08524595802426867,
      "scr_metric_threshold_50": 0.08524595802426867,
      "scr_dir2_threshold_50": 0.27819545839551485,
      "scr_dir1_threshold_100": 0.07213118021861024,
      "scr_metric_threshold_100": 0.07213118021861024,
      "scr_dir2_threshold_100": 0.315789402922868,
      "scr_dir1_threshold_500": 0.09836073582992708,
      "scr_metric_threshold_500": 0.09836073582992708,
      "scr_dir2_threshold_500": 0.315789402922868
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.027681713709644153,
      "scr_metric_threshold_2": 0.027681713709644153,
      "scr_dir2_threshold_2": -0.07812491268852294,
      "scr_dir1_threshold_5": 0.04152257056446623,
      "scr_metric_threshold_5": 0.04152257056446623,
      "scr_dir2_threshold_5": -0.015624796273220196,
      "scr_dir1_threshold_10": 0.04498273321706648,
      "scr_metric_threshold_10": 0.04498273321706648,
      "scr_dir2_threshold_10": -0.07812491268852294,
      "scr_dir1_threshold_20": 0.04498273321706648,
      "scr_metric_threshold_20": 0.04498273321706648,
      "scr_dir2_threshold_20": -0.007812398136610098,
      "scr_dir1_threshold_50": 0.06920428427411039,
      "scr_metric_threshold_50": 0.06920428427411039,
      "scr_dir2_threshold_50": 0.0,
      "scr_dir1_threshold_100": 0.07958477223191113,
      "scr_metric_threshold_100": 0.07958477223191113,
      "scr_dir2_threshold_100": 0.07031251455191284,
      "scr_dir1_threshold_500": 0.11418701749117686,
      "scr_metric_threshold_500": 0.11418701749117686,
      "scr_dir2_threshold_500": 0.007812863797821078
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.02456129416939053,
      "scr_metric_threshold_2": 0.02456129416939053,
      "scr_dir2_threshold_2": 0.04109576178395852,
      "scr_dir1_threshold_5": 0.028070229741376514,
      "scr_metric_threshold_5": 0.028070229741376514,
      "scr_dir2_threshold_5": 0.06849307239023562,
      "scr_dir1_threshold_10": 0.038596409040078786,
      "scr_metric_threshold_10": 0.038596409040078786,
      "scr_dir2_threshold_10": 0.07534229797907632,
      "scr_dir1_threshold_20": 0.07017536521435606,
      "scr_metric_threshold_20": 0.07017536521435606,
      "scr_dir2_threshold_20": 0.10273960858535343,
      "scr_dir1_threshold_50": 0.07368409164725681,
      "scr_metric_threshold_50": 0.07368409164725681,
      "scr_dir2_threshold_50": 0.13698614478047125,
      "scr_dir1_threshold_100": 0.09824559495573258,
      "scr_metric_threshold_100": 0.09824559495573258,
      "scr_dir2_threshold_100": 0.20547921717070686,
      "scr_dir1_threshold_500": 0.1333332775629106,
      "scr_metric_threshold_500": 0.1333332775629106,
      "scr_dir2_threshold_500": 0.14383577862022623
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.02909096426214336,
      "scr_metric_threshold_2": 0.02909096426214336,
      "scr_dir2_threshold_2": 0.059701612038714554,
      "scr_dir1_threshold_5": 0.047272762739949306,
      "scr_metric_threshold_5": 0.047272762739949306,
      "scr_dir2_threshold_5": 0.06716420234086116,
      "scr_dir1_threshold_10": 0.032727280608877626,
      "scr_metric_threshold_10": 0.032727280608877626,
      "scr_dir2_threshold_10": 0.044776431434421324,
      "scr_dir1_threshold_20": 0.06909109430862415,
      "scr_metric_threshold_20": 0.06909109430862415,
      "scr_dir2_threshold_20": 0.06716420234086116,
      "scr_dir1_threshold_50": 0.08727289278643008,
      "scr_metric_threshold_50": 0.08727289278643008,
      "scr_dir2_threshold_50": 0.11194018896451166,
      "scr_dir1_threshold_100": 0.03636381369974652,
      "scr_metric_threshold_100": 0.03636381369974652,
      "scr_dir2_threshold_100": 0.08955241805807182,
      "scr_dir1_threshold_500": 0.10181815817336713,
      "scr_metric_threshold_500": 0.10181815817336713,
      "scr_dir2_threshold_500": 0.23134341304194075
    }
  ],
  "sae_bench_commit_hash": "c5c90a136c8db8e704e401328a49b19932ad56c9",
  "sae_lens_id": "blocks.12.hook_mlp_out",
  "sae_lens_release_id": "suchitg/sae-compression-gemma-2-2b-pruned-sae-pile-0.5",
  "sae_lens_version": "5.6.1",
  "sae_cfg_dict": {
    "architecture": "jumprelu",
    "d_in": 2304,
    "d_sae": 16384,
    "activation_fn_str": "relu",
    "apply_b_dec_to_input": false,
    "finetuning_scaling_factor": false,
    "context_size": 1024,
    "model_name": "gemma-2-2b",
    "hook_name": "blocks.12.hook_mlp_out",
    "hook_layer": 12,
    "hook_head_index": null,
    "prepend_bos": true,
    "dataset_path": "monology/pile-uncopyrighted",
    "dataset_trust_remote_code": true,
    "normalize_activations": null,
    "dtype": "torch.bfloat16",
    "device": "cuda",
    "sae_lens_training_version": null,
    "activation_fn_kwargs": {},
    "neuronpedia_id": "gemma-2-2b/12-gemmascope-mlp-16k",
    "model_from_pretrained_kwargs": {},
    "seqpos_slice": [
      null
    ]
  },
  "eval_result_unstructured": null
}