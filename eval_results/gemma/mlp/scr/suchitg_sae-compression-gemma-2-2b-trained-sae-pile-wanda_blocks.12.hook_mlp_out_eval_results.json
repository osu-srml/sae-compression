{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 32,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": false,
    "model_name": "gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "f4be796b-0f23-47d8-9954-2c97969ee9ba",
  "datetime_epoch_millis": 1742869056988,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.010505263907506716,
      "scr_metric_threshold_2": -0.00139550179766328,
      "scr_dir2_threshold_2": -0.0012990949163609734,
      "scr_dir1_threshold_5": 0.015584546823144073,
      "scr_metric_threshold_5": -0.0010691353174164106,
      "scr_dir2_threshold_5": 0.000966462599494429,
      "scr_dir1_threshold_10": 0.012159227026875287,
      "scr_metric_threshold_10": -0.008742747440882074,
      "scr_dir2_threshold_10": -0.0019968695124661672,
      "scr_dir1_threshold_20": 0.0032894216187501837,
      "scr_metric_threshold_20": -0.009810654465417634,
      "scr_dir2_threshold_20": 0.002103103597969896,
      "scr_dir1_threshold_50": 0.011115639709897374,
      "scr_metric_threshold_50": -0.008826241876873454,
      "scr_dir2_threshold_50": 0.008068840761137579,
      "scr_dir1_threshold_100": 0.024450437687261004,
      "scr_metric_threshold_100": -0.004263932311243024,
      "scr_dir2_threshold_100": 0.016987909127993167,
      "scr_dir1_threshold_500": 0.049385082958165155,
      "scr_metric_threshold_500": 0.05706022442392069,
      "scr_dir2_threshold_500": 0.13293200466780805
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.04166614926499989,
      "scr_metric_threshold_2": 0.0,
      "scr_dir2_threshold_2": 0.0,
      "scr_dir1_threshold_5": 0.04166614926499989,
      "scr_metric_threshold_5": 0.0,
      "scr_dir2_threshold_5": 0.0,
      "scr_dir1_threshold_10": 0.08333229852999978,
      "scr_metric_threshold_10": 0.0,
      "scr_dir2_threshold_10": 0.0,
      "scr_dir1_threshold_20": 0.04166614926499989,
      "scr_metric_threshold_20": 0.0,
      "scr_dir2_threshold_20": 0.0,
      "scr_dir1_threshold_50": 0.04166614926499989,
      "scr_metric_threshold_50": 0.014354023320243603,
      "scr_dir2_threshold_50": 0.014354023320243603,
      "scr_dir1_threshold_100": 0.0,
      "scr_metric_threshold_100": 0.0071770829575365435,
      "scr_dir2_threshold_100": 0.0071770829575365435,
      "scr_dir1_threshold_500": 0.0,
      "scr_metric_threshold_500": 0.04784683946403167,
      "scr_dir2_threshold_500": 0.04784683946403167
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": -0.04081578038253998,
      "scr_metric_threshold_2": 0.002673762275329144,
      "scr_dir2_threshold_2": 0.002673762275329144,
      "scr_dir1_threshold_5": 0.0,
      "scr_metric_threshold_5": 0.002673762275329144,
      "scr_dir2_threshold_5": 0.002673762275329144,
      "scr_dir1_threshold_10": -0.04081578038253998,
      "scr_metric_threshold_10": 0.005347683921360758,
      "scr_dir2_threshold_10": 0.005347683921360758,
      "scr_dir1_threshold_20": -0.02040789019126999,
      "scr_metric_threshold_20": 0.010695208472019047,
      "scr_dir2_threshold_20": 0.010695208472019047,
      "scr_dir1_threshold_50": 0.0,
      "scr_metric_threshold_50": 0.008021446196689902,
      "scr_dir2_threshold_50": 0.008021446196689902,
      "scr_dir1_threshold_100": -0.04081578038253998,
      "scr_metric_threshold_100": -0.010695208472019047,
      "scr_dir2_threshold_100": -0.010695208472019047,
      "scr_dir1_threshold_500": 0.08163277718578636,
      "scr_metric_threshold_500": 0.029411863140727995,
      "scr_dir2_threshold_500": 0.029411863140727995
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.06666573948426141,
      "scr_metric_threshold_2": -0.002512530453780043,
      "scr_dir2_threshold_2": -0.002512530453780043,
      "scr_dir1_threshold_5": 0.06666573948426141,
      "scr_metric_threshold_5": -0.005025210667973376,
      "scr_dir2_threshold_5": -0.005025210667973376,
      "scr_dir1_threshold_10": 0.06666573948426141,
      "scr_metric_threshold_10": -0.005025210667973376,
      "scr_dir2_threshold_10": -0.005025210667973376,
      "scr_dir1_threshold_20": 0.06666573948426141,
      "scr_metric_threshold_20": -0.005025210667973376,
      "scr_dir2_threshold_20": -0.005025210667973376,
      "scr_dir1_threshold_50": 0.13333346578796265,
      "scr_metric_threshold_50": 0.005025060907560086,
      "scr_dir2_threshold_50": 0.005025060907560086,
      "scr_dir1_threshold_100": 0.19999920527222406,
      "scr_metric_threshold_100": 0.012562802029313504,
      "scr_dir2_threshold_100": 0.012562802029313504,
      "scr_dir1_threshold_500": 0.10000059604583195,
      "scr_metric_threshold_500": 0.04773867766347398,
      "scr_dir2_threshold_500": 0.04773867766347398
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.017241148971460694,
      "scr_metric_threshold_2": -0.010610100124727056,
      "scr_dir2_threshold_2": -0.010610100124727056,
      "scr_dir1_threshold_5": 0.017241148971460694,
      "scr_metric_threshold_5": -0.005304971011117609,
      "scr_dir2_threshold_5": -0.005304971011117609,
      "scr_dir1_threshold_10": 0.03448332560871214,
      "scr_metric_threshold_10": -0.023872685755012918,
      "scr_dir2_threshold_10": -0.023872685755012918,
      "scr_dir1_threshold_20": -0.017241148971460694,
      "scr_metric_threshold_20": -0.03978775689085758,
      "scr_dir2_threshold_20": -0.03978775689085758,
      "scr_dir1_threshold_50": -0.05172447458017283,
      "scr_metric_threshold_50": -0.0636604426458705,
      "scr_dir2_threshold_50": -0.0636604426458705,
      "scr_dir1_threshold_100": 0.03448332560871214,
      "scr_metric_threshold_100": -0.04509288600446703,
      "scr_dir2_threshold_100": -0.04509288600446703,
      "scr_dir1_threshold_500": -0.15517239607472774,
      "scr_metric_threshold_500": -0.037135271385298776,
      "scr_dir2_threshold_500": -0.037135271385298776
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.006557486615340239,
      "scr_metric_threshold_2": 0.006557486615340239,
      "scr_dir2_threshold_2": 0.007518699274436781,
      "scr_dir1_threshold_5": 0.009836132210499327,
      "scr_metric_threshold_5": 0.009836132210499327,
      "scr_dir2_threshold_5": 0.015037846704042807,
      "scr_dir1_threshold_10": 0.0,
      "scr_metric_threshold_10": 0.0,
      "scr_dir2_threshold_10": 0.015037846704042807,
      "scr_dir1_threshold_20": 0.016393618825839566,
      "scr_metric_threshold_20": 0.016393618825839566,
      "scr_dir2_threshold_20": 0.03759394452735315,
      "scr_dir1_threshold_50": 0.02295091001615774,
      "scr_metric_threshold_50": 0.02295091001615774,
      "scr_dir2_threshold_50": 0.06015049050583274,
      "scr_dir1_threshold_100": 0.042622979012134334,
      "scr_metric_threshold_100": 0.042622979012134334,
      "scr_dir2_threshold_100": 0.09774443503318589,
      "scr_dir1_threshold_500": 0.15081965162753866,
      "scr_metric_threshold_500": 0.15081965162753866,
      "scr_dir2_threshold_500": 0.25563936057220454
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.0,
      "scr_metric_threshold_2": 0.0,
      "scr_dir2_threshold_2": 0.0,
      "scr_dir1_threshold_5": -0.003460162652600247,
      "scr_metric_threshold_5": -0.003460162652600247,
      "scr_dir2_threshold_5": 0.007812863797821078,
      "scr_dir1_threshold_10": -0.017301019507422324,
      "scr_metric_threshold_10": -0.017301019507422324,
      "scr_dir2_threshold_10": 0.0,
      "scr_dir1_threshold_20": -0.02076118216002257,
      "scr_metric_threshold_20": -0.02076118216002257,
      "scr_dir2_threshold_20": -0.007812398136610098,
      "scr_dir1_threshold_50": -0.017301019507422324,
      "scr_metric_threshold_50": -0.017301019507422324,
      "scr_dir2_threshold_50": -0.023437194409830293,
      "scr_dir1_threshold_100": 0.0034603688970213354,
      "scr_metric_threshold_100": 0.0034603688970213354,
      "scr_dir2_threshold_100": -0.03906245634426147,
      "scr_dir1_threshold_500": 0.07266444692671063,
      "scr_metric_threshold_500": 0.07266444692671063,
      "scr_dir2_threshold_500": 0.14062502910382568
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.0,
      "scr_metric_threshold_2": 0.0,
      "scr_dir2_threshold_2": 0.0,
      "scr_dir1_threshold_5": 0.0,
      "scr_metric_threshold_5": 0.0,
      "scr_dir2_threshold_5": 0.0,
      "scr_dir1_threshold_10": 0.0,
      "scr_metric_threshold_10": 0.0,
      "scr_dir2_threshold_10": 0.0,
      "scr_dir1_threshold_20": 0.0,
      "scr_metric_threshold_20": 0.0,
      "scr_dir2_threshold_20": 0.013698451177681412,
      "scr_dir1_threshold_50": 0.0,
      "scr_metric_threshold_50": 0.0,
      "scr_dir2_threshold_50": 0.03424653619511781,
      "scr_dir1_threshold_100": 0.014035114870688257,
      "scr_metric_threshold_100": 0.014035114870688257,
      "scr_dir2_threshold_100": 0.06849307239023562,
      "scr_dir1_threshold_500": 0.10877177425443485,
      "scr_metric_threshold_500": 0.10877177425443485,
      "scr_dir2_threshold_500": 0.28082192340069745
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": -0.007272632693468524,
      "scr_metric_threshold_2": -0.007272632693468524,
      "scr_dir2_threshold_2": -0.007462590302146612,
      "scr_dir1_threshold_5": -0.007272632693468524,
      "scr_metric_threshold_5": -0.007272632693468524,
      "scr_dir2_threshold_5": -0.007462590302146612,
      "scr_dir1_threshold_10": -0.02909074751800873,
      "scr_metric_threshold_10": -0.02909074751800873,
      "scr_dir2_threshold_10": -0.007462590302146612,
      "scr_dir1_threshold_20": -0.039999913302346146,
      "scr_metric_threshold_20": -0.039999913302346146,
      "scr_dir2_threshold_20": 0.007462590302146612,
      "scr_dir1_threshold_50": -0.039999913302346146,
      "scr_metric_threshold_50": -0.039999913302346146,
      "scr_dir2_threshold_50": 0.029850806019357277,
      "scr_dir1_threshold_100": -0.05818171178015209,
      "scr_metric_threshold_100": -0.05818171178015209,
      "scr_dir2_threshold_100": 0.044776431434421324,
      "scr_dir1_threshold_500": 0.03636381369974652,
      "scr_metric_threshold_500": 0.03636381369974652,
      "scr_dir2_threshold_500": 0.2985076153828019
    }
  ],
  "sae_bench_commit_hash": "c5c90a136c8db8e704e401328a49b19932ad56c9",
  "sae_lens_id": "blocks.12.hook_mlp_out",
  "sae_lens_release_id": "suchitg/sae-compression-gemma-2-2b-trained-sae-pile-wanda",
  "sae_lens_version": "5.6.1",
  "sae_cfg_dict": {
    "architecture": "jumprelu",
    "d_in": 2304,
    "d_sae": 16384,
    "activation_fn_str": "relu",
    "apply_b_dec_to_input": false,
    "finetuning_scaling_factor": false,
    "context_size": 1024,
    "model_name": "gemma-2-2b",
    "hook_name": "blocks.12.hook_mlp_out",
    "hook_layer": 12,
    "hook_head_index": null,
    "prepend_bos": true,
    "dataset_path": "monology/pile-uncopyrighted",
    "dataset_trust_remote_code": true,
    "normalize_activations": "none",
    "dtype": "torch.bfloat16",
    "device": "cuda",
    "sae_lens_training_version": "5.5.2",
    "activation_fn_kwargs": {},
    "neuronpedia_id": null,
    "model_from_pretrained_kwargs": {
      "center_writing_weights": false
    },
    "seqpos_slice": [
      null
    ]
  },
  "eval_result_unstructured": null
}