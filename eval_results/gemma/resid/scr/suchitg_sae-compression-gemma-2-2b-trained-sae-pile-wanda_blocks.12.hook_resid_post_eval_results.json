{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 32,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": false,
    "model_name": "gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "1bc11fd1-9c34-428c-a548-6fa6800ce781",
  "datetime_epoch_millis": 1742859216890,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.06157132305047732,
      "scr_metric_threshold_2": 0.018463784022816277,
      "scr_dir2_threshold_2": 0.022122310148115717,
      "scr_dir1_threshold_5": 0.09873113887538475,
      "scr_metric_threshold_5": 0.0355504590676527,
      "scr_dir2_threshold_5": 0.03289825834529559,
      "scr_dir1_threshold_10": 0.1461212334268246,
      "scr_metric_threshold_10": 0.047385169929870886,
      "scr_dir2_threshold_10": 0.04124442075769313,
      "scr_dir1_threshold_20": 0.11491282992803584,
      "scr_metric_threshold_20": 0.07556123583796891,
      "scr_dir2_threshold_20": 0.06942048666579115,
      "scr_dir1_threshold_50": 0.1528430641173249,
      "scr_metric_threshold_50": 0.10101497303344983,
      "scr_dir2_threshold_50": 0.08884682385516313,
      "scr_dir1_threshold_100": 0.14839662830187836,
      "scr_metric_threshold_100": 0.12806622202034845,
      "scr_dir2_threshold_100": 0.11751418288613609,
      "scr_dir1_threshold_500": 0.03549208710185495,
      "scr_metric_threshold_500": 0.2026027259433407,
      "scr_dir2_threshold_500": 0.18630658067739778
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.2000006502324039,
      "scr_metric_threshold_2": 0.012254890502759344,
      "scr_dir2_threshold_2": 0.012254890502759344,
      "scr_dir1_threshold_5": 0.2545453954334178,
      "scr_metric_threshold_5": 0.024509781005518688,
      "scr_dir2_threshold_5": 0.024509781005518688,
      "scr_dir1_threshold_10": 0.2727280608877623,
      "scr_metric_threshold_10": 0.03431372262568984,
      "scr_dir2_threshold_10": 0.03431372262568984,
      "scr_dir1_threshold_20": 0.2909096426214336,
      "scr_metric_threshold_20": 0.046568613128449184,
      "scr_dir2_threshold_20": 0.046568613128449184,
      "scr_dir1_threshold_50": 0.2545453954334178,
      "scr_metric_threshold_50": 0.05392145977621377,
      "scr_dir2_threshold_50": 0.05392145977621377,
      "scr_dir1_threshold_100": 0.34545438782244753,
      "scr_metric_threshold_100": 0.06862744525137968,
      "scr_dir2_threshold_100": 0.06862744525137968,
      "scr_dir1_threshold_500": 0.30909122435510494,
      "scr_metric_threshold_500": 0.14460773715052394,
      "scr_dir2_threshold_500": 0.14460773715052394
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.10975611528989658,
      "scr_metric_threshold_2": 0.03038683903273859,
      "scr_dir2_threshold_2": 0.03038683903273859,
      "scr_dir1_threshold_5": 0.15853669173937948,
      "scr_metric_threshold_5": 0.06077351341178423,
      "scr_dir2_threshold_5": 0.06077351341178423,
      "scr_dir1_threshold_10": 0.18292661652124106,
      "scr_metric_threshold_10": 0.0828730027712863,
      "scr_dir2_threshold_10": 0.0828730027712863,
      "scr_dir1_threshold_20": -0.036584887172792374,
      "scr_metric_threshold_20": 0.10497249213078838,
      "scr_dir2_threshold_20": 0.10497249213078838,
      "scr_dir1_threshold_50": -0.048780576449482894,
      "scr_metric_threshold_50": 0.1077348871373029,
      "scr_dir2_threshold_50": 0.1077348871373029,
      "scr_dir1_threshold_100": -0.12195107768082737,
      "scr_metric_threshold_100": 0.1574586558693361,
      "scr_dir2_threshold_100": 0.1574586558693361,
      "scr_dir1_threshold_500": -1.0609755388404136,
      "scr_metric_threshold_500": 0.2182320046274274,
      "scr_dir2_threshold_500": 0.2182320046274274
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.1111105854971546,
      "scr_metric_threshold_2": 0.010309298938791562,
      "scr_dir2_threshold_2": 0.010309298938791562,
      "scr_dir1_threshold_5": 0.14285714285714285,
      "scr_metric_threshold_5": 0.010309298938791562,
      "scr_dir2_threshold_5": 0.010309298938791562,
      "scr_dir1_threshold_10": 0.25396772835429743,
      "scr_metric_threshold_10": 0.01804115792772476,
      "scr_dir2_threshold_10": 0.01804115792772476,
      "scr_dir1_threshold_20": 0.3333327025965855,
      "scr_metric_threshold_20": 0.020618597877583123,
      "scr_dir2_threshold_20": 0.020618597877583123,
      "scr_dir1_threshold_50": 0.36507925995657375,
      "scr_metric_threshold_50": -0.023195884207227523,
      "scr_dir2_threshold_50": -0.023195884207227523,
      "scr_dir1_threshold_100": 0.30158709134171896,
      "scr_metric_threshold_100": -0.012886585268435962,
      "scr_dir2_threshold_100": -0.012886585268435962,
      "scr_dir1_threshold_500": 0.20634931147199764,
      "scr_metric_threshold_500": 0.010309298938791562,
      "scr_dir2_threshold_500": 0.010309298938791562
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": -0.02777740984800821,
      "scr_metric_threshold_2": 0.005602168874487308,
      "scr_dir2_threshold_2": 0.005602168874487308,
      "scr_dir1_threshold_5": 0.0,
      "scr_metric_threshold_5": -0.008403420271523371,
      "scr_dir2_threshold_5": -0.008403420271523371,
      "scr_dir1_threshold_10": 0.12037043169199863,
      "scr_metric_threshold_10": -0.008403420271523371,
      "scr_dir2_threshold_10": -0.008403420271523371,
      "scr_dir1_threshold_20": -0.055555371590670775,
      "scr_metric_threshold_20": 0.039215683000788384,
      "scr_dir2_threshold_20": 0.039215683000788384,
      "scr_dir1_threshold_50": 0.12962956830800137,
      "scr_metric_threshold_50": 0.053221272146799066,
      "scr_dir2_threshold_50": 0.053221272146799066,
      "scr_dir1_threshold_100": -0.04629623497466803,
      "scr_metric_threshold_100": 0.08683478627310014,
      "scr_dir2_threshold_100": 0.08683478627310014,
      "scr_dir1_threshold_500": -0.25925913661600275,
      "scr_metric_threshold_500": 0.16246490087764084,
      "scr_dir2_threshold_500": 0.16246490087764084
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.04306221869601003,
      "scr_metric_threshold_2": 0.03030315540788283,
      "scr_dir2_threshold_2": 0.03030315540788283,
      "scr_dir1_threshold_5": 0.062201014248647775,
      "scr_metric_threshold_5": 0.07359315625163687,
      "scr_dir2_threshold_5": 0.07359315625163687,
      "scr_dir1_threshold_10": 0.0669856418393823,
      "scr_metric_threshold_10": 0.09523815667351389,
      "scr_dir2_threshold_10": 0.09523815667351389,
      "scr_dir1_threshold_20": 0.05263147387747908,
      "scr_metric_threshold_20": 0.1731602614037745,
      "scr_dir2_threshold_20": 0.1731602614037745,
      "scr_dir1_threshold_50": -0.004784627590734529,
      "scr_metric_threshold_50": 0.22510841723353434,
      "scr_dir2_threshold_50": 0.22510841723353434,
      "scr_dir1_threshold_100": 0.019138795552637748,
      "scr_metric_threshold_100": 0.26839841807728837,
      "scr_dir2_threshold_100": 0.26839841807728837,
      "scr_dir1_threshold_500": 0.12918665608803007,
      "scr_metric_threshold_500": 0.39393947212992675,
      "scr_dir2_threshold_500": 0.39393947212992675
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.032608921000528666,
      "scr_metric_threshold_2": 0.03265312676229035,
      "scr_dir2_threshold_2": 0.03265312676229035,
      "scr_dir1_threshold_5": 0.059782805875462586,
      "scr_metric_threshold_5": 0.048979690143435534,
      "scr_dir2_threshold_5": 0.048979690143435534,
      "scr_dir1_threshold_10": 0.10869586343799563,
      "scr_metric_threshold_10": 0.07346941357302347,
      "scr_dir2_threshold_10": 0.07346941357302347,
      "scr_dir1_threshold_20": 0.11413057562533041,
      "scr_metric_threshold_20": 0.11020412035953521,
      "scr_dir2_threshold_20": 0.11020412035953521,
      "scr_dir1_threshold_50": 0.16304363318786347,
      "scr_metric_threshold_50": 0.1673469705514135,
      "scr_dir2_threshold_50": 0.1673469705514135,
      "scr_dir1_threshold_100": 0.2228261151250661,
      "scr_metric_threshold_100": 0.1836735339325587,
      "scr_dir2_threshold_100": 0.1836735339325587,
      "scr_dir1_threshold_500": 0.3369566907503965,
      "scr_metric_threshold_500": 0.26938793086250595,
      "scr_dir2_threshold_500": 0.26938793086250595
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.02380950353583304,
      "scr_metric_threshold_2": 0.02620079266358024,
      "scr_dir2_threshold_2": 0.02620079266358024,
      "scr_dir1_threshold_5": 0.08095248232083481,
      "scr_metric_threshold_5": 0.0436680745333855,
      "scr_dir2_threshold_5": 0.0436680745333855,
      "scr_dir1_threshold_10": 0.11904751767916519,
      "scr_metric_threshold_10": 0.039301319136498,
      "scr_dir2_threshold_10": 0.039301319136498,
      "scr_dir1_threshold_20": 0.17619049646416696,
      "scr_metric_threshold_20": 0.06550211180007824,
      "scr_dir2_threshold_20": 0.06550211180007824,
      "scr_dir1_threshold_50": 0.26666666666666666,
      "scr_metric_threshold_50": 0.126637468203269,
      "scr_dir2_threshold_50": 0.126637468203269,
      "scr_dir1_threshold_100": 0.33809517727416577,
      "scr_metric_threshold_100": 0.14410475007307424,
      "scr_dir2_threshold_100": 0.14410475007307424,
      "scr_dir1_threshold_500": 0.41904765959500057,
      "scr_metric_threshold_500": 0.21834063294918274,
      "scr_dir2_threshold_500": 0.21834063294918274
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.0,
      "scr_metric_threshold_2": 0.0,
      "scr_dir2_threshold_2": 0.029268209002395525,
      "scr_dir1_threshold_5": 0.0309735785281926,
      "scr_metric_threshold_5": 0.0309735785281926,
      "scr_dir2_threshold_5": 0.0097559727493357,
      "scr_dir1_threshold_10": 0.04424800700275421,
      "scr_metric_threshold_10": 0.04424800700275421,
      "scr_dir2_threshold_10": -0.00487798637466785,
      "scr_dir1_threshold_20": 0.04424800700275421,
      "scr_metric_threshold_20": 0.04424800700275421,
      "scr_dir2_threshold_20": -0.00487798637466785,
      "scr_dir1_threshold_50": 0.09734519342629372,
      "scr_metric_threshold_50": 0.09734519342629372,
      "scr_dir2_threshold_50": 0.0,
      "scr_dir1_threshold_100": 0.12831877195448632,
      "scr_metric_threshold_100": 0.12831877195448632,
      "scr_dir2_threshold_100": 0.043902458880787504,
      "scr_dir1_threshold_500": 0.2035398300107262,
      "scr_metric_threshold_500": 0.2035398300107262,
      "scr_dir2_threshold_500": 0.07317066788318302
    }
  ],
  "sae_bench_commit_hash": "c5c90a136c8db8e704e401328a49b19932ad56c9",
  "sae_lens_id": "blocks.12.hook_resid_post",
  "sae_lens_release_id": "suchitg/sae-compression-gemma-2-2b-trained-sae-pile-wanda",
  "sae_lens_version": "5.6.1",
  "sae_cfg_dict": {
    "architecture": "jumprelu",
    "d_in": 2304,
    "d_sae": 16384,
    "activation_fn_str": "relu",
    "apply_b_dec_to_input": false,
    "finetuning_scaling_factor": false,
    "context_size": 1024,
    "model_name": "gemma-2-2b",
    "hook_name": "blocks.12.hook_resid_post",
    "hook_layer": 12,
    "hook_head_index": null,
    "prepend_bos": true,
    "dataset_path": "monology/pile-uncopyrighted",
    "dataset_trust_remote_code": true,
    "normalize_activations": "none",
    "dtype": "torch.bfloat16",
    "device": "cuda",
    "sae_lens_training_version": "5.5.2",
    "activation_fn_kwargs": {},
    "neuronpedia_id": null,
    "model_from_pretrained_kwargs": {
      "center_writing_weights": false
    },
    "seqpos_slice": [
      null
    ]
  },
  "eval_result_unstructured": null
}