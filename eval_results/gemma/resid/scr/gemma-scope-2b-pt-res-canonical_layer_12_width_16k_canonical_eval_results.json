{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 32,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": false,
    "model_name": "gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "e7921176-97d2-42cf-8483-23007338d437",
  "datetime_epoch_millis": 1742886910379,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.2863230689073931,
      "scr_metric_threshold_2": 0.11216291577714407,
      "scr_dir2_threshold_2": 0.10300038387924666,
      "scr_dir1_threshold_5": 0.31759458799210305,
      "scr_metric_threshold_5": 0.16979265796562634,
      "scr_dir2_threshold_5": 0.1605869325524831,
      "scr_dir1_threshold_10": 0.32219935642679415,
      "scr_metric_threshold_10": 0.2425282466540095,
      "scr_dir2_threshold_10": 0.23377582575789263,
      "scr_dir1_threshold_20": 0.2868114261270529,
      "scr_metric_threshold_20": 0.30387938969865413,
      "scr_dir2_threshold_20": 0.29258812062337836,
      "scr_dir1_threshold_50": 0.27789720900620185,
      "scr_metric_threshold_50": 0.3647426455559596,
      "scr_dir2_threshold_50": 0.3619448011211715,
      "scr_dir1_threshold_100": 0.2104945259076587,
      "scr_metric_threshold_100": 0.4007229534874084,
      "scr_dir2_threshold_100": 0.4058519096000527,
      "scr_dir1_threshold_500": 0.12558984619837726,
      "scr_metric_threshold_500": 0.3486043215737502,
      "scr_dir2_threshold_500": 0.3428979446778037
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.47272762739949303,
      "scr_metric_threshold_2": 0.036764671508278036,
      "scr_dir2_threshold_2": 0.036764671508278036,
      "scr_dir1_threshold_5": 0.4909092091331643,
      "scr_metric_threshold_5": 0.05147051089362557,
      "scr_dir2_threshold_5": 0.05147051089362557,
      "scr_dir1_threshold_10": 0.5272734563211802,
      "scr_metric_threshold_10": 0.05392145977621377,
      "scr_dir2_threshold_10": 0.05392145977621377,
      "scr_dir1_threshold_20": 0.41818179847780595,
      "scr_metric_threshold_20": 0.09313722625689837,
      "scr_dir2_threshold_20": 0.09313722625689837,
      "scr_dir1_threshold_50": 0.34545438782244753,
      "scr_metric_threshold_50": 0.11764700726241704,
      "scr_dir2_threshold_50": 0.11764700726241704,
      "scr_dir1_threshold_100": 0.2909096426214336,
      "scr_metric_threshold_100": 0.20588233575413903,
      "scr_dir2_threshold_100": 0.20588233575413903,
      "scr_dir1_threshold_500": -0.5818182015221941,
      "scr_metric_threshold_500": 0.2769607298881069,
      "scr_dir2_threshold_500": 0.2769607298881069
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.28048776942020687,
      "scr_metric_threshold_2": 0.18508293524186722,
      "scr_dir2_threshold_2": 0.18508293524186722,
      "scr_dir1_threshold_5": 0.28048776942020687,
      "scr_metric_threshold_5": 0.2071824246013693,
      "scr_dir2_threshold_5": 0.2071824246013693,
      "scr_dir1_threshold_10": 0.29268273181113763,
      "scr_metric_threshold_10": 0.2569060286797095,
      "scr_dir2_threshold_10": 0.2569060286797095,
      "scr_dir1_threshold_20": 0.21951223057979316,
      "scr_metric_threshold_20": 0.33149168177775934,
      "scr_dir2_threshold_20": 0.33149168177775934,
      "scr_dir1_threshold_50": -0.4268287718828958,
      "scr_metric_threshold_50": 0.4530387086013278,
      "scr_dir2_threshold_50": 0.4530387086013278,
      "scr_dir1_threshold_100": -0.5731705012313445,
      "scr_metric_threshold_100": 0.502762477333361,
      "scr_dir2_threshold_100": 0.502762477333361,
      "scr_dir1_threshold_500": 0.21951223057979316,
      "scr_metric_threshold_500": 0.22099456428763486,
      "scr_dir2_threshold_500": 0.22099456428763486
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.5079364028137167,
      "scr_metric_threshold_2": 0.03865975580530789,
      "scr_dir2_threshold_2": 0.03865975580530789,
      "scr_dir1_threshold_5": 0.5079364028137167,
      "scr_metric_threshold_5": 0.07989695156047413,
      "scr_dir2_threshold_5": 0.07989695156047413,
      "scr_dir1_threshold_10": 0.4603170398262951,
      "scr_metric_threshold_10": 0.11855670736578201,
      "scr_dir2_threshold_10": 0.11855670736578201,
      "scr_dir1_threshold_20": 0.4444442341988618,
      "scr_metric_threshold_20": 0.14432987790265395,
      "scr_dir2_threshold_20": 0.14432987790265395,
      "scr_dir1_threshold_50": 0.3333327025965855,
      "scr_metric_threshold_50": 0.2577320126091472,
      "scr_dir2_threshold_50": 0.2577320126091472,
      "scr_dir1_threshold_100": 0.26984148008685244,
      "scr_metric_threshold_100": 0.06443292634217981,
      "scr_dir2_threshold_100": 0.06443292634217981,
      "scr_dir1_threshold_500": -0.0634921686148548,
      "scr_metric_threshold_500": 0.01804115792772476,
      "scr_dir2_threshold_500": 0.01804115792772476
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.25925968851065706,
      "scr_metric_threshold_2": 0.08123245043882042,
      "scr_dir2_threshold_2": 0.08123245043882042,
      "scr_dir1_threshold_5": 0.2129629016413347,
      "scr_metric_threshold_5": 0.15406164756590987,
      "scr_dir2_threshold_5": 0.15406164756590987,
      "scr_dir1_threshold_10": 0.14814839343466119,
      "scr_metric_threshold_10": 0.22128850885871962,
      "scr_dir2_threshold_10": 0.22128850885871962,
      "scr_dir1_threshold_20": -0.03703654646401095,
      "scr_metric_threshold_20": 0.31092437956906344,
      "scr_dir2_threshold_20": 0.31092437956906344,
      "scr_dir1_threshold_50": 0.5925924699493361,
      "scr_metric_threshold_50": 0.3501400625698518,
      "scr_dir2_threshold_50": 0.3501400625698518,
      "scr_dir1_threshold_100": 0.5185188251266598,
      "scr_metric_threshold_100": 0.42296925969694127,
      "scr_dir2_threshold_100": 0.42296925969694127,
      "scr_dir1_threshold_500": 0.3981483934346612,
      "scr_metric_threshold_500": 0.14565822729438652,
      "scr_dir2_threshold_500": 0.14565822729438652
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.0669856418393823,
      "scr_metric_threshold_2": 0.07792210473026061,
      "scr_dir2_threshold_2": 0.07792210473026061,
      "scr_dir1_threshold_5": 0.09569369257348911,
      "scr_metric_threshold_5": 0.1731602614037745,
      "scr_dir2_threshold_5": 0.1731602614037745,
      "scr_dir1_threshold_10": 0.1052632329446578,
      "scr_metric_threshold_10": 0.4372294729736808,
      "scr_dir2_threshold_10": 0.4372294729736808,
      "scr_dir1_threshold_20": 0.08133980980128552,
      "scr_metric_threshold_20": 0.5541126300690717,
      "scr_dir2_threshold_20": 0.5541126300690717,
      "scr_dir1_threshold_50": 0.08133980980128552,
      "scr_metric_threshold_50": 0.6536797352212094,
      "scr_dir2_threshold_50": 0.6536797352212094,
      "scr_dir1_threshold_100": 0.07177026943011683,
      "scr_metric_threshold_100": 0.7186147364868404,
      "scr_dir2_threshold_100": 0.7186147364868404,
      "scr_dir1_threshold_500": 0.033492963514540966,
      "scr_metric_threshold_500": 0.7878789442598535,
      "scr_dir2_threshold_500": 0.7878789442598535
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.22826115125066082,
      "scr_metric_threshold_2": 0.0653062535245807,
      "scr_dir2_threshold_2": 0.0653062535245807,
      "scr_dir1_threshold_5": 0.3097828058754626,
      "scr_metric_threshold_5": 0.122449103716459,
      "scr_dir2_threshold_5": 0.122449103716459,
      "scr_dir1_threshold_10": 0.3369566907503965,
      "scr_metric_threshold_10": 0.15510223047874935,
      "scr_dir2_threshold_10": 0.15510223047874935,
      "scr_dir1_threshold_20": 0.3641305756253304,
      "scr_metric_threshold_20": 0.21632666069484904,
      "scr_dir2_threshold_20": 0.21632666069484904,
      "scr_dir1_threshold_50": 0.3967391726875991,
      "scr_metric_threshold_50": 0.33061236107860564,
      "scr_dir2_threshold_50": 0.33061236107860564,
      "scr_dir1_threshold_100": 0.4293480936881278,
      "scr_metric_threshold_100": 0.45306122151080497,
      "scr_dir2_threshold_100": 0.45306122151080497,
      "scr_dir1_threshold_500": 0.28260892100052865,
      "scr_metric_threshold_500": 0.5959184686326305,
      "scr_dir2_threshold_500": 0.5959184686326305
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.3333333333333333,
      "scr_metric_threshold_2": 0.2707422182763432,
      "scr_dir2_threshold_2": 0.2707422182763432,
      "scr_dir1_threshold_5": 0.45714297878500176,
      "scr_metric_threshold_5": 0.38427942028894974,
      "scr_dir2_threshold_5": 0.38427942028894974,
      "scr_dir1_threshold_10": 0.4857143262616673,
      "scr_metric_threshold_10": 0.4759825850348635,
      "scr_dir2_threshold_10": 0.4759825850348635,
      "scr_dir1_threshold_20": 0.5428573050466691,
      "scr_metric_threshold_20": 0.519650659568249,
      "scr_dir2_threshold_20": 0.519650659568249,
      "scr_dir1_threshold_50": 0.5952381560591675,
      "scr_metric_threshold_50": 0.449781532089028,
      "scr_dir2_threshold_50": 0.449781532089028,
      "scr_dir1_threshold_100": 0.3714286525233345,
      "scr_metric_threshold_100": 0.5327509257589115,
      "scr_dir2_threshold_100": 0.5327509257589115,
      "scr_dir1_threshold_500": 0.30476198585666786,
      "scr_metric_threshold_500": 0.33187783496178924,
      "scr_dir2_threshold_500": 0.33187783496178924
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.14159293669169445,
      "scr_metric_threshold_2": 0.14159293669169445,
      "scr_dir2_threshold_2": 0.06829268150851518,
      "scr_dir1_threshold_5": 0.18584094369444867,
      "scr_metric_threshold_5": 0.18584094369444867,
      "scr_dir2_threshold_5": 0.11219514038930269,
      "scr_dir1_threshold_10": 0.2212389800643572,
      "scr_metric_threshold_10": 0.2212389800643572,
      "scr_dir2_threshold_10": 0.15121961289542232,
      "scr_dir1_threshold_20": 0.26106200175068855,
      "scr_metric_threshold_20": 0.26106200175068855,
      "scr_dir2_threshold_20": 0.17073184914848216,
      "scr_dir1_threshold_50": 0.3053097450160893,
      "scr_metric_threshold_50": 0.3053097450160893,
      "scr_dir2_threshold_50": 0.28292698953778483,
      "scr_dir1_threshold_100": 0.3053097450160893,
      "scr_metric_threshold_100": 0.3053097450160893,
      "scr_dir2_threshold_100": 0.3463413939172437,
      "scr_dir1_threshold_500": 0.41150464533787523,
      "scr_metric_threshold_500": 0.41150464533787523,
      "scr_dir2_threshold_500": 0.3658536301703036
    }
  ],
  "sae_bench_commit_hash": "c5c90a136c8db8e704e401328a49b19932ad56c9",
  "sae_lens_id": "layer_12/width_16k/canonical",
  "sae_lens_release_id": "gemma-scope-2b-pt-res-canonical",
  "sae_lens_version": "5.6.1",
  "sae_cfg_dict": {
    "architecture": "jumprelu",
    "d_in": 2304,
    "d_sae": 16384,
    "activation_fn_str": "relu",
    "apply_b_dec_to_input": false,
    "finetuning_scaling_factor": false,
    "context_size": 1024,
    "model_name": "gemma-2-2b",
    "hook_name": "blocks.12.hook_resid_post",
    "hook_layer": 12,
    "hook_head_index": null,
    "prepend_bos": true,
    "dataset_path": "monology/pile-uncopyrighted",
    "dataset_trust_remote_code": true,
    "normalize_activations": null,
    "dtype": "torch.bfloat16",
    "device": "cuda",
    "sae_lens_training_version": null,
    "activation_fn_kwargs": {},
    "neuronpedia_id": "gemma-2-2b/12-gemmascope-res-16k",
    "model_from_pretrained_kwargs": {},
    "seqpos_slice": [
      null
    ]
  },
  "eval_result_unstructured": null
}