2025-03-08 18:53:36,787 - INFO - Using device: cuda:3
2025-03-08 18:53:39,353 - INFO - Loaded wanda pruned gpt-2 small
2025-03-08 18:53:40,320 - INFO - Loaded calibration dataset: wiki
2025-03-08 18:55:46,351 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 11.6548, and Test loss: 11.8987
2025-03-08 18:57:36,058 - INFO - Before pruning pretrained SAE, Validation loss: 7.6497, and Test loss: 7.6443
2025-03-08 18:57:36,060 - INFO - Pruning for layer: 0
2025-03-08 18:57:36,060 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.0.hook_z
2025-03-08 18:57:36,060 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.0.attn.hook_z-attn-sae-v1
2025-03-08 18:59:21,483 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 4.8366
2025-03-08 18:59:21,738 - INFO - Resetting pretrained SAE
2025-03-08 19:01:07,009 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 6.2948
2025-03-08 19:01:07,453 - INFO - Resetting pretrained SAE
2025-03-08 19:02:53,012 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 7.4471
2025-03-08 19:02:53,283 - INFO - Resetting pretrained SAE
2025-03-08 19:04:39,586 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 7.7301
2025-03-08 19:04:39,945 - INFO - Resetting pretrained SAE
2025-03-08 19:06:26,150 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 7.9232
2025-03-08 19:06:26,379 - INFO - Resetting pretrained SAE
2025-03-08 19:08:13,097 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 8.0174
2025-03-08 19:08:13,422 - INFO - Resetting pretrained SAE
2025-03-08 19:09:59,907 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 8.1167
2025-03-08 19:10:04,724 - INFO - Resetting pretrained SAE
2025-03-08 19:11:50,041 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 8.0938
2025-03-08 19:11:50,269 - INFO - Resetting pretrained SAE
2025-03-08 19:13:36,924 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 8.0784
2025-03-08 19:13:37,172 - INFO - Resetting pretrained SAE
2025-03-08 19:15:23,232 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 8.0507
2025-03-08 19:15:23,455 - INFO - Resetting pretrained SAE
2025-03-08 19:17:08,995 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 8.0205
2025-03-08 19:17:09,272 - INFO - Resetting pretrained SAE
2025-03-08 19:18:55,463 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 7.9782
2025-03-08 19:18:55,711 - INFO - Resetting pretrained SAE
2025-03-08 19:20:42,143 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 7.9377
2025-03-08 19:20:42,383 - INFO - Resetting pretrained SAE
2025-03-08 19:22:29,944 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 7.9188
2025-03-08 19:22:30,174 - INFO - Resetting pretrained SAE
2025-03-08 19:24:17,717 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 7.8914
2025-03-08 19:24:17,948 - INFO - Resetting pretrained SAE
2025-03-08 19:26:04,884 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 7.8652
2025-03-08 19:26:05,120 - INFO - Resetting pretrained SAE
2025-03-08 19:27:52,182 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 7.8474
2025-03-08 19:27:52,488 - INFO - Resetting pretrained SAE
2025-03-08 19:29:39,501 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 7.8297
2025-03-08 19:29:39,741 - INFO - Resetting pretrained SAE
2025-03-08 19:31:25,331 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 7.8322
2025-03-08 19:31:25,565 - INFO - Resetting pretrained SAE
2025-03-08 19:33:12,500 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 7.8143
2025-03-08 19:33:12,721 - INFO - Resetting pretrained SAE
2025-03-08 19:35:00,632 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 7.8064
2025-03-08 19:35:00,880 - INFO - Resetting pretrained SAE
2025-03-08 19:36:48,763 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 7.7847
2025-03-08 19:36:48,996 - INFO - Resetting pretrained SAE
2025-03-08 19:38:36,347 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 7.7733
2025-03-08 19:38:36,573 - INFO - Resetting pretrained SAE
2025-03-08 19:40:23,993 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 7.7645
2025-03-08 19:40:24,538 - INFO - Resetting pretrained SAE
2025-03-08 19:42:11,462 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 7.7531
2025-03-08 19:42:11,681 - INFO - Resetting pretrained SAE
2025-03-08 19:43:59,122 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 7.7471
2025-03-08 19:43:59,343 - INFO - Resetting pretrained SAE
2025-03-08 19:45:46,202 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 7.7351
2025-03-08 19:45:46,447 - INFO - Resetting pretrained SAE
2025-03-08 19:47:33,890 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 7.7224
2025-03-08 19:47:34,129 - INFO - Resetting pretrained SAE
2025-03-08 19:49:22,395 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 7.7163
2025-03-08 19:49:22,624 - INFO - Resetting pretrained SAE
2025-03-08 19:51:09,138 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 7.7032
2025-03-08 19:51:09,420 - INFO - Resetting pretrained SAE
2025-03-08 19:52:55,222 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 7.6923
2025-03-08 19:52:55,449 - INFO - Resetting pretrained SAE
2025-03-08 19:54:42,760 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 7.6831
2025-03-08 19:54:42,978 - INFO - Resetting pretrained SAE
2025-03-08 19:56:30,108 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 7.6764
2025-03-08 19:56:30,347 - INFO - Resetting pretrained SAE
2025-03-08 19:58:16,817 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 7.6737
2025-03-08 19:58:17,068 - INFO - Resetting pretrained SAE
2025-03-08 20:00:03,097 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 7.6698
2025-03-08 20:00:03,338 - INFO - Resetting pretrained SAE
2025-03-08 20:01:49,652 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 7.6647
2025-03-08 20:01:51,067 - INFO - Resetting pretrained SAE
2025-03-08 20:03:38,248 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 7.6613
2025-03-08 20:03:38,479 - INFO - Resetting pretrained SAE
2025-03-08 20:05:24,577 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 7.6558
2025-03-08 20:05:24,939 - INFO - Resetting pretrained SAE
2025-03-08 20:05:24,943 - INFO - For layer 0, the best Sparse Ratio: 0.99 with validation loss: 4.8366
2025-03-08 20:05:47,012 - INFO - After pruning pretrained SAE, Validation loss: 4.8366, and Test loss: 4.9906
2025-03-08 20:07:38,306 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 7.984, and Test loss: 8.0709
2025-03-08 20:09:29,573 - INFO - Before pruning pretrained SAE, Validation loss: 5.2103, and Test loss: 5.3977
2025-03-08 20:09:29,575 - INFO - Pruning for layer: 1
2025-03-08 20:09:29,575 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.1.hook_z
2025-03-08 20:09:29,575 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.1.attn.hook_z-attn-sae-v1
2025-03-08 20:11:15,135 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 3.7554
2025-03-08 20:11:15,379 - INFO - Resetting pretrained SAE
2025-03-08 20:13:02,358 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 4.5836
2025-03-08 20:13:02,598 - INFO - Resetting pretrained SAE
2025-03-08 20:14:50,434 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 4.6803
2025-03-08 20:14:50,930 - INFO - Resetting pretrained SAE
2025-03-08 20:16:39,717 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 4.6873
2025-03-08 20:16:39,959 - INFO - Resetting pretrained SAE
2025-03-08 20:18:27,531 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 4.6388
2025-03-08 20:18:27,755 - INFO - Resetting pretrained SAE
2025-03-08 20:20:14,456 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 4.5613
2025-03-08 20:20:14,698 - INFO - Resetting pretrained SAE
2025-03-08 20:22:02,108 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 4.5471
2025-03-08 20:22:02,399 - INFO - Resetting pretrained SAE
2025-03-08 20:23:48,729 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 4.5735
2025-03-08 20:23:48,975 - INFO - Resetting pretrained SAE
2025-03-08 20:25:35,323 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 4.6374
2025-03-08 20:25:35,578 - INFO - Resetting pretrained SAE
2025-03-08 20:27:22,167 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 4.6951
2025-03-08 20:27:22,392 - INFO - Resetting pretrained SAE
2025-03-08 20:29:10,128 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 4.7045
2025-03-08 20:29:10,343 - INFO - Resetting pretrained SAE
2025-03-08 20:30:57,509 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 4.7605
2025-03-08 20:30:57,740 - INFO - Resetting pretrained SAE
2025-03-08 20:32:44,383 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 4.7921
2025-03-08 20:32:44,609 - INFO - Resetting pretrained SAE
2025-03-08 20:34:30,138 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 4.8106
2025-03-08 20:34:30,402 - INFO - Resetting pretrained SAE
2025-03-08 20:36:16,549 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 4.9121
2025-03-08 20:36:16,778 - INFO - Resetting pretrained SAE
2025-03-08 20:38:03,796 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 4.9682
2025-03-08 20:38:04,028 - INFO - Resetting pretrained SAE
2025-03-08 20:39:50,479 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 5.026
2025-03-08 20:39:50,704 - INFO - Resetting pretrained SAE
2025-03-08 20:41:37,021 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 5.0217
2025-03-08 20:41:37,256 - INFO - Resetting pretrained SAE
2025-03-08 20:43:24,888 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 5.0866
2025-03-08 20:43:25,188 - INFO - Resetting pretrained SAE
2025-03-08 20:45:12,750 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 5.1163
2025-03-08 20:45:13,066 - INFO - Resetting pretrained SAE
2025-03-08 20:47:00,106 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 5.1227
2025-03-08 20:47:00,368 - INFO - Resetting pretrained SAE
2025-03-08 20:48:48,588 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 5.1469
2025-03-08 20:48:48,831 - INFO - Resetting pretrained SAE
2025-03-08 20:50:35,898 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 5.1267
2025-03-08 20:50:36,134 - INFO - Resetting pretrained SAE
2025-03-08 20:52:21,899 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 5.1981
2025-03-08 20:52:22,213 - INFO - Resetting pretrained SAE
2025-03-08 20:54:09,340 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 5.1843
2025-03-08 20:54:09,580 - INFO - Resetting pretrained SAE
2025-03-08 20:55:56,866 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 5.1885
2025-03-08 20:55:57,109 - INFO - Resetting pretrained SAE
2025-03-08 20:57:44,414 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 5.1984
2025-03-08 20:57:44,646 - INFO - Resetting pretrained SAE
2025-03-08 20:59:31,550 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 5.1857
2025-03-08 20:59:31,850 - INFO - Resetting pretrained SAE
2025-03-08 21:01:18,831 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 5.1988
2025-03-08 21:01:19,135 - INFO - Resetting pretrained SAE
2025-03-08 21:03:04,011 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 5.1917
2025-03-08 21:03:04,268 - INFO - Resetting pretrained SAE
2025-03-08 21:04:50,431 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 5.1978
2025-03-08 21:04:50,661 - INFO - Resetting pretrained SAE
2025-03-08 21:06:37,230 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 5.1986
2025-03-08 21:06:37,575 - INFO - Resetting pretrained SAE
2025-03-08 21:08:23,552 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 5.1842
2025-03-08 21:08:23,786 - INFO - Resetting pretrained SAE
2025-03-08 21:10:10,620 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 5.1885
2025-03-08 21:10:10,921 - INFO - Resetting pretrained SAE
2025-03-08 21:11:56,850 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 5.182
2025-03-08 21:11:57,098 - INFO - Resetting pretrained SAE
2025-03-08 21:13:42,799 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 5.1815
2025-03-08 21:13:43,027 - INFO - Resetting pretrained SAE
2025-03-08 21:15:30,883 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 5.1765
2025-03-08 21:15:31,132 - INFO - Resetting pretrained SAE
2025-03-08 21:17:18,184 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 5.1866
2025-03-08 21:17:18,434 - INFO - Resetting pretrained SAE
2025-03-08 21:17:18,440 - INFO - For layer 1, the best Sparse Ratio: 0.99 with validation loss: 3.7554
2025-03-08 21:17:39,224 - INFO - After pruning pretrained SAE, Validation loss: 3.7554, and Test loss: 3.8113
2025-03-08 21:19:30,568 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.7422, and Test loss: 3.864
2025-03-08 21:21:21,409 - INFO - Before pruning pretrained SAE, Validation loss: 5.0332, and Test loss: 5.1418
2025-03-08 21:21:21,410 - INFO - Pruning for layer: 2
2025-03-08 21:21:21,410 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.2.hook_z
2025-03-08 21:21:21,410 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.2.attn.hook_z-attn-sae-v1
2025-03-08 21:23:08,914 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9421
2025-03-08 21:23:09,143 - INFO - Resetting pretrained SAE
2025-03-08 21:24:56,555 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.9559
2025-03-08 21:24:56,796 - INFO - Resetting pretrained SAE
2025-03-08 21:26:43,515 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 3.0463
2025-03-08 21:26:43,733 - INFO - Resetting pretrained SAE
2025-03-08 21:28:30,128 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 3.1009
2025-03-08 21:28:30,354 - INFO - Resetting pretrained SAE
2025-03-08 21:30:16,034 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 3.1485
2025-03-08 21:30:16,275 - INFO - Resetting pretrained SAE
2025-03-08 21:32:02,393 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 3.2956
2025-03-08 21:32:02,640 - INFO - Resetting pretrained SAE
2025-03-08 21:33:48,144 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 3.4087
2025-03-08 21:33:48,369 - INFO - Resetting pretrained SAE
2025-03-08 21:35:34,416 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 3.5484
2025-03-08 21:35:34,696 - INFO - Resetting pretrained SAE
2025-03-08 21:37:20,471 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 3.6884
2025-03-08 21:37:20,706 - INFO - Resetting pretrained SAE
2025-03-08 21:39:08,323 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 3.8024
2025-03-08 21:39:08,564 - INFO - Resetting pretrained SAE
2025-03-08 21:40:55,439 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 3.8049
2025-03-08 21:40:55,664 - INFO - Resetting pretrained SAE
2025-03-08 21:42:41,821 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 3.8979
2025-03-08 21:42:42,127 - INFO - Resetting pretrained SAE
2025-03-08 21:44:28,784 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 3.9375
2025-03-08 21:44:29,013 - INFO - Resetting pretrained SAE
2025-03-08 21:46:14,156 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 3.9814
2025-03-08 21:46:14,390 - INFO - Resetting pretrained SAE
2025-03-08 21:48:00,378 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 3.9982
2025-03-08 21:48:00,604 - INFO - Resetting pretrained SAE
2025-03-08 21:49:46,852 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 4.0386
2025-03-08 21:49:47,077 - INFO - Resetting pretrained SAE
2025-03-08 21:51:33,646 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 4.057
2025-03-08 21:51:33,866 - INFO - Resetting pretrained SAE
2025-03-08 21:53:21,415 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 4.0518
2025-03-08 21:53:21,627 - INFO - Resetting pretrained SAE
2025-03-08 21:55:08,838 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 4.0912
2025-03-08 21:55:09,072 - INFO - Resetting pretrained SAE
2025-03-08 21:56:54,764 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 4.1259
2025-03-08 21:56:55,087 - INFO - Resetting pretrained SAE
2025-03-08 21:58:41,862 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 4.1527
2025-03-08 21:58:42,176 - INFO - Resetting pretrained SAE
2025-03-08 22:00:27,541 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 4.2048
2025-03-08 22:00:27,826 - INFO - Resetting pretrained SAE
2025-03-08 22:02:14,576 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 4.2817
2025-03-08 22:02:14,811 - INFO - Resetting pretrained SAE
2025-03-08 22:04:01,287 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 4.2997
2025-03-08 22:04:01,524 - INFO - Resetting pretrained SAE
2025-03-08 22:05:48,251 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 4.3382
2025-03-08 22:05:48,485 - INFO - Resetting pretrained SAE
2025-03-08 22:07:32,776 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 4.3924
2025-03-08 22:07:33,050 - INFO - Resetting pretrained SAE
2025-03-08 22:09:19,436 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 4.4318
2025-03-08 22:09:19,678 - INFO - Resetting pretrained SAE
2025-03-08 22:11:06,557 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 4.4725
2025-03-08 22:11:06,800 - INFO - Resetting pretrained SAE
2025-03-08 22:12:53,140 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 4.5113
2025-03-08 22:12:53,421 - INFO - Resetting pretrained SAE
2025-03-08 22:14:38,971 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 4.5521
2025-03-08 22:14:39,196 - INFO - Resetting pretrained SAE
2025-03-08 22:16:25,373 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 4.5852
2025-03-08 22:16:25,597 - INFO - Resetting pretrained SAE
2025-03-08 22:18:12,006 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 4.5839
2025-03-08 22:18:12,239 - INFO - Resetting pretrained SAE
2025-03-08 22:19:57,906 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 4.5878
2025-03-08 22:19:58,237 - INFO - Resetting pretrained SAE
2025-03-08 22:21:44,821 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 4.6097
2025-03-08 22:21:45,057 - INFO - Resetting pretrained SAE
2025-03-08 22:23:29,997 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 4.6234
2025-03-08 22:23:30,225 - INFO - Resetting pretrained SAE
2025-03-08 22:25:17,938 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 4.6581
2025-03-08 22:25:18,188 - INFO - Resetting pretrained SAE
2025-03-08 22:27:04,022 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 4.6837
2025-03-08 22:27:04,252 - INFO - Resetting pretrained SAE
2025-03-08 22:28:51,204 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 4.731
2025-03-08 22:28:51,423 - INFO - Resetting pretrained SAE
2025-03-08 22:28:51,426 - INFO - For layer 2, the best Sparse Ratio: 0.99 with validation loss: 2.9421
2025-03-08 22:29:12,387 - INFO - After pruning pretrained SAE, Validation loss: 2.9421, and Test loss: 3.0438
2025-03-08 22:31:03,731 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.9178, and Test loss: 3.013
2025-03-08 22:32:55,473 - INFO - Before pruning pretrained SAE, Validation loss: 2.9535, and Test loss: 3.04
2025-03-08 22:32:55,474 - INFO - Pruning for layer: 3
2025-03-08 22:32:55,474 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.3.hook_z
2025-03-08 22:32:55,474 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.3.attn.hook_z-attn-sae-v1
2025-03-08 22:34:42,814 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9354
2025-03-08 22:34:43,070 - INFO - Resetting pretrained SAE
2025-03-08 22:36:29,743 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.9352
2025-03-08 22:36:29,961 - INFO - Resetting pretrained SAE
2025-03-08 22:38:16,804 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.9346
2025-03-08 22:38:17,035 - INFO - Resetting pretrained SAE
2025-03-08 22:40:01,825 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9347
2025-03-08 22:40:02,145 - INFO - Resetting pretrained SAE
2025-03-08 22:41:48,950 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.9343
2025-03-08 22:41:49,243 - INFO - Resetting pretrained SAE
2025-03-08 22:43:36,713 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.9343
2025-03-08 22:43:36,946 - INFO - Resetting pretrained SAE
2025-03-08 22:45:23,667 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.9334
2025-03-08 22:45:23,887 - INFO - Resetting pretrained SAE
2025-03-08 22:47:10,372 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.9341
2025-03-08 22:47:10,590 - INFO - Resetting pretrained SAE
2025-03-08 22:48:59,295 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.934
2025-03-08 22:48:59,658 - INFO - Resetting pretrained SAE
2025-03-08 22:50:45,951 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.9342
2025-03-08 22:50:46,245 - INFO - Resetting pretrained SAE
2025-03-08 22:52:32,144 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.933
2025-03-08 22:52:32,435 - INFO - Resetting pretrained SAE
2025-03-08 22:54:19,195 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.9345
2025-03-08 22:54:19,429 - INFO - Resetting pretrained SAE
2025-03-08 22:56:06,665 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.9358
2025-03-08 22:56:06,907 - INFO - Resetting pretrained SAE
2025-03-08 22:57:53,712 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.9358
2025-03-08 22:57:53,953 - INFO - Resetting pretrained SAE
2025-03-08 22:59:41,051 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.936
2025-03-08 22:59:41,282 - INFO - Resetting pretrained SAE
2025-03-08 23:01:29,132 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9394
2025-03-08 23:01:29,406 - INFO - Resetting pretrained SAE
2025-03-08 23:03:16,556 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9406
2025-03-08 23:03:16,964 - INFO - Resetting pretrained SAE
2025-03-08 23:05:02,806 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.944
2025-03-08 23:05:03,076 - INFO - Resetting pretrained SAE
2025-03-08 23:06:48,903 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9456
2025-03-08 23:06:49,123 - INFO - Resetting pretrained SAE
2025-03-08 23:08:35,531 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9437
2025-03-08 23:08:35,781 - INFO - Resetting pretrained SAE
2025-03-08 23:10:21,069 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.9436
2025-03-08 23:10:21,330 - INFO - Resetting pretrained SAE
2025-03-08 23:12:08,508 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9523
2025-03-08 23:12:08,742 - INFO - Resetting pretrained SAE
2025-03-08 23:13:55,640 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.9445
2025-03-08 23:13:55,868 - INFO - Resetting pretrained SAE
2025-03-08 23:15:41,556 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9611
2025-03-08 23:15:41,829 - INFO - Resetting pretrained SAE
2025-03-08 23:17:28,470 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.9664
2025-03-08 23:17:28,763 - INFO - Resetting pretrained SAE
2025-03-08 23:19:16,965 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.9748
2025-03-08 23:19:17,196 - INFO - Resetting pretrained SAE
2025-03-08 23:21:02,773 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.9611
2025-03-08 23:21:03,002 - INFO - Resetting pretrained SAE
2025-03-08 23:22:48,849 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.9704
2025-03-08 23:22:49,070 - INFO - Resetting pretrained SAE
2025-03-08 23:24:35,544 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.9702
2025-03-08 23:24:35,955 - INFO - Resetting pretrained SAE
2025-03-08 23:26:21,922 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.9831
2025-03-08 23:26:22,214 - INFO - Resetting pretrained SAE
2025-03-08 23:28:08,301 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.9616
2025-03-08 23:28:08,529 - INFO - Resetting pretrained SAE
2025-03-08 23:29:55,124 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.9637
2025-03-08 23:29:55,359 - INFO - Resetting pretrained SAE
2025-03-08 23:31:41,902 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9655
2025-03-08 23:31:42,129 - INFO - Resetting pretrained SAE
2025-03-08 23:33:29,737 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9648
2025-03-08 23:33:30,002 - INFO - Resetting pretrained SAE
2025-03-08 23:35:16,170 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.9598
2025-03-08 23:35:16,775 - INFO - Resetting pretrained SAE
2025-03-08 23:37:03,708 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9599
2025-03-08 23:37:03,950 - INFO - Resetting pretrained SAE
2025-03-08 23:38:50,253 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.9542
2025-03-08 23:38:50,507 - INFO - Resetting pretrained SAE
2025-03-08 23:40:36,611 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9581
2025-03-08 23:40:36,868 - INFO - Resetting pretrained SAE
2025-03-08 23:40:36,871 - INFO - For layer 3, the best Sparse Ratio: 0.79 with validation loss: 2.933
2025-03-08 23:40:57,047 - INFO - After pruning pretrained SAE, Validation loss: 2.933, and Test loss: 3.0305
2025-03-08 23:42:48,756 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.5533, and Test loss: 3.471
2025-03-08 23:44:39,997 - INFO - Before pruning pretrained SAE, Validation loss: 2.9265, and Test loss: 3.0219
2025-03-08 23:44:39,998 - INFO - Pruning for layer: 4
2025-03-08 23:44:39,998 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.4.hook_z
2025-03-08 23:44:39,998 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.4.attn.hook_z-attn-sae-v1
2025-03-08 23:46:25,283 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9526
2025-03-08 23:46:25,538 - INFO - Resetting pretrained SAE
2025-03-08 23:48:11,991 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.9524
2025-03-08 23:48:12,210 - INFO - Resetting pretrained SAE
2025-03-08 23:49:57,927 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.9519
2025-03-08 23:49:58,156 - INFO - Resetting pretrained SAE
2025-03-08 23:51:44,251 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9512
2025-03-08 23:51:44,475 - INFO - Resetting pretrained SAE
2025-03-08 23:53:30,587 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.9505
2025-03-08 23:53:30,843 - INFO - Resetting pretrained SAE
2025-03-08 23:55:17,407 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.9499
2025-03-08 23:55:17,660 - INFO - Resetting pretrained SAE
2025-03-08 23:57:04,567 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.9489
2025-03-08 23:57:04,774 - INFO - Resetting pretrained SAE
2025-03-08 23:58:51,120 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.948
2025-03-08 23:58:51,339 - INFO - Resetting pretrained SAE
2025-03-09 00:00:37,955 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.9472
2025-03-09 00:00:38,182 - INFO - Resetting pretrained SAE
2025-03-09 00:02:24,215 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.9462
2025-03-09 00:02:24,513 - INFO - Resetting pretrained SAE
2025-03-09 00:04:09,716 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.9455
2025-03-09 00:04:09,951 - INFO - Resetting pretrained SAE
2025-03-09 00:05:55,301 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.9449
2025-03-09 00:05:55,545 - INFO - Resetting pretrained SAE
2025-03-09 00:07:41,635 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.9439
2025-03-09 00:07:41,868 - INFO - Resetting pretrained SAE
2025-03-09 00:09:27,557 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.9433
2025-03-09 00:09:27,780 - INFO - Resetting pretrained SAE
2025-03-09 00:11:15,883 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.9427
2025-03-09 00:11:16,112 - INFO - Resetting pretrained SAE
2025-03-09 00:13:01,325 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9419
2025-03-09 00:13:01,576 - INFO - Resetting pretrained SAE
2025-03-09 00:14:46,770 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9413
2025-03-09 00:14:46,999 - INFO - Resetting pretrained SAE
2025-03-09 00:16:33,413 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.9408
2025-03-09 00:16:33,637 - INFO - Resetting pretrained SAE
2025-03-09 00:18:19,565 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9402
2025-03-09 00:18:19,834 - INFO - Resetting pretrained SAE
2025-03-09 00:20:06,312 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9396
2025-03-09 00:20:06,531 - INFO - Resetting pretrained SAE
2025-03-09 00:21:52,331 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.9392
2025-03-09 00:21:52,547 - INFO - Resetting pretrained SAE
2025-03-09 00:23:38,411 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9386
2025-03-09 00:23:38,687 - INFO - Resetting pretrained SAE
2025-03-09 00:25:25,558 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.938
2025-03-09 00:25:25,783 - INFO - Resetting pretrained SAE
2025-03-09 00:27:11,646 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9375
2025-03-09 00:27:11,861 - INFO - Resetting pretrained SAE
2025-03-09 00:28:57,440 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.9368
2025-03-09 00:28:57,745 - INFO - Resetting pretrained SAE
2025-03-09 00:30:45,266 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.936
2025-03-09 00:30:45,493 - INFO - Resetting pretrained SAE
2025-03-09 00:32:30,506 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.9353
2025-03-09 00:32:30,764 - INFO - Resetting pretrained SAE
2025-03-09 00:34:15,811 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.9347
2025-03-09 00:34:16,051 - INFO - Resetting pretrained SAE
2025-03-09 00:36:01,234 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.934
2025-03-09 00:36:01,469 - INFO - Resetting pretrained SAE
2025-03-09 00:37:47,211 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.9335
2025-03-09 00:37:47,445 - INFO - Resetting pretrained SAE
2025-03-09 00:39:34,275 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.9328
2025-03-09 00:39:35,377 - INFO - Resetting pretrained SAE
2025-03-09 00:41:20,847 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.9324
2025-03-09 00:41:21,196 - INFO - Resetting pretrained SAE
2025-03-09 00:43:07,771 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9318
2025-03-09 00:43:08,114 - INFO - Resetting pretrained SAE
2025-03-09 00:44:54,445 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9312
2025-03-09 00:44:54,766 - INFO - Resetting pretrained SAE
2025-03-09 00:46:39,468 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.9305
2025-03-09 00:46:39,709 - INFO - Resetting pretrained SAE
2025-03-09 00:48:25,566 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9298
2025-03-09 00:48:25,796 - INFO - Resetting pretrained SAE
2025-03-09 00:50:11,692 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.9293
2025-03-09 00:50:11,924 - INFO - Resetting pretrained SAE
2025-03-09 00:51:58,522 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9289
2025-03-09 00:51:58,746 - INFO - Resetting pretrained SAE
2025-03-09 00:51:58,749 - INFO - For layer 4, the best Sparse Ratio: 0.25 with validation loss: 2.9289
2025-03-09 00:52:19,084 - INFO - After pruning pretrained SAE, Validation loss: 2.9289, and Test loss: 3.0244
2025-03-09 00:54:10,692 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.9556, and Test loss: 3.058
2025-03-09 00:56:05,766 - INFO - Before pruning pretrained SAE, Validation loss: 3.2956, and Test loss: 3.4152
2025-03-09 00:56:05,767 - INFO - Pruning for layer: 5
2025-03-09 00:56:05,767 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.5.hook_z
2025-03-09 00:56:05,767 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.5.attn.hook_z-attn-sae-v1
2025-03-09 00:57:56,668 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 3.6566
2025-03-09 00:57:57,107 - INFO - Resetting pretrained SAE
2025-03-09 00:59:47,450 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 4.1425
2025-03-09 00:59:47,824 - INFO - Resetting pretrained SAE
2025-03-09 01:01:38,294 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 4.6684
2025-03-09 01:01:38,682 - INFO - Resetting pretrained SAE
2025-03-09 01:03:29,261 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 4.5468
2025-03-09 01:03:29,665 - INFO - Resetting pretrained SAE
2025-03-09 01:05:19,890 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 4.3186
2025-03-09 01:05:20,276 - INFO - Resetting pretrained SAE
2025-03-09 01:07:09,902 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 4.2442
2025-03-09 01:07:10,289 - INFO - Resetting pretrained SAE
2025-03-09 01:09:01,537 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 4.2995
2025-03-09 01:09:01,945 - INFO - Resetting pretrained SAE
2025-03-09 01:10:52,396 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 4.0935
2025-03-09 01:10:52,923 - INFO - Resetting pretrained SAE
2025-03-09 01:12:44,122 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 4.0857
2025-03-09 01:12:44,501 - INFO - Resetting pretrained SAE
2025-03-09 01:14:36,603 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 4.0318
2025-03-09 01:14:40,324 - INFO - Resetting pretrained SAE
2025-03-09 01:16:30,423 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 3.9723
2025-03-09 01:16:30,811 - INFO - Resetting pretrained SAE
2025-03-09 01:18:21,752 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 4.0483
2025-03-09 01:18:22,126 - INFO - Resetting pretrained SAE
2025-03-09 01:20:11,671 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 3.9822
2025-03-09 01:20:12,043 - INFO - Resetting pretrained SAE
2025-03-09 01:22:03,133 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 3.9995
2025-03-09 01:22:03,539 - INFO - Resetting pretrained SAE
2025-03-09 01:23:55,261 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 4.0986
2025-03-09 01:23:55,644 - INFO - Resetting pretrained SAE
2025-03-09 01:25:47,481 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 4.2627
2025-03-09 01:25:47,868 - INFO - Resetting pretrained SAE
2025-03-09 01:27:39,341 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 4.1521
2025-03-09 01:27:39,723 - INFO - Resetting pretrained SAE
2025-03-09 01:29:31,169 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 4.22
2025-03-09 01:29:31,550 - INFO - Resetting pretrained SAE
2025-03-09 01:31:22,452 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 4.0396
2025-03-09 01:31:22,845 - INFO - Resetting pretrained SAE
2025-03-09 01:33:13,839 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 4.1881
2025-03-09 01:33:14,239 - INFO - Resetting pretrained SAE
2025-03-09 01:35:06,562 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 4.0782
2025-03-09 01:35:06,956 - INFO - Resetting pretrained SAE
2025-03-09 01:36:57,083 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 4.2515
2025-03-09 01:36:57,469 - INFO - Resetting pretrained SAE
2025-03-09 01:38:48,406 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 4.2285
2025-03-09 01:38:48,817 - INFO - Resetting pretrained SAE
2025-03-09 01:40:39,253 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 4.1898
2025-03-09 01:40:39,674 - INFO - Resetting pretrained SAE
2025-03-09 01:42:31,510 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 4.0422
2025-03-09 01:42:31,955 - INFO - Resetting pretrained SAE
2025-03-09 01:44:21,809 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 4.1695
2025-03-09 01:44:22,215 - INFO - Resetting pretrained SAE
2025-03-09 01:46:13,562 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 4.2094
2025-03-09 01:46:13,938 - INFO - Resetting pretrained SAE
2025-03-09 01:48:04,890 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 4.0982
2025-03-09 01:48:05,282 - INFO - Resetting pretrained SAE
2025-03-09 01:49:56,801 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 3.9997
2025-03-09 01:49:57,176 - INFO - Resetting pretrained SAE
2025-03-09 01:51:47,101 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 3.9804
2025-03-09 01:51:47,507 - INFO - Resetting pretrained SAE
2025-03-09 01:53:38,474 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 3.9553
2025-03-09 01:53:38,871 - INFO - Resetting pretrained SAE
2025-03-09 01:55:30,083 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 3.9032
2025-03-09 01:55:30,699 - INFO - Resetting pretrained SAE
2025-03-09 01:57:21,761 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 3.809
2025-03-09 01:57:22,238 - INFO - Resetting pretrained SAE
2025-03-09 01:59:13,750 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 3.6406
2025-03-09 01:59:14,148 - INFO - Resetting pretrained SAE
2025-03-09 03:01:05,636 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 3.608
2025-03-09 03:01:06,027 - INFO - Resetting pretrained SAE
2025-03-09 03:02:56,343 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 3.5124
2025-03-09 03:02:56,742 - INFO - Resetting pretrained SAE
2025-03-09 03:04:48,145 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 3.4442
2025-03-09 03:04:48,549 - INFO - Resetting pretrained SAE
2025-03-09 03:06:40,776 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 3.3951
2025-03-09 03:06:41,214 - INFO - Resetting pretrained SAE
2025-03-09 03:06:41,219 - INFO - For layer 5, the best Sparse Ratio: 0.25 with validation loss: 3.3951
2025-03-09 03:07:02,839 - INFO - After pruning pretrained SAE, Validation loss: 3.3951, and Test loss: 3.5052
2025-03-09 03:08:54,943 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.112, and Test loss: 3.2143
2025-03-09 03:10:44,807 - INFO - Before pruning pretrained SAE, Validation loss: 2.9405, and Test loss: 3.033
2025-03-09 03:10:44,808 - INFO - Pruning for layer: 6
2025-03-09 03:10:44,808 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.6.hook_z
2025-03-09 03:10:44,808 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.6.attn.hook_z-attn-sae-v1
2025-03-09 03:12:31,112 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9733
2025-03-09 03:12:31,348 - INFO - Resetting pretrained SAE
2025-03-09 03:14:17,511 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.9729
2025-03-09 03:14:18,709 - INFO - Resetting pretrained SAE
2025-03-09 03:16:06,405 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.9743
2025-03-09 03:16:06,638 - INFO - Resetting pretrained SAE
2025-03-09 03:17:52,761 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9739
2025-03-09 03:17:52,976 - INFO - Resetting pretrained SAE
2025-03-09 03:19:38,372 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.9734
2025-03-09 03:19:38,586 - INFO - Resetting pretrained SAE
2025-03-09 03:21:25,549 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.9726
2025-03-09 03:21:25,822 - INFO - Resetting pretrained SAE
2025-03-09 03:23:10,414 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.9717
2025-03-09 03:23:10,638 - INFO - Resetting pretrained SAE
2025-03-09 03:24:57,836 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.9709
2025-03-09 03:24:58,072 - INFO - Resetting pretrained SAE
2025-03-09 03:26:43,713 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.971
2025-03-09 03:26:43,932 - INFO - Resetting pretrained SAE
2025-03-09 03:28:29,789 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.9703
2025-03-09 03:28:30,009 - INFO - Resetting pretrained SAE
2025-03-09 03:30:16,889 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.9703
2025-03-09 03:30:17,100 - INFO - Resetting pretrained SAE
2025-03-09 03:32:03,168 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.9697
2025-03-09 03:32:03,402 - INFO - Resetting pretrained SAE
2025-03-09 03:33:49,026 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.9695
2025-03-09 03:33:49,248 - INFO - Resetting pretrained SAE
2025-03-09 03:35:35,239 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.9695
2025-03-09 03:35:35,460 - INFO - Resetting pretrained SAE
2025-03-09 03:37:21,902 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.9697
2025-03-09 03:37:22,122 - INFO - Resetting pretrained SAE
2025-03-09 03:39:08,702 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9689
2025-03-09 03:39:08,935 - INFO - Resetting pretrained SAE
2025-03-09 03:40:55,694 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9695
2025-03-09 03:40:55,932 - INFO - Resetting pretrained SAE
2025-03-09 03:42:41,859 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.968
2025-03-09 03:42:42,085 - INFO - Resetting pretrained SAE
2025-03-09 03:44:27,357 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9675
2025-03-09 03:44:27,599 - INFO - Resetting pretrained SAE
2025-03-09 03:46:12,639 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9674
2025-03-09 03:46:12,894 - INFO - Resetting pretrained SAE
2025-03-09 03:47:58,447 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.9666
2025-03-09 03:47:58,680 - INFO - Resetting pretrained SAE
2025-03-09 03:49:44,203 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9674
2025-03-09 03:49:44,497 - INFO - Resetting pretrained SAE
2025-03-09 03:51:30,212 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.9664
2025-03-09 03:51:30,458 - INFO - Resetting pretrained SAE
2025-03-09 03:53:15,924 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9642
2025-03-09 03:53:16,168 - INFO - Resetting pretrained SAE
2025-03-09 03:55:01,429 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.9634
2025-03-09 03:55:01,656 - INFO - Resetting pretrained SAE
2025-03-09 03:56:47,460 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.9619
2025-03-09 03:56:47,687 - INFO - Resetting pretrained SAE
2025-03-09 03:58:32,950 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.9611
2025-03-09 03:58:33,224 - INFO - Resetting pretrained SAE
2025-03-09 04:00:19,170 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.9593
2025-03-09 04:00:19,519 - INFO - Resetting pretrained SAE
2025-03-09 04:02:06,200 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.9576
2025-03-09 04:02:06,429 - INFO - Resetting pretrained SAE
2025-03-09 04:03:52,821 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.9556
2025-03-09 04:03:53,045 - INFO - Resetting pretrained SAE
2025-03-09 04:05:39,771 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.9542
2025-03-09 04:05:40,018 - INFO - Resetting pretrained SAE
2025-03-09 04:07:25,766 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.9528
2025-03-09 04:07:26,007 - INFO - Resetting pretrained SAE
2025-03-09 04:09:11,244 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9502
2025-03-09 04:09:11,485 - INFO - Resetting pretrained SAE
2025-03-09 04:10:57,612 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9497
2025-03-09 04:10:57,834 - INFO - Resetting pretrained SAE
2025-03-09 04:12:43,782 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.948
2025-03-09 04:12:44,007 - INFO - Resetting pretrained SAE
2025-03-09 04:14:29,267 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9474
2025-03-09 04:14:29,494 - INFO - Resetting pretrained SAE
2025-03-09 04:16:14,978 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.9456
2025-03-09 04:16:15,250 - INFO - Resetting pretrained SAE
2025-03-09 04:18:01,406 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9441
2025-03-09 04:18:01,688 - INFO - Resetting pretrained SAE
2025-03-09 04:18:01,692 - INFO - For layer 6, the best Sparse Ratio: 0.25 with validation loss: 2.9441
2025-03-09 04:18:22,405 - INFO - After pruning pretrained SAE, Validation loss: 2.9441, and Test loss: 3.0369
2025-03-09 04:20:14,250 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 5.0011, and Test loss: 5.1628
2025-03-09 04:22:09,133 - INFO - Before pruning pretrained SAE, Validation loss: 2.9354, and Test loss: 3.0306
2025-03-09 04:22:09,135 - INFO - Pruning for layer: 7
2025-03-09 04:22:09,135 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.7.hook_z
2025-03-09 04:22:09,135 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.7.attn.hook_z-attn-sae-v1
2025-03-09 04:23:59,434 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9951
2025-03-09 04:23:59,888 - INFO - Resetting pretrained SAE
2025-03-09 04:25:49,426 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 3.0863
2025-03-09 04:25:49,824 - INFO - Resetting pretrained SAE
2025-03-09 04:27:40,484 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 3.0393
2025-03-09 04:27:40,903 - INFO - Resetting pretrained SAE
2025-03-09 04:29:31,196 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9895
2025-03-09 04:29:31,589 - INFO - Resetting pretrained SAE
2025-03-09 04:31:22,714 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 3.2911
2025-03-09 04:31:23,106 - INFO - Resetting pretrained SAE
2025-03-09 04:33:14,140 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 3.1179
2025-03-09 04:33:14,528 - INFO - Resetting pretrained SAE
2025-03-09 04:35:05,351 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 3.4305
2025-03-09 04:35:05,736 - INFO - Resetting pretrained SAE
2025-03-09 04:36:55,298 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 3.2798
2025-03-09 04:37:00,115 - INFO - Resetting pretrained SAE
2025-03-09 04:38:50,735 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 3.2652
2025-03-09 04:38:51,128 - INFO - Resetting pretrained SAE
2025-03-09 04:40:42,290 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 3.2191
2025-03-09 04:40:42,702 - INFO - Resetting pretrained SAE
2025-03-09 04:42:34,956 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 3.2271
2025-03-09 04:42:35,381 - INFO - Resetting pretrained SAE
2025-03-09 04:44:26,035 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 3.2895
2025-03-09 04:44:26,423 - INFO - Resetting pretrained SAE
2025-03-09 04:46:18,753 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 3.243
2025-03-09 04:46:19,146 - INFO - Resetting pretrained SAE
2025-03-09 04:48:09,399 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 3.2102
2025-03-09 04:48:09,779 - INFO - Resetting pretrained SAE
2025-03-09 04:50:00,014 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 3.3056
2025-03-09 04:50:00,393 - INFO - Resetting pretrained SAE
2025-03-09 04:51:51,653 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 3.2199
2025-03-09 04:51:52,037 - INFO - Resetting pretrained SAE
2025-03-09 04:53:42,656 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 3.2032
2025-03-09 04:53:43,035 - INFO - Resetting pretrained SAE
2025-03-09 04:55:36,186 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 3.299
2025-03-09 04:55:36,571 - INFO - Resetting pretrained SAE
2025-03-09 04:57:27,811 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 3.2586
2025-03-09 04:57:28,203 - INFO - Resetting pretrained SAE
2025-03-09 04:59:18,671 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 3.1739
2025-03-09 04:59:19,072 - INFO - Resetting pretrained SAE
2025-03-09 05:01:10,647 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 3.1784
2025-03-09 05:01:11,035 - INFO - Resetting pretrained SAE
2025-03-09 05:03:01,963 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 3.1732
2025-03-09 05:03:02,356 - INFO - Resetting pretrained SAE
2025-03-09 05:04:54,812 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 3.2466
2025-03-09 05:04:55,175 - INFO - Resetting pretrained SAE
2025-03-09 05:06:45,663 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 3.0934
2025-03-09 05:06:46,053 - INFO - Resetting pretrained SAE
2025-03-09 05:08:37,077 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 3.1778
2025-03-09 05:08:37,520 - INFO - Resetting pretrained SAE
2025-03-09 05:10:29,413 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 3.215
2025-03-09 05:10:29,801 - INFO - Resetting pretrained SAE
2025-03-09 05:12:21,394 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 3.1345
2025-03-09 05:12:21,798 - INFO - Resetting pretrained SAE
2025-03-09 05:14:12,487 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 3.1429
2025-03-09 05:14:12,889 - INFO - Resetting pretrained SAE
2025-03-09 05:16:06,344 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 3.2373
2025-03-09 05:16:06,724 - INFO - Resetting pretrained SAE
2025-03-09 05:17:57,315 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 3.0932
2025-03-09 05:17:57,698 - INFO - Resetting pretrained SAE
2025-03-09 05:19:49,867 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 3.0173
2025-03-09 05:19:50,247 - INFO - Resetting pretrained SAE
2025-03-09 05:21:41,348 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 3.0042
2025-03-09 05:21:41,856 - INFO - Resetting pretrained SAE
2025-03-09 05:23:33,623 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9964
2025-03-09 05:23:34,339 - INFO - Resetting pretrained SAE
2025-03-09 05:25:25,827 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9866
2025-03-09 05:25:26,181 - INFO - Resetting pretrained SAE
2025-03-09 05:27:17,591 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.9697
2025-03-09 05:27:17,984 - INFO - Resetting pretrained SAE
2025-03-09 05:29:09,641 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9627
2025-03-09 05:29:10,058 - INFO - Resetting pretrained SAE
2025-03-09 05:31:00,806 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.9595
2025-03-09 05:31:01,203 - INFO - Resetting pretrained SAE
2025-03-09 05:32:51,588 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9553
2025-03-09 05:32:51,993 - INFO - Resetting pretrained SAE
2025-03-09 05:32:51,998 - INFO - For layer 7, the best Sparse Ratio: 0.25 with validation loss: 2.9553
2025-03-09 05:33:13,413 - INFO - After pruning pretrained SAE, Validation loss: 2.9553, and Test loss: 3.0496
2025-03-09 05:35:05,881 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 3.6064, and Test loss: 3.7118
2025-03-09 05:36:56,875 - INFO - Before pruning pretrained SAE, Validation loss: 2.935, and Test loss: 3.0325
2025-03-09 05:36:56,876 - INFO - Pruning for layer: 8
2025-03-09 05:36:56,876 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.8.hook_z
2025-03-09 05:36:56,876 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.8.attn.hook_z-attn-sae-v1
2025-03-09 05:38:41,678 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9609
2025-03-09 05:38:41,906 - INFO - Resetting pretrained SAE
2025-03-09 05:40:28,465 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.9609
2025-03-09 05:40:28,717 - INFO - Resetting pretrained SAE
2025-03-09 05:42:14,414 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.9608
2025-03-09 05:42:14,628 - INFO - Resetting pretrained SAE
2025-03-09 05:44:00,206 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9606
2025-03-09 05:44:00,428 - INFO - Resetting pretrained SAE
2025-03-09 05:45:46,135 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.9605
2025-03-09 05:45:46,355 - INFO - Resetting pretrained SAE
2025-03-09 05:47:32,431 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.9603
2025-03-09 05:47:32,653 - INFO - Resetting pretrained SAE
2025-03-09 05:49:19,420 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.9601
2025-03-09 05:49:19,646 - INFO - Resetting pretrained SAE
2025-03-09 05:51:06,339 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.9599
2025-03-09 05:51:06,594 - INFO - Resetting pretrained SAE
2025-03-09 05:52:52,351 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.9597
2025-03-09 05:52:52,575 - INFO - Resetting pretrained SAE
2025-03-09 05:54:38,664 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.9594
2025-03-09 05:54:39,067 - INFO - Resetting pretrained SAE
2025-03-09 05:56:25,658 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.9592
2025-03-09 05:56:25,885 - INFO - Resetting pretrained SAE
2025-03-09 05:58:11,481 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.959
2025-03-09 05:58:11,707 - INFO - Resetting pretrained SAE
2025-03-09 05:59:58,022 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.9586
2025-03-09 05:59:58,265 - INFO - Resetting pretrained SAE
2025-03-09 06:01:44,629 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.9584
2025-03-09 06:01:44,873 - INFO - Resetting pretrained SAE
2025-03-09 06:03:29,926 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.958
2025-03-09 06:03:30,264 - INFO - Resetting pretrained SAE
2025-03-09 06:05:17,600 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9576
2025-03-09 06:05:17,814 - INFO - Resetting pretrained SAE
2025-03-09 06:07:04,709 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9573
2025-03-09 06:07:04,935 - INFO - Resetting pretrained SAE
2025-03-09 06:08:50,550 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.9567
2025-03-09 06:08:50,798 - INFO - Resetting pretrained SAE
2025-03-09 06:10:37,260 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9562
2025-03-09 06:10:37,511 - INFO - Resetting pretrained SAE
2025-03-09 06:12:24,441 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9559
2025-03-09 06:12:24,660 - INFO - Resetting pretrained SAE
2025-03-09 06:14:09,872 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.9554
2025-03-09 06:14:10,138 - INFO - Resetting pretrained SAE
2025-03-09 06:15:56,763 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9549
2025-03-09 06:15:57,021 - INFO - Resetting pretrained SAE
2025-03-09 06:17:43,384 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.9541
2025-03-09 06:17:43,680 - INFO - Resetting pretrained SAE
2025-03-09 06:19:30,828 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9536
2025-03-09 06:19:31,054 - INFO - Resetting pretrained SAE
2025-03-09 06:21:18,531 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.953
2025-03-09 06:21:18,764 - INFO - Resetting pretrained SAE
2025-03-09 06:23:05,900 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.9521
2025-03-09 06:23:06,120 - INFO - Resetting pretrained SAE
2025-03-09 06:24:52,681 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.9515
2025-03-09 06:24:52,985 - INFO - Resetting pretrained SAE
2025-03-09 06:26:38,768 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.9505
2025-03-09 06:26:38,982 - INFO - Resetting pretrained SAE
2025-03-09 06:28:25,013 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.9495
2025-03-09 06:28:25,240 - INFO - Resetting pretrained SAE
2025-03-09 06:30:11,121 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.9484
2025-03-09 06:30:11,356 - INFO - Resetting pretrained SAE
2025-03-09 06:31:57,471 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.9474
2025-03-09 06:31:57,701 - INFO - Resetting pretrained SAE
2025-03-09 06:33:44,376 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.946
2025-03-09 06:33:44,601 - INFO - Resetting pretrained SAE
2025-03-09 06:35:27,857 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9449
2025-03-09 06:35:28,084 - INFO - Resetting pretrained SAE
2025-03-09 06:37:12,551 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9439
2025-03-09 06:37:12,790 - INFO - Resetting pretrained SAE
2025-03-09 06:38:57,656 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.9426
2025-03-09 06:38:57,877 - INFO - Resetting pretrained SAE
2025-03-09 06:40:42,541 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9417
2025-03-09 06:40:42,766 - INFO - Resetting pretrained SAE
2025-03-09 06:42:28,108 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.94
2025-03-09 06:42:28,347 - INFO - Resetting pretrained SAE
2025-03-09 06:44:13,643 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9392
2025-03-09 06:44:13,873 - INFO - Resetting pretrained SAE
2025-03-09 06:44:13,877 - INFO - For layer 8, the best Sparse Ratio: 0.25 with validation loss: 2.9392
2025-03-09 06:44:34,250 - INFO - After pruning pretrained SAE, Validation loss: 2.9392, and Test loss: 3.0372
2025-03-09 06:46:24,809 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 4.0182, and Test loss: 4.1562
2025-03-09 06:48:15,273 - INFO - Before pruning pretrained SAE, Validation loss: 2.9337, and Test loss: 3.0302
2025-03-09 06:48:15,274 - INFO - Pruning for layer: 9
2025-03-09 06:48:15,275 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.9.hook_z
2025-03-09 06:48:15,276 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.9.attn.hook_z-attn-sae-v1
2025-03-09 06:49:59,863 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9628
2025-03-09 06:50:00,224 - INFO - Resetting pretrained SAE
2025-03-09 06:51:45,001 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.9628
2025-03-09 06:51:45,539 - INFO - Resetting pretrained SAE
2025-03-09 06:53:30,336 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.9624
2025-03-09 06:53:30,617 - INFO - Resetting pretrained SAE
2025-03-09 06:55:14,822 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9628
2025-03-09 06:55:15,043 - INFO - Resetting pretrained SAE
2025-03-09 06:56:59,517 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.9627
2025-03-09 06:56:59,747 - INFO - Resetting pretrained SAE
2025-03-09 06:58:43,926 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.9627
2025-03-09 06:58:44,161 - INFO - Resetting pretrained SAE
2025-03-09 07:00:29,278 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.9626
2025-03-09 07:00:30,015 - INFO - Resetting pretrained SAE
2025-03-09 07:02:15,959 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.9626
2025-03-09 07:02:16,188 - INFO - Resetting pretrained SAE
2025-03-09 07:04:01,184 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.9626
2025-03-09 07:04:01,441 - INFO - Resetting pretrained SAE
2025-03-09 07:05:45,688 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.9626
2025-03-09 07:05:45,915 - INFO - Resetting pretrained SAE
2025-03-09 07:07:30,851 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.9624
2025-03-09 07:07:31,135 - INFO - Resetting pretrained SAE
2025-03-09 07:09:16,338 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.9625
2025-03-09 07:09:16,571 - INFO - Resetting pretrained SAE
2025-03-09 07:11:01,290 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.9625
2025-03-09 07:11:01,526 - INFO - Resetting pretrained SAE
2025-03-09 07:12:46,445 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.9621
2025-03-09 07:12:46,689 - INFO - Resetting pretrained SAE
2025-03-09 07:14:31,956 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.962
2025-03-09 07:14:32,196 - INFO - Resetting pretrained SAE
2025-03-09 07:16:19,308 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9627
2025-03-09 07:16:19,538 - INFO - Resetting pretrained SAE
2025-03-09 07:18:03,882 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9624
2025-03-09 07:18:04,113 - INFO - Resetting pretrained SAE
2025-03-09 07:19:48,386 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.9621
2025-03-09 07:19:48,608 - INFO - Resetting pretrained SAE
2025-03-09 07:21:33,627 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9617
2025-03-09 07:21:33,895 - INFO - Resetting pretrained SAE
2025-03-09 07:23:18,088 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9614
2025-03-09 07:23:18,320 - INFO - Resetting pretrained SAE
2025-03-09 07:25:03,857 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.961
2025-03-09 07:25:04,091 - INFO - Resetting pretrained SAE
2025-03-09 07:26:49,030 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9615
2025-03-09 07:26:49,265 - INFO - Resetting pretrained SAE
2025-03-09 07:28:34,689 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.9628
2025-03-09 07:28:34,946 - INFO - Resetting pretrained SAE
2025-03-09 07:30:19,606 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9617
2025-03-09 07:30:19,831 - INFO - Resetting pretrained SAE
2025-03-09 07:32:05,794 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.96
2025-03-09 07:32:06,011 - INFO - Resetting pretrained SAE
2025-03-09 07:33:51,121 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.9578
2025-03-09 07:33:51,348 - INFO - Resetting pretrained SAE
2025-03-09 07:35:36,260 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.9589
2025-03-09 07:35:36,582 - INFO - Resetting pretrained SAE
2025-03-09 07:37:21,590 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.9583
2025-03-09 07:37:21,822 - INFO - Resetting pretrained SAE
2025-03-09 07:39:05,839 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.957
2025-03-09 07:39:06,064 - INFO - Resetting pretrained SAE
2025-03-09 07:40:51,363 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.9556
2025-03-09 07:40:51,618 - INFO - Resetting pretrained SAE
2025-03-09 07:42:36,503 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.9532
2025-03-09 07:42:36,749 - INFO - Resetting pretrained SAE
2025-03-09 07:44:21,011 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.9544
2025-03-09 07:44:21,288 - INFO - Resetting pretrained SAE
2025-03-09 07:46:05,864 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9513
2025-03-09 07:46:06,098 - INFO - Resetting pretrained SAE
2025-03-09 07:47:51,751 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9502
2025-03-09 07:47:51,988 - INFO - Resetting pretrained SAE
2025-03-09 07:49:38,303 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.9485
2025-03-09 07:49:38,551 - INFO - Resetting pretrained SAE
2025-03-09 07:51:23,562 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9476
2025-03-09 07:51:23,788 - INFO - Resetting pretrained SAE
2025-03-09 07:53:09,516 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.9464
2025-03-09 07:53:09,733 - INFO - Resetting pretrained SAE
2025-03-09 07:54:55,210 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9452
2025-03-09 07:54:55,435 - INFO - Resetting pretrained SAE
2025-03-09 07:54:55,438 - INFO - For layer 9, the best Sparse Ratio: 0.25 with validation loss: 2.9452
2025-03-09 07:55:15,697 - INFO - After pruning pretrained SAE, Validation loss: 2.9452, and Test loss: 3.0416
2025-03-09 07:57:06,021 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.9476, and Test loss: 3.0451
2025-03-09 07:58:56,837 - INFO - Before pruning pretrained SAE, Validation loss: 2.9317, and Test loss: 3.029
2025-03-09 07:58:56,837 - INFO - Pruning for layer: 10
2025-03-09 07:58:56,837 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.10.hook_z
2025-03-09 07:58:56,837 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.10.attn.hook_z-attn-sae-v1
2025-03-09 08:00:43,025 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9571
2025-03-09 08:00:43,423 - INFO - Resetting pretrained SAE
2025-03-09 08:02:28,066 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.9571
2025-03-09 08:02:28,307 - INFO - Resetting pretrained SAE
2025-03-09 08:04:12,638 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.9571
2025-03-09 08:04:12,930 - INFO - Resetting pretrained SAE
2025-03-09 08:05:57,009 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.957
2025-03-09 08:05:57,240 - INFO - Resetting pretrained SAE
2025-03-09 08:07:41,427 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.957
2025-03-09 08:07:41,665 - INFO - Resetting pretrained SAE
2025-03-09 08:09:26,540 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.9569
2025-03-09 08:09:26,768 - INFO - Resetting pretrained SAE
2025-03-09 08:11:12,225 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.9569
2025-03-09 08:11:12,482 - INFO - Resetting pretrained SAE
2025-03-09 08:12:57,899 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.9568
2025-03-09 08:12:58,180 - INFO - Resetting pretrained SAE
2025-03-09 08:14:44,270 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.9568
2025-03-09 08:14:44,513 - INFO - Resetting pretrained SAE
2025-03-09 08:16:28,826 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.9567
2025-03-09 08:16:29,045 - INFO - Resetting pretrained SAE
2025-03-09 08:18:13,626 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.9566
2025-03-09 08:18:13,876 - INFO - Resetting pretrained SAE
2025-03-09 08:19:58,311 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.9565
2025-03-09 08:19:58,593 - INFO - Resetting pretrained SAE
2025-03-09 08:21:43,496 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.9564
2025-03-09 08:21:43,738 - INFO - Resetting pretrained SAE
2025-03-09 08:23:29,285 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.9562
2025-03-09 08:23:29,522 - INFO - Resetting pretrained SAE
2025-03-09 08:25:14,051 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.9561
2025-03-09 08:25:14,287 - INFO - Resetting pretrained SAE
2025-03-09 08:27:00,031 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9559
2025-03-09 08:27:00,267 - INFO - Resetting pretrained SAE
2025-03-09 08:28:44,434 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9558
2025-03-09 08:28:44,900 - INFO - Resetting pretrained SAE
2025-03-09 08:30:31,236 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.9557
2025-03-09 08:30:31,471 - INFO - Resetting pretrained SAE
2025-03-09 08:32:15,345 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9555
2025-03-09 08:32:15,704 - INFO - Resetting pretrained SAE
2025-03-09 08:34:00,945 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9552
2025-03-09 08:34:01,167 - INFO - Resetting pretrained SAE
2025-03-09 08:35:46,703 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.9549
2025-03-09 08:35:46,978 - INFO - Resetting pretrained SAE
2025-03-09 08:37:31,441 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9545
2025-03-09 08:37:31,676 - INFO - Resetting pretrained SAE
2025-03-09 08:39:16,907 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.9543
2025-03-09 08:39:17,150 - INFO - Resetting pretrained SAE
2025-03-09 08:41:02,020 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9539
2025-03-09 08:41:03,083 - INFO - Resetting pretrained SAE
2025-03-09 08:42:46,525 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.9533
2025-03-09 08:42:46,768 - INFO - Resetting pretrained SAE
2025-03-09 08:44:30,847 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.9526
2025-03-09 08:44:31,122 - INFO - Resetting pretrained SAE
2025-03-09 08:46:15,762 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.952
2025-03-09 08:46:16,024 - INFO - Resetting pretrained SAE
2025-03-09 08:47:59,515 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.9514
2025-03-09 08:47:59,769 - INFO - Resetting pretrained SAE
2025-03-09 08:49:42,840 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.9506
2025-03-09 08:49:43,085 - INFO - Resetting pretrained SAE
2025-03-09 08:51:27,530 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.95
2025-03-09 08:51:27,783 - INFO - Resetting pretrained SAE
2025-03-09 08:53:11,003 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.9492
2025-03-09 08:53:11,227 - INFO - Resetting pretrained SAE
2025-03-09 08:54:54,579 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.9482
2025-03-09 08:54:54,820 - INFO - Resetting pretrained SAE
2025-03-09 08:56:38,578 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9475
2025-03-09 08:56:38,850 - INFO - Resetting pretrained SAE
2025-03-09 08:58:23,122 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9463
2025-03-09 08:58:23,376 - INFO - Resetting pretrained SAE
2025-03-09 09:00:07,336 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.9452
2025-03-09 09:00:07,581 - INFO - Resetting pretrained SAE
2025-03-09 09:01:51,360 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9439
2025-03-09 09:01:51,594 - INFO - Resetting pretrained SAE
2025-03-09 09:03:35,900 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.9423
2025-03-09 09:03:36,137 - INFO - Resetting pretrained SAE
2025-03-09 09:05:19,093 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9407
2025-03-09 09:05:19,324 - INFO - Resetting pretrained SAE
2025-03-09 09:05:19,328 - INFO - For layer 10, the best Sparse Ratio: 0.25 with validation loss: 2.9407
2025-03-09 09:05:39,458 - INFO - After pruning pretrained SAE, Validation loss: 2.9407, and Test loss: 3.0389
2025-03-09 09:07:27,830 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.9225, and Test loss: 3.0187
2025-03-09 09:09:16,403 - INFO - Before pruning pretrained SAE, Validation loss: 2.9473, and Test loss: 3.0444
2025-03-09 09:09:16,404 - INFO - Pruning for layer: 11
2025-03-09 09:09:16,404 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.11.hook_z
2025-03-09 09:09:16,404 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.11.attn.hook_z-attn-sae-v1
2025-03-09 09:11:00,207 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.9669
2025-03-09 09:11:00,468 - INFO - Resetting pretrained SAE
2025-03-09 09:12:44,240 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.967
2025-03-09 09:12:44,535 - INFO - Resetting pretrained SAE
2025-03-09 09:14:28,957 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.9678
2025-03-09 09:14:29,201 - INFO - Resetting pretrained SAE
2025-03-09 09:16:12,097 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.9682
2025-03-09 09:16:12,334 - INFO - Resetting pretrained SAE
2025-03-09 09:17:55,267 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.9675
2025-03-09 09:17:55,504 - INFO - Resetting pretrained SAE
2025-03-09 09:19:38,523 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.9687
2025-03-09 09:19:38,785 - INFO - Resetting pretrained SAE
2025-03-09 09:21:22,862 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.968
2025-03-09 09:21:23,143 - INFO - Resetting pretrained SAE
2025-03-09 09:23:06,279 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.9683
2025-03-09 09:23:06,520 - INFO - Resetting pretrained SAE
2025-03-09 09:24:50,118 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.9681
2025-03-09 09:24:50,433 - INFO - Resetting pretrained SAE
2025-03-09 09:26:33,366 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.9678
2025-03-09 09:26:33,629 - INFO - Resetting pretrained SAE
2025-03-09 09:28:18,222 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.9678
2025-03-09 09:28:18,472 - INFO - Resetting pretrained SAE
2025-03-09 09:30:02,660 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.9679
2025-03-09 09:30:03,123 - INFO - Resetting pretrained SAE
2025-03-09 09:31:46,503 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.968
2025-03-09 09:31:46,731 - INFO - Resetting pretrained SAE
2025-03-09 09:33:30,662 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.9685
2025-03-09 09:33:30,898 - INFO - Resetting pretrained SAE
2025-03-09 09:35:15,249 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.9683
2025-03-09 09:35:15,509 - INFO - Resetting pretrained SAE
2025-03-09 09:36:59,605 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9685
2025-03-09 09:36:59,845 - INFO - Resetting pretrained SAE
2025-03-09 09:38:43,938 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9689
2025-03-09 09:38:44,161 - INFO - Resetting pretrained SAE
2025-03-09 09:40:28,165 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.9687
2025-03-09 09:40:28,400 - INFO - Resetting pretrained SAE
2025-03-09 09:42:12,218 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9681
2025-03-09 09:42:12,460 - INFO - Resetting pretrained SAE
2025-03-09 09:43:56,169 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9683
2025-03-09 09:43:56,406 - INFO - Resetting pretrained SAE
2025-03-09 09:45:41,159 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.9686
2025-03-09 09:45:41,401 - INFO - Resetting pretrained SAE
2025-03-09 09:47:24,579 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9685
2025-03-09 09:47:24,920 - INFO - Resetting pretrained SAE
2025-03-09 09:49:08,441 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.968
2025-03-09 09:49:08,674 - INFO - Resetting pretrained SAE
2025-03-09 09:50:51,975 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9679
2025-03-09 09:50:52,216 - INFO - Resetting pretrained SAE
2025-03-09 09:52:36,149 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.9675
2025-03-09 09:52:36,412 - INFO - Resetting pretrained SAE
2025-03-09 09:54:20,487 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.9671
2025-03-09 09:54:20,836 - INFO - Resetting pretrained SAE
2025-03-09 09:56:05,099 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.9674
2025-03-09 09:56:05,444 - INFO - Resetting pretrained SAE
2025-03-09 09:57:49,815 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 2.9664
2025-03-09 09:57:50,099 - INFO - Resetting pretrained SAE
2025-03-09 09:59:33,536 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 2.9668
2025-03-09 09:59:33,777 - INFO - Resetting pretrained SAE
2025-03-09 10:01:17,873 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 2.9665
2025-03-09 10:01:18,161 - INFO - Resetting pretrained SAE
2025-03-09 10:03:02,131 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.9662
2025-03-09 10:03:02,349 - INFO - Resetting pretrained SAE
2025-03-09 10:04:47,080 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.9658
2025-03-09 10:04:47,319 - INFO - Resetting pretrained SAE
2025-03-09 10:06:30,578 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 2.9651
2025-03-09 10:06:30,819 - INFO - Resetting pretrained SAE
2025-03-09 10:08:13,709 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.9648
2025-03-09 10:08:13,959 - INFO - Resetting pretrained SAE
2025-03-09 10:09:57,693 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.9649
2025-03-09 10:10:00,286 - INFO - Resetting pretrained SAE
2025-03-09 10:11:43,158 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.9652
2025-03-09 10:11:43,415 - INFO - Resetting pretrained SAE
2025-03-09 10:13:26,532 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.965
2025-03-09 10:13:26,768 - INFO - Resetting pretrained SAE
2025-03-09 10:15:10,865 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.9653
2025-03-09 10:15:11,102 - INFO - Resetting pretrained SAE
2025-03-09 10:15:11,105 - INFO - For layer 11, the best Sparse Ratio: 0.33 with validation loss: 2.9648
2025-03-09 10:15:31,385 - INFO - After pruning pretrained SAE, Validation loss: 2.9648, and Test loss: 3.0638
