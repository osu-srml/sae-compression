2025-03-08 18:53:21,889 - INFO - Using device: cuda:2
2025-03-08 18:53:24,767 - INFO - Loaded wanda pruned gpt-2 small
2025-03-08 18:53:25,937 - INFO - Loaded calibration dataset: pile
2025-03-08 18:55:28,886 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 9.2595, and Test loss: 9.2169
2025-03-08 18:57:06,508 - INFO - Before pruning pretrained SAE, Validation loss: 6.9216, and Test loss: 6.9736
2025-03-08 18:57:06,508 - INFO - Pruning for layer: 0
2025-03-08 18:57:06,508 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.0.hook_z
2025-03-08 18:57:06,508 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.0.attn.hook_z-attn-sae-v1
2025-03-08 18:58:41,038 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.8689
2025-03-08 18:58:41,258 - INFO - Resetting pretrained SAE
2025-03-08 19:00:15,162 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 4.0959
2025-03-08 19:00:15,390 - INFO - Resetting pretrained SAE
2025-03-08 19:01:50,254 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 5.0453
2025-03-08 19:01:50,470 - INFO - Resetting pretrained SAE
2025-03-08 19:03:25,588 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 5.9249
2025-03-08 19:03:26,060 - INFO - Resetting pretrained SAE
2025-03-08 19:05:00,894 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 6.64
2025-03-08 19:05:03,910 - INFO - Resetting pretrained SAE
2025-03-08 19:06:38,028 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 7.0589
2025-03-08 19:06:38,254 - INFO - Resetting pretrained SAE
2025-03-08 19:08:12,892 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 7.2672
2025-03-08 19:08:13,165 - INFO - Resetting pretrained SAE
2025-03-08 19:09:47,378 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 7.2689
2025-03-08 19:09:47,614 - INFO - Resetting pretrained SAE
2025-03-08 19:11:21,579 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 7.3525
2025-03-08 19:11:21,809 - INFO - Resetting pretrained SAE
2025-03-08 19:12:56,265 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 7.4143
2025-03-08 19:12:56,516 - INFO - Resetting pretrained SAE
2025-03-08 19:14:31,064 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 7.3926
2025-03-08 19:14:31,333 - INFO - Resetting pretrained SAE
2025-03-08 19:16:05,910 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 7.3644
2025-03-08 19:16:06,212 - INFO - Resetting pretrained SAE
2025-03-08 19:17:41,085 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 7.339
2025-03-08 19:17:41,312 - INFO - Resetting pretrained SAE
2025-03-08 19:19:15,670 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 7.2501
2025-03-08 19:19:15,900 - INFO - Resetting pretrained SAE
2025-03-08 19:20:50,285 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 7.2345
2025-03-08 19:20:50,539 - INFO - Resetting pretrained SAE
2025-03-08 19:22:24,994 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 7.2049
2025-03-08 19:22:25,213 - INFO - Resetting pretrained SAE
2025-03-08 19:24:00,829 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 7.1655
2025-03-08 19:24:01,053 - INFO - Resetting pretrained SAE
2025-03-08 19:25:36,260 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 7.1616
2025-03-08 19:25:36,501 - INFO - Resetting pretrained SAE
2025-03-08 19:27:11,816 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 7.18
2025-03-08 19:27:12,090 - INFO - Resetting pretrained SAE
2025-03-08 19:28:47,021 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 7.1758
2025-03-08 19:28:47,364 - INFO - Resetting pretrained SAE
2025-03-08 19:30:22,234 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 7.1704
2025-03-08 19:30:22,466 - INFO - Resetting pretrained SAE
2025-03-08 19:31:57,040 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 7.1446
2025-03-08 19:31:57,304 - INFO - Resetting pretrained SAE
2025-03-08 19:33:31,479 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 7.1444
2025-03-08 19:33:31,755 - INFO - Resetting pretrained SAE
2025-03-08 19:35:09,145 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 7.1331
2025-03-08 19:35:09,437 - INFO - Resetting pretrained SAE
2025-03-08 19:36:44,268 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 7.1274
2025-03-08 19:36:44,549 - INFO - Resetting pretrained SAE
2025-03-08 19:38:18,562 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 7.1018
2025-03-08 19:38:18,874 - INFO - Resetting pretrained SAE
2025-03-08 19:39:53,775 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 7.0918
2025-03-08 19:39:54,029 - INFO - Resetting pretrained SAE
2025-03-08 19:41:28,196 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 7.054
2025-03-08 19:41:28,436 - INFO - Resetting pretrained SAE
2025-03-08 19:43:02,795 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 7.0701
2025-03-08 19:43:03,039 - INFO - Resetting pretrained SAE
2025-03-08 19:44:37,964 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 7.039
2025-03-08 19:44:38,264 - INFO - Resetting pretrained SAE
2025-03-08 19:46:12,722 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 7.021
2025-03-08 19:46:13,019 - INFO - Resetting pretrained SAE
2025-03-08 19:47:47,908 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 7.0053
2025-03-08 19:47:48,169 - INFO - Resetting pretrained SAE
2025-03-08 19:49:22,638 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 6.9591
2025-03-08 19:49:22,949 - INFO - Resetting pretrained SAE
2025-03-08 19:50:57,196 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 6.9704
2025-03-08 19:50:57,434 - INFO - Resetting pretrained SAE
2025-03-08 19:52:31,720 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 6.9538
2025-03-08 19:52:31,959 - INFO - Resetting pretrained SAE
2025-03-08 19:54:05,618 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 6.9458
2025-03-08 19:54:05,863 - INFO - Resetting pretrained SAE
2025-03-08 19:55:40,103 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 6.9396
2025-03-08 19:55:40,326 - INFO - Resetting pretrained SAE
2025-03-08 19:57:14,714 - INFO - After pruning layer 0 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 6.9268
2025-03-08 19:57:14,967 - INFO - Resetting pretrained SAE
2025-03-08 19:57:14,970 - INFO - For layer 0, the best Sparse Ratio: 0.99 with validation loss: 2.8689
2025-03-08 19:57:32,837 - INFO - After pruning pretrained SAE, Validation loss: 2.8689, and Test loss: 2.8208
2025-03-08 19:59:10,562 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 7.1276, and Test loss: 7.1361
2025-03-08 20:00:49,071 - INFO - Before pruning pretrained SAE, Validation loss: 3.1165, and Test loss: 3.0754
2025-03-08 20:00:49,073 - INFO - Pruning for layer: 1
2025-03-08 20:00:49,073 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.1.hook_z
2025-03-08 20:00:49,073 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.1.attn.hook_z-attn-sae-v1
2025-03-08 20:02:23,130 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 2.0985
2025-03-08 20:02:23,394 - INFO - Resetting pretrained SAE
2025-03-08 20:03:58,330 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.8457
2025-03-08 20:03:58,567 - INFO - Resetting pretrained SAE
2025-03-08 20:05:32,519 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.5694
2025-03-08 20:05:32,755 - INFO - Resetting pretrained SAE
2025-03-08 20:07:06,075 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 2.543
2025-03-08 20:07:06,322 - INFO - Resetting pretrained SAE
2025-03-08 20:08:41,164 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 2.5702
2025-03-08 20:08:41,405 - INFO - Resetting pretrained SAE
2025-03-08 20:10:15,627 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 2.5535
2025-03-08 20:10:15,933 - INFO - Resetting pretrained SAE
2025-03-08 20:11:50,053 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.5625
2025-03-08 20:11:50,281 - INFO - Resetting pretrained SAE
2025-03-08 20:13:24,808 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.5714
2025-03-08 20:13:25,062 - INFO - Resetting pretrained SAE
2025-03-08 20:15:00,409 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.5733
2025-03-08 20:15:00,683 - INFO - Resetting pretrained SAE
2025-03-08 20:16:34,724 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.5941
2025-03-08 20:16:35,011 - INFO - Resetting pretrained SAE
2025-03-08 20:18:09,559 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.6099
2025-03-08 20:18:09,789 - INFO - Resetting pretrained SAE
2025-03-08 20:19:45,223 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.6444
2025-03-08 20:19:45,459 - INFO - Resetting pretrained SAE
2025-03-08 20:21:19,160 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.6219
2025-03-08 20:21:19,867 - INFO - Resetting pretrained SAE
2025-03-08 20:22:55,028 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.6617
2025-03-08 20:22:55,299 - INFO - Resetting pretrained SAE
2025-03-08 20:24:29,891 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.6771
2025-03-08 20:24:30,130 - INFO - Resetting pretrained SAE
2025-03-08 20:26:04,532 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.7833
2025-03-08 20:26:04,807 - INFO - Resetting pretrained SAE
2025-03-08 20:27:39,501 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.856
2025-03-08 20:27:39,754 - INFO - Resetting pretrained SAE
2025-03-08 20:29:14,223 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.893
2025-03-08 20:29:14,489 - INFO - Resetting pretrained SAE
2025-03-08 20:30:49,180 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.8829
2025-03-08 20:30:49,468 - INFO - Resetting pretrained SAE
2025-03-08 20:32:23,837 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.9076
2025-03-08 20:32:24,255 - INFO - Resetting pretrained SAE
2025-03-08 20:33:58,495 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 3.0856
2025-03-08 20:33:58,817 - INFO - Resetting pretrained SAE
2025-03-08 20:35:33,439 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 3.1424
2025-03-08 20:35:33,732 - INFO - Resetting pretrained SAE
2025-03-08 20:37:08,294 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 3.0813
2025-03-08 20:37:08,522 - INFO - Resetting pretrained SAE
2025-03-08 20:38:43,196 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 3.1614
2025-03-08 20:38:43,431 - INFO - Resetting pretrained SAE
2025-03-08 20:40:18,662 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 3.0981
2025-03-08 20:40:18,917 - INFO - Resetting pretrained SAE
2025-03-08 20:41:52,944 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 3.2745
2025-03-08 20:41:53,217 - INFO - Resetting pretrained SAE
2025-03-08 20:43:27,519 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 3.2248
2025-03-08 20:43:27,773 - INFO - Resetting pretrained SAE
2025-03-08 20:45:03,074 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 3.1941
2025-03-08 20:45:03,322 - INFO - Resetting pretrained SAE
2025-03-08 20:46:37,767 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 3.2858
2025-03-08 20:46:38,010 - INFO - Resetting pretrained SAE
2025-03-08 20:48:12,910 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 3.2941
2025-03-08 20:48:13,271 - INFO - Resetting pretrained SAE
2025-03-08 20:49:49,001 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 3.3791
2025-03-08 20:49:49,244 - INFO - Resetting pretrained SAE
2025-03-08 20:51:23,697 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 3.2442
2025-03-08 20:51:23,933 - INFO - Resetting pretrained SAE
2025-03-08 20:52:58,898 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 3.2557
2025-03-08 20:52:59,194 - INFO - Resetting pretrained SAE
2025-03-08 20:54:33,897 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 3.2091
2025-03-08 20:54:34,125 - INFO - Resetting pretrained SAE
2025-03-08 20:56:08,508 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 3.1732
2025-03-08 20:56:08,734 - INFO - Resetting pretrained SAE
2025-03-08 20:57:42,784 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 3.0694
2025-03-08 20:57:43,044 - INFO - Resetting pretrained SAE
2025-03-08 20:59:17,156 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 3.0742
2025-03-08 20:59:17,534 - INFO - Resetting pretrained SAE
2025-03-08 21:00:51,746 - INFO - After pruning layer 1 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 3.0482
2025-03-08 21:00:52,041 - INFO - Resetting pretrained SAE
2025-03-08 21:00:52,047 - INFO - For layer 1, the best Sparse Ratio: 0.99 with validation loss: 2.0985
2025-03-08 21:01:10,205 - INFO - After pruning pretrained SAE, Validation loss: 2.0985, and Test loss: 1.9985
2025-03-08 21:02:47,855 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.2986, and Test loss: 2.2851
2025-03-08 21:04:26,792 - INFO - Before pruning pretrained SAE, Validation loss: 3.7464, and Test loss: 3.7188
2025-03-08 21:04:26,793 - INFO - Pruning for layer: 2
2025-03-08 21:04:26,793 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.2.hook_z
2025-03-08 21:04:26,793 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.2.attn.hook_z-attn-sae-v1
2025-03-08 21:06:00,919 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7099
2025-03-08 21:06:01,141 - INFO - Resetting pretrained SAE
2025-03-08 21:07:35,120 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.7235
2025-03-08 21:07:35,349 - INFO - Resetting pretrained SAE
2025-03-08 21:09:09,804 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.7558
2025-03-08 21:09:10,041 - INFO - Resetting pretrained SAE
2025-03-08 21:10:44,907 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.8248
2025-03-08 21:10:45,515 - INFO - Resetting pretrained SAE
2025-03-08 21:12:18,745 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.87
2025-03-08 21:12:19,013 - INFO - Resetting pretrained SAE
2025-03-08 21:13:53,411 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.9723
2025-03-08 21:13:53,652 - INFO - Resetting pretrained SAE
2025-03-08 21:15:27,957 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.1201
2025-03-08 21:15:28,199 - INFO - Resetting pretrained SAE
2025-03-08 21:17:03,150 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.3419
2025-03-08 21:17:03,409 - INFO - Resetting pretrained SAE
2025-03-08 21:18:37,571 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.5588
2025-03-08 21:18:37,816 - INFO - Resetting pretrained SAE
2025-03-08 21:20:12,761 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.4797
2025-03-08 21:20:12,991 - INFO - Resetting pretrained SAE
2025-03-08 21:21:47,709 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 2.5478
2025-03-08 21:21:47,956 - INFO - Resetting pretrained SAE
2025-03-08 21:23:22,535 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 2.594
2025-03-08 21:23:22,939 - INFO - Resetting pretrained SAE
2025-03-08 21:24:56,742 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 2.6322
2025-03-08 21:24:56,974 - INFO - Resetting pretrained SAE
2025-03-08 21:26:31,331 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 2.6012
2025-03-08 21:26:31,679 - INFO - Resetting pretrained SAE
2025-03-08 21:28:06,214 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 2.8507
2025-03-08 21:28:06,463 - INFO - Resetting pretrained SAE
2025-03-08 21:29:41,473 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 2.9567
2025-03-08 21:29:42,075 - INFO - Resetting pretrained SAE
2025-03-08 21:31:16,366 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 2.9267
2025-03-08 21:31:16,595 - INFO - Resetting pretrained SAE
2025-03-08 21:32:50,086 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 3.0011
2025-03-08 21:32:50,310 - INFO - Resetting pretrained SAE
2025-03-08 21:34:24,432 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.9147
2025-03-08 21:34:24,677 - INFO - Resetting pretrained SAE
2025-03-08 21:35:59,259 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.926
2025-03-08 21:35:59,482 - INFO - Resetting pretrained SAE
2025-03-08 21:37:32,945 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 3.0509
2025-03-08 21:37:33,182 - INFO - Resetting pretrained SAE
2025-03-08 21:39:07,746 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 3.0703
2025-03-08 21:39:08,062 - INFO - Resetting pretrained SAE
2025-03-08 21:40:42,126 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 3.0687
2025-03-08 21:40:42,354 - INFO - Resetting pretrained SAE
2025-03-08 21:42:17,195 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 3.0929
2025-03-08 21:42:17,438 - INFO - Resetting pretrained SAE
2025-03-08 21:43:52,325 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 3.1448
2025-03-08 21:43:52,563 - INFO - Resetting pretrained SAE
2025-03-08 21:45:26,683 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 3.1537
2025-03-08 21:45:26,904 - INFO - Resetting pretrained SAE
2025-03-08 21:47:01,289 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 3.1652
2025-03-08 21:47:01,522 - INFO - Resetting pretrained SAE
2025-03-08 21:48:35,738 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 3.0852
2025-03-08 21:48:35,973 - INFO - Resetting pretrained SAE
2025-03-08 21:50:10,712 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 3.1703
2025-03-08 21:50:10,959 - INFO - Resetting pretrained SAE
2025-03-08 21:51:45,519 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 3.047
2025-03-08 21:51:45,747 - INFO - Resetting pretrained SAE
2025-03-08 21:53:20,283 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 3.0955
2025-03-08 21:53:20,501 - INFO - Resetting pretrained SAE
2025-03-08 21:54:55,017 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 3.1381
2025-03-08 21:54:55,344 - INFO - Resetting pretrained SAE
2025-03-08 21:56:29,921 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 3.1207
2025-03-08 21:56:30,155 - INFO - Resetting pretrained SAE
2025-03-08 21:58:04,414 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 3.0932
2025-03-08 21:58:04,710 - INFO - Resetting pretrained SAE
2025-03-08 21:59:39,091 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 3.0993
2025-03-08 21:59:39,316 - INFO - Resetting pretrained SAE
2025-03-08 22:01:13,578 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 3.1752
2025-03-08 22:01:13,815 - INFO - Resetting pretrained SAE
2025-03-08 22:02:48,111 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 3.1816
2025-03-08 22:02:48,346 - INFO - Resetting pretrained SAE
2025-03-08 22:04:22,531 - INFO - After pruning layer 2 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 3.2666
2025-03-08 22:04:22,855 - INFO - Resetting pretrained SAE
2025-03-08 22:04:22,860 - INFO - For layer 2, the best Sparse Ratio: 0.99 with validation loss: 1.7099
2025-03-08 22:04:40,979 - INFO - After pruning pretrained SAE, Validation loss: 1.7099, and Test loss: 1.6761
2025-03-08 22:06:18,981 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 1.7018, and Test loss: 1.6733
2025-03-08 22:07:57,673 - INFO - Before pruning pretrained SAE, Validation loss: 1.8185, and Test loss: 1.8029
2025-03-08 22:07:57,674 - INFO - Pruning for layer: 3
2025-03-08 22:07:57,675 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.3.hook_z
2025-03-08 22:07:57,675 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.3.attn.hook_z-attn-sae-v1
2025-03-08 22:09:30,741 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7146
2025-03-08 22:09:30,985 - INFO - Resetting pretrained SAE
2025-03-08 22:11:04,784 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.715
2025-03-08 22:11:05,012 - INFO - Resetting pretrained SAE
2025-03-08 22:12:39,310 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.715
2025-03-08 22:12:39,666 - INFO - Resetting pretrained SAE
2025-03-08 22:14:13,772 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.7149
2025-03-08 22:14:14,016 - INFO - Resetting pretrained SAE
2025-03-08 22:15:48,540 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.717
2025-03-08 22:15:48,820 - INFO - Resetting pretrained SAE
2025-03-08 22:17:23,225 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.7168
2025-03-08 22:17:23,446 - INFO - Resetting pretrained SAE
2025-03-08 22:18:57,262 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 1.7155
2025-03-08 22:18:57,507 - INFO - Resetting pretrained SAE
2025-03-08 22:20:31,660 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 1.7151
2025-03-08 22:20:31,924 - INFO - Resetting pretrained SAE
2025-03-08 22:22:06,220 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 1.7176
2025-03-08 22:22:06,458 - INFO - Resetting pretrained SAE
2025-03-08 22:23:40,425 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 1.7186
2025-03-08 22:23:40,648 - INFO - Resetting pretrained SAE
2025-03-08 22:25:14,958 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 1.7173
2025-03-08 22:25:15,185 - INFO - Resetting pretrained SAE
2025-03-08 22:26:49,159 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 1.7186
2025-03-08 22:26:49,546 - INFO - Resetting pretrained SAE
2025-03-08 22:28:25,401 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 1.7187
2025-03-08 22:28:25,635 - INFO - Resetting pretrained SAE
2025-03-08 22:30:00,906 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 1.72
2025-03-08 22:30:01,202 - INFO - Resetting pretrained SAE
2025-03-08 22:31:36,431 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 1.7251
2025-03-08 22:31:36,723 - INFO - Resetting pretrained SAE
2025-03-08 22:33:11,078 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 1.7256
2025-03-08 22:33:11,411 - INFO - Resetting pretrained SAE
2025-03-08 22:34:45,427 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 1.7184
2025-03-08 22:34:45,655 - INFO - Resetting pretrained SAE
2025-03-08 22:36:19,755 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 1.7224
2025-03-08 22:36:19,977 - INFO - Resetting pretrained SAE
2025-03-08 22:37:54,869 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 1.7506
2025-03-08 22:37:55,109 - INFO - Resetting pretrained SAE
2025-03-08 22:39:29,842 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 1.7533
2025-03-08 22:39:30,084 - INFO - Resetting pretrained SAE
2025-03-08 22:41:04,203 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 1.7587
2025-03-08 22:41:04,429 - INFO - Resetting pretrained SAE
2025-03-08 22:42:38,031 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 1.7964
2025-03-08 22:42:38,268 - INFO - Resetting pretrained SAE
2025-03-08 22:44:12,489 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 1.8092
2025-03-08 22:44:12,715 - INFO - Resetting pretrained SAE
2025-03-08 22:45:46,774 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 1.8485
2025-03-08 22:45:47,008 - INFO - Resetting pretrained SAE
2025-03-08 22:47:20,981 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 1.8488
2025-03-08 22:47:21,283 - INFO - Resetting pretrained SAE
2025-03-08 22:48:56,726 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 1.8437
2025-03-08 22:48:56,946 - INFO - Resetting pretrained SAE
2025-03-08 22:50:31,383 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 1.862
2025-03-08 22:50:31,628 - INFO - Resetting pretrained SAE
2025-03-08 22:52:06,232 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 1.8637
2025-03-08 22:52:06,843 - INFO - Resetting pretrained SAE
2025-03-08 22:53:40,502 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 1.8838
2025-03-08 22:53:40,826 - INFO - Resetting pretrained SAE
2025-03-08 22:55:15,099 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 1.8876
2025-03-08 22:55:15,320 - INFO - Resetting pretrained SAE
2025-03-08 22:56:49,190 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 1.8284
2025-03-08 22:56:49,408 - INFO - Resetting pretrained SAE
2025-03-08 22:58:23,295 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 1.8594
2025-03-08 22:58:23,521 - INFO - Resetting pretrained SAE
2025-03-08 22:59:57,470 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.8711
2025-03-08 22:59:57,694 - INFO - Resetting pretrained SAE
2025-03-08 23:01:32,144 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.8574
2025-03-08 23:01:32,454 - INFO - Resetting pretrained SAE
2025-03-08 23:03:06,936 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.8431
2025-03-08 23:03:07,205 - INFO - Resetting pretrained SAE
2025-03-08 23:04:40,807 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.8304
2025-03-08 23:04:41,065 - INFO - Resetting pretrained SAE
2025-03-08 23:06:14,709 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.833
2025-03-08 23:06:14,930 - INFO - Resetting pretrained SAE
2025-03-08 23:07:49,033 - INFO - After pruning layer 3 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.838
2025-03-08 23:07:49,264 - INFO - Resetting pretrained SAE
2025-03-08 23:07:49,267 - INFO - For layer 3, the best Sparse Ratio: 0.99 with validation loss: 1.7146
2025-03-08 23:08:06,899 - INFO - After pruning pretrained SAE, Validation loss: 1.7146, and Test loss: 1.6834
2025-03-08 23:09:44,556 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 4.1164, and Test loss: 4.1702
2025-03-08 23:11:23,443 - INFO - Before pruning pretrained SAE, Validation loss: 1.7134, and Test loss: 1.6834
2025-03-08 23:11:23,444 - INFO - Pruning for layer: 4
2025-03-08 23:11:23,444 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.4.hook_z
2025-03-08 23:11:23,444 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.4.attn.hook_z-attn-sae-v1
2025-03-08 23:12:57,780 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7298
2025-03-08 23:12:58,242 - INFO - Resetting pretrained SAE
2025-03-08 23:14:32,362 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.7296
2025-03-08 23:14:32,586 - INFO - Resetting pretrained SAE
2025-03-08 23:16:06,408 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.7295
2025-03-08 23:16:06,714 - INFO - Resetting pretrained SAE
2025-03-08 23:17:41,177 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.7292
2025-03-08 23:17:41,456 - INFO - Resetting pretrained SAE
2025-03-08 23:19:15,347 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.7286
2025-03-08 23:19:15,581 - INFO - Resetting pretrained SAE
2025-03-08 23:20:49,630 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.7285
2025-03-08 23:20:50,240 - INFO - Resetting pretrained SAE
2025-03-08 23:22:24,862 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 1.7285
2025-03-08 23:22:25,097 - INFO - Resetting pretrained SAE
2025-03-08 23:23:59,245 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 1.7282
2025-03-08 23:23:59,511 - INFO - Resetting pretrained SAE
2025-03-08 23:25:34,164 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 1.7274
2025-03-08 23:25:34,397 - INFO - Resetting pretrained SAE
2025-03-08 23:27:07,934 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 1.727
2025-03-08 23:27:08,267 - INFO - Resetting pretrained SAE
2025-03-08 23:28:42,468 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 1.7268
2025-03-08 23:28:42,693 - INFO - Resetting pretrained SAE
2025-03-08 23:30:16,931 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 1.7262
2025-03-08 23:30:17,251 - INFO - Resetting pretrained SAE
2025-03-08 23:31:51,431 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 1.7261
2025-03-08 23:31:51,653 - INFO - Resetting pretrained SAE
2025-03-08 23:33:25,801 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 1.7258
2025-03-08 23:33:26,058 - INFO - Resetting pretrained SAE
2025-03-08 23:35:00,306 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 1.7249
2025-03-08 23:35:00,546 - INFO - Resetting pretrained SAE
2025-03-08 23:36:34,682 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 1.7245
2025-03-08 23:36:34,914 - INFO - Resetting pretrained SAE
2025-03-08 23:38:08,942 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 1.7244
2025-03-08 23:38:09,172 - INFO - Resetting pretrained SAE
2025-03-08 23:39:43,336 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 1.7241
2025-03-08 23:39:43,634 - INFO - Resetting pretrained SAE
2025-03-08 23:41:18,302 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 1.7232
2025-03-08 23:41:18,501 - INFO - Resetting pretrained SAE
2025-03-08 23:42:52,906 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 1.7229
2025-03-08 23:42:53,178 - INFO - Resetting pretrained SAE
2025-03-08 23:44:26,746 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 1.7218
2025-03-08 23:44:27,028 - INFO - Resetting pretrained SAE
2025-03-08 23:46:00,207 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 1.7219
2025-03-08 23:46:00,480 - INFO - Resetting pretrained SAE
2025-03-08 23:47:34,606 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 1.722
2025-03-08 23:47:34,867 - INFO - Resetting pretrained SAE
2025-03-08 23:49:08,878 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 1.7212
2025-03-08 23:49:09,132 - INFO - Resetting pretrained SAE
2025-03-08 23:50:43,698 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 1.7208
2025-03-08 23:50:43,929 - INFO - Resetting pretrained SAE
2025-03-08 23:52:17,805 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 1.7204
2025-03-08 23:52:18,031 - INFO - Resetting pretrained SAE
2025-03-08 23:53:52,035 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 1.7191
2025-03-08 23:53:52,261 - INFO - Resetting pretrained SAE
2025-03-08 23:55:27,040 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 1.719
2025-03-08 23:55:27,362 - INFO - Resetting pretrained SAE
2025-03-08 23:57:01,291 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 1.7186
2025-03-08 23:57:01,564 - INFO - Resetting pretrained SAE
2025-03-08 23:58:35,889 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 1.7178
2025-03-08 23:58:36,130 - INFO - Resetting pretrained SAE
2025-03-09 00:00:10,198 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 1.7175
2025-03-09 00:00:10,455 - INFO - Resetting pretrained SAE
2025-03-09 00:01:44,657 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 1.7168
2025-03-09 00:01:44,928 - INFO - Resetting pretrained SAE
2025-03-09 00:03:18,974 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.7172
2025-03-09 00:03:19,236 - INFO - Resetting pretrained SAE
2025-03-09 00:04:53,598 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.7178
2025-03-09 00:04:53,818 - INFO - Resetting pretrained SAE
2025-03-09 00:06:27,890 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.7172
2025-03-09 00:06:28,126 - INFO - Resetting pretrained SAE
2025-03-09 00:08:01,915 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.717
2025-03-09 00:08:02,334 - INFO - Resetting pretrained SAE
2025-03-09 00:09:36,248 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.7165
2025-03-09 00:09:36,484 - INFO - Resetting pretrained SAE
2025-03-09 00:11:10,334 - INFO - After pruning layer 4 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.7152
2025-03-09 00:11:10,627 - INFO - Resetting pretrained SAE
2025-03-09 00:11:10,631 - INFO - For layer 4, the best Sparse Ratio: 0.25 with validation loss: 1.7152
2025-03-09 00:11:28,898 - INFO - After pruning pretrained SAE, Validation loss: 1.7152, and Test loss: 1.6859
2025-03-09 00:13:07,505 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 1.7218, and Test loss: 1.6957
2025-03-09 00:14:50,793 - INFO - Before pruning pretrained SAE, Validation loss: 1.9584, and Test loss: 1.9408
2025-03-09 00:14:50,794 - INFO - Pruning for layer: 5
2025-03-09 00:14:50,794 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.5.hook_z
2025-03-09 00:14:50,794 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.5.attn.hook_z-attn-sae-v1
2025-03-09 00:16:28,944 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 3.6934
2025-03-09 00:16:29,389 - INFO - Resetting pretrained SAE
2025-03-09 00:18:08,091 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 3.7141
2025-03-09 00:18:08,517 - INFO - Resetting pretrained SAE
2025-03-09 00:19:47,572 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 5.0347
2025-03-09 00:19:47,927 - INFO - Resetting pretrained SAE
2025-03-09 00:21:26,502 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 4.368
2025-03-09 00:21:26,917 - INFO - Resetting pretrained SAE
2025-03-09 00:23:05,486 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 4.4644
2025-03-09 00:23:05,895 - INFO - Resetting pretrained SAE
2025-03-09 00:24:44,621 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 4.2671
2025-03-09 00:24:45,022 - INFO - Resetting pretrained SAE
2025-03-09 00:26:23,691 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 5.0378
2025-03-09 00:26:24,063 - INFO - Resetting pretrained SAE
2025-03-09 00:28:02,564 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 4.2562
2025-03-09 00:28:03,003 - INFO - Resetting pretrained SAE
2025-03-09 00:29:41,485 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 3.979
2025-03-09 00:29:41,831 - INFO - Resetting pretrained SAE
2025-03-09 00:31:19,967 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 3.386
2025-03-09 00:31:20,404 - INFO - Resetting pretrained SAE
2025-03-09 00:32:59,383 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 4.4081
2025-03-09 00:32:59,748 - INFO - Resetting pretrained SAE
2025-03-09 00:34:38,299 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 3.7873
2025-03-09 00:34:38,717 - INFO - Resetting pretrained SAE
2025-03-09 00:36:17,492 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 3.497
2025-03-09 00:36:17,858 - INFO - Resetting pretrained SAE
2025-03-09 00:37:56,096 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 3.792
2025-03-09 00:37:56,513 - INFO - Resetting pretrained SAE
2025-03-09 00:39:35,678 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 5.1185
2025-03-09 00:39:36,047 - INFO - Resetting pretrained SAE
2025-03-09 00:41:14,957 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 4.7435
2025-03-09 00:41:15,375 - INFO - Resetting pretrained SAE
2025-03-09 00:42:54,825 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 3.9549
2025-03-09 00:42:55,235 - INFO - Resetting pretrained SAE
2025-03-09 00:44:33,900 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 4.737
2025-03-09 00:44:34,280 - INFO - Resetting pretrained SAE
2025-03-09 00:46:12,935 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 5.1856
2025-03-09 00:46:13,281 - INFO - Resetting pretrained SAE
2025-03-09 00:47:51,128 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 5.0539
2025-03-09 00:47:51,566 - INFO - Resetting pretrained SAE
2025-03-09 00:49:29,509 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 5.0411
2025-03-09 00:49:29,854 - INFO - Resetting pretrained SAE
2025-03-09 00:51:08,904 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 4.725
2025-03-09 00:51:09,246 - INFO - Resetting pretrained SAE
2025-03-09 00:52:49,006 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 4.6147
2025-03-09 00:52:49,357 - INFO - Resetting pretrained SAE
2025-03-09 00:54:28,214 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 4.55
2025-03-09 00:54:28,568 - INFO - Resetting pretrained SAE
2025-03-09 00:56:07,389 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 4.4805
2025-03-09 00:56:07,789 - INFO - Resetting pretrained SAE
2025-03-09 00:57:47,220 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 5.0292
2025-03-09 00:57:47,667 - INFO - Resetting pretrained SAE
2025-03-09 00:59:26,308 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 4.4123
2025-03-09 00:59:26,665 - INFO - Resetting pretrained SAE
2025-03-09 01:01:05,863 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 4.4653
2025-03-09 01:01:06,206 - INFO - Resetting pretrained SAE
2025-03-09 01:02:44,674 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 4.3722
2025-03-09 01:02:45,061 - INFO - Resetting pretrained SAE
2025-03-09 01:04:24,223 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 4.5158
2025-03-09 01:04:24,632 - INFO - Resetting pretrained SAE
2025-03-09 01:06:02,882 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 3.3357
2025-03-09 01:06:03,227 - INFO - Resetting pretrained SAE
2025-03-09 01:07:41,235 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 3.7508
2025-03-09 01:07:41,579 - INFO - Resetting pretrained SAE
2025-03-09 01:09:20,321 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 3.4552
2025-03-09 01:09:20,663 - INFO - Resetting pretrained SAE
2025-03-09 01:10:59,231 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 2.819
2025-03-09 01:10:59,674 - INFO - Resetting pretrained SAE
2025-03-09 01:12:38,807 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 2.8225
2025-03-09 01:12:39,156 - INFO - Resetting pretrained SAE
2025-03-09 01:14:18,211 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 2.5826
2025-03-09 01:14:18,555 - INFO - Resetting pretrained SAE
2025-03-09 01:15:57,167 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 2.1134
2025-03-09 01:15:57,522 - INFO - Resetting pretrained SAE
2025-03-09 01:17:36,109 - INFO - After pruning layer 5 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 2.0848
2025-03-09 01:17:36,488 - INFO - Resetting pretrained SAE
2025-03-09 01:17:36,493 - INFO - For layer 5, the best Sparse Ratio: 0.25 with validation loss: 2.0848
2025-03-09 01:17:55,613 - INFO - After pruning pretrained SAE, Validation loss: 2.0848, and Test loss: 2.0131
2025-03-09 01:19:33,522 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 1.8188, and Test loss: 1.7874
2025-03-09 01:21:12,778 - INFO - Before pruning pretrained SAE, Validation loss: 1.7273, and Test loss: 1.7017
2025-03-09 01:21:12,779 - INFO - Pruning for layer: 6
2025-03-09 01:21:12,779 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.6.hook_z
2025-03-09 01:21:12,779 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.6.attn.hook_z-attn-sae-v1
2025-03-09 01:22:46,805 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7527
2025-03-09 01:22:47,016 - INFO - Resetting pretrained SAE
2025-03-09 01:24:21,461 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.7548
2025-03-09 01:24:21,713 - INFO - Resetting pretrained SAE
2025-03-09 01:25:55,940 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.7527
2025-03-09 01:25:56,167 - INFO - Resetting pretrained SAE
2025-03-09 01:27:30,523 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.7541
2025-03-09 01:27:30,745 - INFO - Resetting pretrained SAE
2025-03-09 01:29:05,429 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.7463
2025-03-09 01:29:05,697 - INFO - Resetting pretrained SAE
2025-03-09 01:30:40,637 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.7438
2025-03-09 01:30:40,947 - INFO - Resetting pretrained SAE
2025-03-09 01:32:15,238 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 1.7471
2025-03-09 01:32:15,496 - INFO - Resetting pretrained SAE
2025-03-09 01:33:49,688 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 1.7515
2025-03-09 01:33:49,910 - INFO - Resetting pretrained SAE
2025-03-09 01:35:24,693 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 1.7459
2025-03-09 01:35:24,921 - INFO - Resetting pretrained SAE
2025-03-09 01:36:58,714 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 1.7439
2025-03-09 01:36:58,928 - INFO - Resetting pretrained SAE
2025-03-09 01:38:32,405 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 1.7438
2025-03-09 01:38:32,739 - INFO - Resetting pretrained SAE
2025-03-09 01:40:06,278 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 1.7417
2025-03-09 01:40:06,579 - INFO - Resetting pretrained SAE
2025-03-09 01:41:41,227 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 1.7422
2025-03-09 01:41:41,452 - INFO - Resetting pretrained SAE
2025-03-09 01:43:16,007 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 1.7419
2025-03-09 01:43:16,228 - INFO - Resetting pretrained SAE
2025-03-09 01:44:50,398 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 1.7405
2025-03-09 01:44:50,619 - INFO - Resetting pretrained SAE
2025-03-09 01:46:24,923 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 1.7405
2025-03-09 01:46:25,160 - INFO - Resetting pretrained SAE
2025-03-09 01:47:58,667 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 1.739
2025-03-09 01:47:58,941 - INFO - Resetting pretrained SAE
2025-03-09 01:49:33,390 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 1.7391
2025-03-09 01:49:33,626 - INFO - Resetting pretrained SAE
2025-03-09 01:51:07,899 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 1.7378
2025-03-09 01:51:08,127 - INFO - Resetting pretrained SAE
2025-03-09 01:52:43,266 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 1.7473
2025-03-09 01:52:43,484 - INFO - Resetting pretrained SAE
2025-03-09 01:54:17,544 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 1.7393
2025-03-09 01:54:17,768 - INFO - Resetting pretrained SAE
2025-03-09 01:55:51,930 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 1.7366
2025-03-09 01:55:52,145 - INFO - Resetting pretrained SAE
2025-03-09 01:57:26,280 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 1.7366
2025-03-09 01:57:26,585 - INFO - Resetting pretrained SAE
2025-03-09 01:59:01,014 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 1.7364
2025-03-09 01:59:01,261 - INFO - Resetting pretrained SAE
2025-03-09 03:00:36,250 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 1.7367
2025-03-09 03:00:36,484 - INFO - Resetting pretrained SAE
2025-03-09 03:02:11,219 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 1.7369
2025-03-09 03:02:11,596 - INFO - Resetting pretrained SAE
2025-03-09 03:03:45,752 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 1.7357
2025-03-09 03:03:46,017 - INFO - Resetting pretrained SAE
2025-03-09 03:05:21,599 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 1.7355
2025-03-09 03:05:21,876 - INFO - Resetting pretrained SAE
2025-03-09 03:06:55,968 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 1.7331
2025-03-09 03:06:56,444 - INFO - Resetting pretrained SAE
2025-03-09 03:08:31,159 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 1.73
2025-03-09 03:08:31,398 - INFO - Resetting pretrained SAE
2025-03-09 03:10:05,845 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 1.7342
2025-03-09 03:10:06,421 - INFO - Resetting pretrained SAE
2025-03-09 03:11:40,227 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 1.7296
2025-03-09 03:11:40,466 - INFO - Resetting pretrained SAE
2025-03-09 03:13:15,802 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.7302
2025-03-09 03:13:16,058 - INFO - Resetting pretrained SAE
2025-03-09 03:14:50,172 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.7265
2025-03-09 03:14:50,421 - INFO - Resetting pretrained SAE
2025-03-09 03:16:24,887 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.7272
2025-03-09 03:16:25,190 - INFO - Resetting pretrained SAE
2025-03-09 03:17:59,871 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.7265
2025-03-09 03:18:00,114 - INFO - Resetting pretrained SAE
2025-03-09 03:19:34,284 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.7251
2025-03-09 03:19:34,502 - INFO - Resetting pretrained SAE
2025-03-09 03:21:10,172 - INFO - After pruning layer 6 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.7261
2025-03-09 03:21:10,702 - INFO - Resetting pretrained SAE
2025-03-09 03:21:10,707 - INFO - For layer 6, the best Sparse Ratio: 0.27 with validation loss: 1.7251
2025-03-09 03:21:28,656 - INFO - After pruning pretrained SAE, Validation loss: 1.7251, and Test loss: 1.6993
2025-03-09 03:23:06,709 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.9964, and Test loss: 2.9842
2025-03-09 03:24:51,141 - INFO - Before pruning pretrained SAE, Validation loss: 1.7165, and Test loss: 1.6877
2025-03-09 03:24:51,142 - INFO - Pruning for layer: 7
2025-03-09 03:24:51,142 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.7.hook_z
2025-03-09 03:24:51,142 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.7.attn.hook_z-attn-sae-v1
2025-03-09 03:26:30,158 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.9564
2025-03-09 03:26:30,504 - INFO - Resetting pretrained SAE
2025-03-09 03:28:08,908 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 2.2228
2025-03-09 03:28:09,249 - INFO - Resetting pretrained SAE
2025-03-09 03:29:48,769 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 2.5296
2025-03-09 03:29:49,122 - INFO - Resetting pretrained SAE
2025-03-09 03:31:28,317 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.9107
2025-03-09 03:31:28,671 - INFO - Resetting pretrained SAE
2025-03-09 03:33:06,813 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.9082
2025-03-09 03:33:07,203 - INFO - Resetting pretrained SAE
2025-03-09 03:34:45,416 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.8563
2025-03-09 03:34:45,770 - INFO - Resetting pretrained SAE
2025-03-09 03:36:24,063 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 2.0701
2025-03-09 03:36:24,482 - INFO - Resetting pretrained SAE
2025-03-09 03:38:03,595 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 2.1232
2025-03-09 03:38:03,949 - INFO - Resetting pretrained SAE
2025-03-09 03:39:42,537 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 2.3764
2025-03-09 03:39:42,932 - INFO - Resetting pretrained SAE
2025-03-09 03:41:21,959 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 2.5112
2025-03-09 03:41:22,307 - INFO - Resetting pretrained SAE
2025-03-09 03:43:01,094 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 3.0674
2025-03-09 03:43:02,270 - INFO - Resetting pretrained SAE
2025-03-09 03:44:41,205 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 3.1635
2025-03-09 03:44:41,585 - INFO - Resetting pretrained SAE
2025-03-09 03:46:20,222 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 3.0675
2025-03-09 03:46:20,576 - INFO - Resetting pretrained SAE
2025-03-09 03:47:59,287 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 3.0216
2025-03-09 03:47:59,658 - INFO - Resetting pretrained SAE
2025-03-09 03:49:38,400 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 3.6634
2025-03-09 03:49:38,760 - INFO - Resetting pretrained SAE
2025-03-09 03:51:17,468 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 3.4586
2025-03-09 03:51:17,906 - INFO - Resetting pretrained SAE
2025-03-09 03:52:56,239 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 3.1447
2025-03-09 03:52:56,598 - INFO - Resetting pretrained SAE
2025-03-09 03:54:34,774 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 2.8231
2025-03-09 03:54:35,149 - INFO - Resetting pretrained SAE
2025-03-09 03:56:13,339 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 2.974
2025-03-09 03:56:13,702 - INFO - Resetting pretrained SAE
2025-03-09 03:57:53,335 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 2.7507
2025-03-09 03:57:53,677 - INFO - Resetting pretrained SAE
2025-03-09 03:59:32,595 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 2.6265
2025-03-09 03:59:32,948 - INFO - Resetting pretrained SAE
2025-03-09 04:01:11,715 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 2.9333
2025-03-09 04:01:12,092 - INFO - Resetting pretrained SAE
2025-03-09 04:02:50,663 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 2.5612
2025-03-09 04:02:51,034 - INFO - Resetting pretrained SAE
2025-03-09 04:04:30,181 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 2.9091
2025-03-09 04:04:30,528 - INFO - Resetting pretrained SAE
2025-03-09 04:06:09,229 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 2.6958
2025-03-09 04:06:09,579 - INFO - Resetting pretrained SAE
2025-03-09 04:07:47,680 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 2.9235
2025-03-09 04:07:48,055 - INFO - Resetting pretrained SAE
2025-03-09 04:09:26,649 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 2.9626
2025-03-09 04:09:27,115 - INFO - Resetting pretrained SAE
2025-03-09 04:11:05,977 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 3.3027
2025-03-09 04:11:06,387 - INFO - Resetting pretrained SAE
2025-03-09 04:12:44,801 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 3.0531
2025-03-09 04:12:45,154 - INFO - Resetting pretrained SAE
2025-03-09 04:14:24,037 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 3.3377
2025-03-09 04:14:24,440 - INFO - Resetting pretrained SAE
2025-03-09 04:16:03,484 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 2.5824
2025-03-09 04:16:03,837 - INFO - Resetting pretrained SAE
2025-03-09 04:17:42,873 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 2.1011
2025-03-09 04:17:43,251 - INFO - Resetting pretrained SAE
2025-03-09 04:19:21,358 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.9507
2025-03-09 04:19:21,730 - INFO - Resetting pretrained SAE
2025-03-09 04:21:00,062 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.9031
2025-03-09 04:21:00,470 - INFO - Resetting pretrained SAE
2025-03-09 04:22:39,978 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.7792
2025-03-09 04:22:40,360 - INFO - Resetting pretrained SAE
2025-03-09 04:24:18,681 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.7811
2025-03-09 04:24:19,047 - INFO - Resetting pretrained SAE
2025-03-09 04:25:57,091 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.7466
2025-03-09 04:25:57,439 - INFO - Resetting pretrained SAE
2025-03-09 04:27:36,161 - INFO - After pruning layer 7 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.7419
2025-03-09 04:27:36,562 - INFO - Resetting pretrained SAE
2025-03-09 04:27:36,567 - INFO - For layer 7, the best Sparse Ratio: 0.25 with validation loss: 1.7419
2025-03-09 04:27:56,475 - INFO - After pruning pretrained SAE, Validation loss: 1.7419, and Test loss: 1.7165
2025-03-09 04:29:34,699 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.1235, and Test loss: 2.1057
2025-03-09 04:31:13,831 - INFO - Before pruning pretrained SAE, Validation loss: 1.7028, and Test loss: 1.6748
2025-03-09 04:31:13,831 - INFO - Pruning for layer: 8
2025-03-09 04:31:13,831 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.8.hook_z
2025-03-09 04:31:13,831 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.8.attn.hook_z-attn-sae-v1
2025-03-09 04:32:47,652 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7179
2025-03-09 04:32:48,114 - INFO - Resetting pretrained SAE
2025-03-09 04:34:23,020 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.7179
2025-03-09 04:34:23,245 - INFO - Resetting pretrained SAE
2025-03-09 04:35:56,947 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.7178
2025-03-09 04:35:57,234 - INFO - Resetting pretrained SAE
2025-03-09 04:37:31,258 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.7178
2025-03-09 04:37:31,506 - INFO - Resetting pretrained SAE
2025-03-09 04:39:05,923 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.7177
2025-03-09 04:39:06,417 - INFO - Resetting pretrained SAE
2025-03-09 04:40:40,635 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.7174
2025-03-09 04:40:40,871 - INFO - Resetting pretrained SAE
2025-03-09 04:42:16,033 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 1.717
2025-03-09 04:42:16,310 - INFO - Resetting pretrained SAE
2025-03-09 04:43:50,696 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 1.7168
2025-03-09 04:43:50,928 - INFO - Resetting pretrained SAE
2025-03-09 04:45:24,861 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 1.7165
2025-03-09 04:45:25,517 - INFO - Resetting pretrained SAE
2025-03-09 04:47:00,411 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 1.7162
2025-03-09 04:47:00,643 - INFO - Resetting pretrained SAE
2025-03-09 04:48:34,441 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 1.7158
2025-03-09 04:48:34,724 - INFO - Resetting pretrained SAE
2025-03-09 04:50:08,788 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 1.7156
2025-03-09 04:50:09,020 - INFO - Resetting pretrained SAE
2025-03-09 04:51:44,027 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 1.7152
2025-03-09 04:51:44,289 - INFO - Resetting pretrained SAE
2025-03-09 04:53:18,864 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 1.7148
2025-03-09 04:53:19,116 - INFO - Resetting pretrained SAE
2025-03-09 04:54:53,438 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 1.7146
2025-03-09 04:54:53,689 - INFO - Resetting pretrained SAE
2025-03-09 04:56:28,190 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 1.7144
2025-03-09 04:56:28,499 - INFO - Resetting pretrained SAE
2025-03-09 04:58:01,779 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 1.714
2025-03-09 04:58:02,022 - INFO - Resetting pretrained SAE
2025-03-09 04:59:36,076 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 1.7137
2025-03-09 04:59:36,337 - INFO - Resetting pretrained SAE
2025-03-09 05:01:10,890 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 1.7133
2025-03-09 05:01:11,121 - INFO - Resetting pretrained SAE
2025-03-09 05:02:46,103 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 1.713
2025-03-09 05:02:46,327 - INFO - Resetting pretrained SAE
2025-03-09 05:04:20,236 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 1.7126
2025-03-09 05:04:20,501 - INFO - Resetting pretrained SAE
2025-03-09 05:05:55,250 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 1.7119
2025-03-09 05:05:55,494 - INFO - Resetting pretrained SAE
2025-03-09 05:07:30,127 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 1.7115
2025-03-09 05:07:30,384 - INFO - Resetting pretrained SAE
2025-03-09 05:09:05,440 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 1.7113
2025-03-09 05:09:05,681 - INFO - Resetting pretrained SAE
2025-03-09 05:10:40,276 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 1.711
2025-03-09 05:10:40,495 - INFO - Resetting pretrained SAE
2025-03-09 05:12:15,217 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 1.7103
2025-03-09 05:12:15,446 - INFO - Resetting pretrained SAE
2025-03-09 05:13:49,918 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 1.7097
2025-03-09 05:13:50,156 - INFO - Resetting pretrained SAE
2025-03-09 05:15:24,932 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 1.7092
2025-03-09 05:15:25,179 - INFO - Resetting pretrained SAE
2025-03-09 05:17:01,037 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 1.7084
2025-03-09 05:17:01,279 - INFO - Resetting pretrained SAE
2025-03-09 05:18:35,198 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 1.7078
2025-03-09 05:18:35,422 - INFO - Resetting pretrained SAE
2025-03-09 05:20:09,905 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 1.7076
2025-03-09 05:20:10,153 - INFO - Resetting pretrained SAE
2025-03-09 05:21:43,996 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 1.7068
2025-03-09 05:21:44,270 - INFO - Resetting pretrained SAE
2025-03-09 05:23:19,241 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.7062
2025-03-09 05:23:19,470 - INFO - Resetting pretrained SAE
2025-03-09 05:24:54,155 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.7057
2025-03-09 05:24:54,642 - INFO - Resetting pretrained SAE
2025-03-09 05:26:29,468 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.7053
2025-03-09 05:26:29,705 - INFO - Resetting pretrained SAE
2025-03-09 05:28:04,393 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.7045
2025-03-09 05:28:04,627 - INFO - Resetting pretrained SAE
2025-03-09 05:29:39,093 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.7044
2025-03-09 05:29:39,313 - INFO - Resetting pretrained SAE
2025-03-09 05:31:14,384 - INFO - After pruning layer 8 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.7041
2025-03-09 05:31:14,613 - INFO - Resetting pretrained SAE
2025-03-09 05:31:14,616 - INFO - For layer 8, the best Sparse Ratio: 0.25 with validation loss: 1.7041
2025-03-09 05:31:32,362 - INFO - After pruning pretrained SAE, Validation loss: 1.7041, and Test loss: 1.6765
2025-03-09 05:33:10,129 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 2.4269, and Test loss: 2.4151
2025-03-09 05:34:49,302 - INFO - Before pruning pretrained SAE, Validation loss: 1.7082, and Test loss: 1.6775
2025-03-09 05:34:49,303 - INFO - Pruning for layer: 9
2025-03-09 05:34:49,303 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.9.hook_z
2025-03-09 05:34:49,303 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.9.attn.hook_z-attn-sae-v1
2025-03-09 05:36:23,829 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7526
2025-03-09 05:36:24,064 - INFO - Resetting pretrained SAE
2025-03-09 05:37:58,375 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.7527
2025-03-09 05:37:58,607 - INFO - Resetting pretrained SAE
2025-03-09 05:39:32,865 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.7525
2025-03-09 05:39:33,088 - INFO - Resetting pretrained SAE
2025-03-09 05:41:07,771 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.7525
2025-03-09 05:41:08,018 - INFO - Resetting pretrained SAE
2025-03-09 05:42:41,762 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.7531
2025-03-09 05:42:42,026 - INFO - Resetting pretrained SAE
2025-03-09 05:44:15,915 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.7532
2025-03-09 05:44:16,139 - INFO - Resetting pretrained SAE
2025-03-09 05:45:49,920 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 1.7523
2025-03-09 05:45:50,140 - INFO - Resetting pretrained SAE
2025-03-09 05:47:24,773 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 1.7531
2025-03-09 05:47:25,000 - INFO - Resetting pretrained SAE
2025-03-09 05:48:59,841 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 1.7518
2025-03-09 05:49:00,099 - INFO - Resetting pretrained SAE
2025-03-09 05:50:34,098 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 1.7523
2025-03-09 05:50:34,331 - INFO - Resetting pretrained SAE
2025-03-09 05:52:08,022 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 1.7514
2025-03-09 05:52:08,255 - INFO - Resetting pretrained SAE
2025-03-09 05:53:42,812 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 1.7525
2025-03-09 05:53:43,082 - INFO - Resetting pretrained SAE
2025-03-09 05:55:18,101 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 1.7525
2025-03-09 05:55:18,371 - INFO - Resetting pretrained SAE
2025-03-09 05:56:53,292 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 1.7525
2025-03-09 05:56:53,589 - INFO - Resetting pretrained SAE
2025-03-09 05:58:27,554 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 1.7523
2025-03-09 05:58:27,773 - INFO - Resetting pretrained SAE
2025-03-09 06:00:02,427 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 1.7517
2025-03-09 06:00:02,664 - INFO - Resetting pretrained SAE
2025-03-09 06:01:37,581 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 1.7524
2025-03-09 06:01:37,817 - INFO - Resetting pretrained SAE
2025-03-09 06:03:13,595 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 1.7516
2025-03-09 06:03:14,034 - INFO - Resetting pretrained SAE
2025-03-09 06:04:48,520 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 1.7514
2025-03-09 06:04:48,815 - INFO - Resetting pretrained SAE
2025-03-09 06:06:22,830 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 1.7517
2025-03-09 06:06:23,130 - INFO - Resetting pretrained SAE
2025-03-09 06:07:56,622 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 1.7493
2025-03-09 06:07:56,849 - INFO - Resetting pretrained SAE
2025-03-09 06:09:31,170 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 1.7502
2025-03-09 06:09:31,408 - INFO - Resetting pretrained SAE
2025-03-09 06:11:06,684 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 1.7568
2025-03-09 06:11:06,939 - INFO - Resetting pretrained SAE
2025-03-09 06:12:41,008 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 1.7602
2025-03-09 06:12:41,379 - INFO - Resetting pretrained SAE
2025-03-09 06:14:15,929 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 1.7535
2025-03-09 06:14:16,177 - INFO - Resetting pretrained SAE
2025-03-09 06:15:51,394 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 1.7396
2025-03-09 06:15:51,684 - INFO - Resetting pretrained SAE
2025-03-09 06:17:25,212 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 1.7309
2025-03-09 06:17:25,464 - INFO - Resetting pretrained SAE
2025-03-09 06:19:00,408 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 1.7298
2025-03-09 06:19:00,641 - INFO - Resetting pretrained SAE
2025-03-09 06:20:35,908 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 1.7264
2025-03-09 06:20:36,135 - INFO - Resetting pretrained SAE
2025-03-09 06:22:11,422 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 1.7257
2025-03-09 06:22:11,647 - INFO - Resetting pretrained SAE
2025-03-09 06:23:46,562 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 1.7249
2025-03-09 06:23:46,834 - INFO - Resetting pretrained SAE
2025-03-09 06:25:21,866 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 1.7236
2025-03-09 06:25:22,102 - INFO - Resetting pretrained SAE
2025-03-09 06:26:57,166 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.7231
2025-03-09 06:26:57,389 - INFO - Resetting pretrained SAE
2025-03-09 06:28:31,916 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.7212
2025-03-09 06:28:33,654 - INFO - Resetting pretrained SAE
2025-03-09 06:30:08,077 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.7188
2025-03-09 06:30:08,341 - INFO - Resetting pretrained SAE
2025-03-09 06:31:42,733 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.7179
2025-03-09 06:31:42,967 - INFO - Resetting pretrained SAE
2025-03-09 06:33:17,654 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.7157
2025-03-09 06:33:17,896 - INFO - Resetting pretrained SAE
2025-03-09 06:34:51,783 - INFO - After pruning layer 9 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.7142
2025-03-09 06:34:52,091 - INFO - Resetting pretrained SAE
2025-03-09 06:34:52,094 - INFO - For layer 9, the best Sparse Ratio: 0.25 with validation loss: 1.7142
2025-03-09 06:35:09,638 - INFO - After pruning pretrained SAE, Validation loss: 1.7142, and Test loss: 1.6824
2025-03-09 06:36:46,550 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 1.7118, and Test loss: 1.6841
2025-03-09 06:38:24,286 - INFO - Before pruning pretrained SAE, Validation loss: 1.7017, and Test loss: 1.6707
2025-03-09 06:38:24,287 - INFO - Pruning for layer: 10
2025-03-09 06:38:24,287 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.10.hook_z
2025-03-09 06:38:24,287 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.10.attn.hook_z-attn-sae-v1
2025-03-09 06:39:57,429 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7277
2025-03-09 06:39:57,656 - INFO - Resetting pretrained SAE
2025-03-09 06:41:30,303 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.7278
2025-03-09 06:41:30,536 - INFO - Resetting pretrained SAE
2025-03-09 06:43:04,605 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.7279
2025-03-09 06:43:04,912 - INFO - Resetting pretrained SAE
2025-03-09 06:44:38,594 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.7281
2025-03-09 06:44:38,823 - INFO - Resetting pretrained SAE
2025-03-09 06:46:12,723 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.7281
2025-03-09 06:46:12,954 - INFO - Resetting pretrained SAE
2025-03-09 06:47:46,652 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.7281
2025-03-09 06:47:46,882 - INFO - Resetting pretrained SAE
2025-03-09 06:49:20,401 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 1.7281
2025-03-09 06:49:20,676 - INFO - Resetting pretrained SAE
2025-03-09 06:50:53,994 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 1.728
2025-03-09 06:50:54,261 - INFO - Resetting pretrained SAE
2025-03-09 06:52:27,856 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 1.7279
2025-03-09 06:52:28,093 - INFO - Resetting pretrained SAE
2025-03-09 06:54:02,125 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 1.7281
2025-03-09 06:54:02,351 - INFO - Resetting pretrained SAE
2025-03-09 06:55:35,381 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 1.7279
2025-03-09 06:55:35,610 - INFO - Resetting pretrained SAE
2025-03-09 06:57:08,920 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 1.7279
2025-03-09 06:57:09,176 - INFO - Resetting pretrained SAE
2025-03-09 06:58:42,432 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 1.7278
2025-03-09 06:58:42,684 - INFO - Resetting pretrained SAE
2025-03-09 07:00:16,307 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 1.7277
2025-03-09 07:00:16,592 - INFO - Resetting pretrained SAE
2025-03-09 07:01:50,537 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 1.7276
2025-03-09 07:01:50,929 - INFO - Resetting pretrained SAE
2025-03-09 07:03:24,033 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 1.7273
2025-03-09 07:03:24,262 - INFO - Resetting pretrained SAE
2025-03-09 07:04:57,258 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 1.7276
2025-03-09 07:04:57,492 - INFO - Resetting pretrained SAE
2025-03-09 07:06:31,008 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 1.7272
2025-03-09 07:06:31,308 - INFO - Resetting pretrained SAE
2025-03-09 07:08:04,956 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 1.7273
2025-03-09 07:08:05,177 - INFO - Resetting pretrained SAE
2025-03-09 07:09:38,990 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 1.7273
2025-03-09 07:09:39,215 - INFO - Resetting pretrained SAE
2025-03-09 07:11:12,562 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 1.7271
2025-03-09 07:11:12,798 - INFO - Resetting pretrained SAE
2025-03-09 07:12:46,495 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 1.7268
2025-03-09 07:12:46,788 - INFO - Resetting pretrained SAE
2025-03-09 07:14:19,989 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 1.7267
2025-03-09 07:14:20,224 - INFO - Resetting pretrained SAE
2025-03-09 07:15:53,922 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 1.7259
2025-03-09 07:15:54,146 - INFO - Resetting pretrained SAE
2025-03-09 07:17:27,997 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 1.7248
2025-03-09 07:17:28,227 - INFO - Resetting pretrained SAE
2025-03-09 07:19:01,816 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 1.7245
2025-03-09 07:19:02,048 - INFO - Resetting pretrained SAE
2025-03-09 07:20:36,039 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 1.7242
2025-03-09 07:20:36,263 - INFO - Resetting pretrained SAE
2025-03-09 07:22:10,427 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 1.7239
2025-03-09 07:22:10,658 - INFO - Resetting pretrained SAE
2025-03-09 07:23:43,864 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 1.7225
2025-03-09 07:23:44,094 - INFO - Resetting pretrained SAE
2025-03-09 07:25:17,546 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 1.722
2025-03-09 07:25:17,821 - INFO - Resetting pretrained SAE
2025-03-09 07:26:51,789 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 1.7199
2025-03-09 07:26:52,027 - INFO - Resetting pretrained SAE
2025-03-09 07:28:25,309 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 1.7187
2025-03-09 07:28:25,535 - INFO - Resetting pretrained SAE
2025-03-09 07:29:58,584 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.7179
2025-03-09 07:29:58,814 - INFO - Resetting pretrained SAE
2025-03-09 07:31:32,212 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.7153
2025-03-09 07:31:32,448 - INFO - Resetting pretrained SAE
2025-03-09 07:33:06,148 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.7146
2025-03-09 07:33:06,399 - INFO - Resetting pretrained SAE
2025-03-09 07:34:40,372 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.7128
2025-03-09 07:34:40,606 - INFO - Resetting pretrained SAE
2025-03-09 07:36:14,696 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.7113
2025-03-09 07:36:14,929 - INFO - Resetting pretrained SAE
2025-03-09 07:37:49,053 - INFO - After pruning layer 10 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.7096
2025-03-09 07:37:49,432 - INFO - Resetting pretrained SAE
2025-03-09 07:37:49,437 - INFO - For layer 10, the best Sparse Ratio: 0.25 with validation loss: 1.7096
2025-03-09 07:38:07,305 - INFO - After pruning pretrained SAE, Validation loss: 1.7096, and Test loss: 1.6781
2025-03-09 07:39:44,914 - INFO - HuggingFace SAE trained on the pruned model, Validation loss: 1.6968, and Test loss: 1.6687
2025-03-09 07:41:23,083 - INFO - Before pruning pretrained SAE, Validation loss: 1.7229, and Test loss: 1.6933
2025-03-09 07:41:23,084 - INFO - Pruning for layer: 11
2025-03-09 07:41:23,084 - INFO - Pretrained SAE location: gpt2-small-hook-z-kk/blocks.11.hook_z
2025-03-09 07:41:23,084 - INFO - HuggingFace SAE location: suchitg/sae_test/blocks.11.attn.hook_z-attn-sae-v1
2025-03-09 07:42:57,523 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.99, Validation Loss: 1.7337
2025-03-09 07:42:57,762 - INFO - Resetting pretrained SAE
2025-03-09 07:44:31,268 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.97, Validation Loss: 1.7359
2025-03-09 07:44:31,490 - INFO - Resetting pretrained SAE
2025-03-09 07:46:04,512 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.95, Validation Loss: 1.7344
2025-03-09 07:46:04,753 - INFO - Resetting pretrained SAE
2025-03-09 07:47:38,230 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.93, Validation Loss: 1.7353
2025-03-09 07:47:38,479 - INFO - Resetting pretrained SAE
2025-03-09 07:49:12,794 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.91, Validation Loss: 1.7352
2025-03-09 07:49:13,034 - INFO - Resetting pretrained SAE
2025-03-09 07:50:47,080 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.89, Validation Loss: 1.736
2025-03-09 07:50:47,311 - INFO - Resetting pretrained SAE
2025-03-09 07:52:21,947 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.87, Validation Loss: 1.7361
2025-03-09 07:52:22,187 - INFO - Resetting pretrained SAE
2025-03-09 07:53:55,748 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.85, Validation Loss: 1.7366
2025-03-09 07:53:55,976 - INFO - Resetting pretrained SAE
2025-03-09 07:55:29,915 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.83, Validation Loss: 1.7371
2025-03-09 07:55:30,201 - INFO - Resetting pretrained SAE
2025-03-09 07:57:04,500 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.81, Validation Loss: 1.7361
2025-03-09 07:57:04,785 - INFO - Resetting pretrained SAE
2025-03-09 07:58:39,299 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.79, Validation Loss: 1.7373
2025-03-09 07:58:39,539 - INFO - Resetting pretrained SAE
2025-03-09 08:00:13,107 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.77, Validation Loss: 1.7375
2025-03-09 08:00:13,350 - INFO - Resetting pretrained SAE
2025-03-09 08:01:47,387 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.75, Validation Loss: 1.7382
2025-03-09 08:01:47,656 - INFO - Resetting pretrained SAE
2025-03-09 08:03:21,100 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.73, Validation Loss: 1.7375
2025-03-09 08:03:21,342 - INFO - Resetting pretrained SAE
2025-03-09 08:04:54,909 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.71, Validation Loss: 1.7364
2025-03-09 08:04:55,162 - INFO - Resetting pretrained SAE
2025-03-09 08:06:28,315 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.69, Validation Loss: 1.738
2025-03-09 08:06:28,553 - INFO - Resetting pretrained SAE
2025-03-09 08:08:02,326 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.67, Validation Loss: 1.7384
2025-03-09 08:08:02,564 - INFO - Resetting pretrained SAE
2025-03-09 08:09:35,799 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.65, Validation Loss: 1.7387
2025-03-09 08:09:36,050 - INFO - Resetting pretrained SAE
2025-03-09 08:11:09,980 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.63, Validation Loss: 1.7388
2025-03-09 08:11:10,215 - INFO - Resetting pretrained SAE
2025-03-09 08:12:43,233 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.61, Validation Loss: 1.7397
2025-03-09 08:12:43,485 - INFO - Resetting pretrained SAE
2025-03-09 08:14:17,819 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.59, Validation Loss: 1.7402
2025-03-09 08:14:18,058 - INFO - Resetting pretrained SAE
2025-03-09 08:15:51,668 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.57, Validation Loss: 1.7396
2025-03-09 08:15:51,904 - INFO - Resetting pretrained SAE
2025-03-09 08:17:25,228 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.55, Validation Loss: 1.7385
2025-03-09 08:17:25,479 - INFO - Resetting pretrained SAE
2025-03-09 08:18:59,105 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.53, Validation Loss: 1.7385
2025-03-09 08:18:59,347 - INFO - Resetting pretrained SAE
2025-03-09 08:20:33,421 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.51, Validation Loss: 1.7379
2025-03-09 08:20:33,684 - INFO - Resetting pretrained SAE
2025-03-09 08:22:07,642 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.49, Validation Loss: 1.7376
2025-03-09 08:22:07,880 - INFO - Resetting pretrained SAE
2025-03-09 08:23:41,060 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.47, Validation Loss: 1.7367
2025-03-09 08:23:41,318 - INFO - Resetting pretrained SAE
2025-03-09 08:25:15,507 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.45, Validation Loss: 1.7395
2025-03-09 08:25:15,736 - INFO - Resetting pretrained SAE
2025-03-09 08:26:49,638 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.43, Validation Loss: 1.7381
2025-03-09 08:26:49,913 - INFO - Resetting pretrained SAE
2025-03-09 08:28:24,091 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.41, Validation Loss: 1.7381
2025-03-09 08:28:24,327 - INFO - Resetting pretrained SAE
2025-03-09 08:29:57,518 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.39, Validation Loss: 1.7397
2025-03-09 08:29:57,771 - INFO - Resetting pretrained SAE
2025-03-09 08:31:31,483 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.37, Validation Loss: 1.7382
2025-03-09 08:31:31,762 - INFO - Resetting pretrained SAE
2025-03-09 08:33:05,218 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.35, Validation Loss: 1.7445
2025-03-09 08:33:05,477 - INFO - Resetting pretrained SAE
2025-03-09 08:34:39,771 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.33, Validation Loss: 1.7344
2025-03-09 08:34:40,043 - INFO - Resetting pretrained SAE
2025-03-09 08:36:13,690 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.31, Validation Loss: 1.737
2025-03-09 08:36:13,991 - INFO - Resetting pretrained SAE
2025-03-09 08:37:47,324 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.29, Validation Loss: 1.7329
2025-03-09 08:37:47,553 - INFO - Resetting pretrained SAE
2025-03-09 08:39:21,310 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.27, Validation Loss: 1.7335
2025-03-09 08:39:21,558 - INFO - Resetting pretrained SAE
2025-03-09 08:40:55,248 - INFO - After pruning layer 11 of pretrained SAE with sparse ratio: 0.25, Validation Loss: 1.7332
2025-03-09 08:40:55,487 - INFO - Resetting pretrained SAE
2025-03-09 08:40:55,490 - INFO - For layer 11, the best Sparse Ratio: 0.29 with validation loss: 1.7329
2025-03-09 08:41:13,145 - INFO - After pruning pretrained SAE, Validation loss: 1.7329, and Test loss: 1.7011
